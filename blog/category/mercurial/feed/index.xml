<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:wfw="http://wellformedweb.org/CommentAPI/"
     >
  <channel>
    <title>Gregory Szorc's Digital Home</title>
    <link>http://gregoryszorc.com/blog</link>
    <description>Rambling on</description>
    <pubDate>Tue, 14 Oct 2014 19:13:54 GMT</pubDate>
    <generator>Blogofile</generator>
    <sy:updatePeriod>hourly</sy:updatePeriod>
    <sy:updateFrequency>1</sy:updateFrequency>
    <item>
      <title>Robustly Testing Version Control at Mozilla</title>
      <link>http://gregoryszorc.com/blog/2014/10/14/robustly-testing-version-control-at-mozilla</link>
      <pubDate>Tue, 14 Oct 2014 12:00:00 PDT</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2014/10/14/robustly-testing-version-control-at-mozilla</guid>
      <description>Robustly Testing Version Control at Mozilla</description>
      <content:encoded><![CDATA[<p>Version control services and interaction with them play an important
role at any company. Despite version control being a critical part
of your infrastructure, my experience from working at a few companies
and talking with others is that version control often doesn't get the
testing love that other services do. Hooks get written, spot-tested
by the author, and deployed. Tools that interact with version control
often rely on behavior that may or may not change over time,
especially when the version of your version control software is
upgraded.</p>
<p>We've seen this pattern at Mozilla. Mercurial hooks and extensions
were written and deployed to the server without test coverage. As a
result, <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1070637">things break</a>
when we try to upgrade the server. This happens a few times and you
naturally develop an attitude of fear, uncertainty, and doubt around
touching anything on the server (or the clients for that matter). <em>If
it isn't broken, why fix it</em> prevails for months or years. Then one an
enthusiastic individual comes around wanting to deploy some hot new
functionality. You tell them the path is arduous because the server is
running antiquated versions of software and nothing is tested. The
individual realizes the amazing change isn't worth the effort and
justifiably throws up their hands and gives up. This is almost a
textbook definition of how not having test coverage can result
in technical debt. This is the position Mozilla is trying to recover
from.</p>
<p>One of the biggest impacts I've had since joining the Developer Services
Team at Mozilla a little over a month ago has been changing the story
about how we test version control at Mozilla.</p>
<p>I'm proud to say that Mozilla now has a robust enough testing
infrastructure in place around our Mercurial server that we're feeling
pretty good about silencing the doubters when it comes to changing
server behavior. Here's how we did it.</p>
<p>The genesis of this project was likely me getting involved with the
hg-git and Mercurial projects. For hg-git, I learned a bit about
Mercurial internals and how extensions work. When I looked at Mercurial
extensions and hooks used by Mozilla, I started to realize what parts
were good and what parts were bad. I realized what parts would likely
break after upgrades. When I started contributing patches to Mercurial
itself, I took notice of how Mercurial is tested. When I discovered
<a href="http://mercurial.selenic.com/wiki/WritingTests">T Tests</a>, I thought,
<em>wow, that's pretty cool: we should use them to test Mozilla's Mercurial
customizations!</em></p>
<p>After some frustrations with Mercurial extensions breaking after
Mercurial upgrades, I wanted to do something about it to prevent this from
happening again. I'm a
<a href="/blog/2014/09/09/on-monolithic-repositories/">huge fan of unified repositories</a>.
So earlier this year, I reached out to the various parties who maintain
all the different components and convinced nearly everyone that
establishing a single repository for all the version control code was a
<a href="/blog/2014/02/05/new-repository-for-mozilla-version-control-tools/">good idea</a>.
The <a href="https://hg.mozilla.org/hgcustom/version-control-tools/">version-control-tools</a>
repository was born. Things were slow at first. It was initially pretty
much my playground for hosting Mercurial extensions that I authored.
Fast forward a few months, and the version-control-tools repository now
contains full history imports of our
<a href="https://hg.mozilla.org/hgcustom/version-control-tools/file/573db71cdb79/hghooks">Mercurial hooks</a>
that are deployed on <a href="https://hg.mozilla.org/">hg.mozilla.org</a>, the
<a href="https://hg.mozilla.org/hgcustom/version-control-tools/file/573db71cdb79/hgtemplates">templates</a>
used to render HTML on hg.mozilla.org, and pretty much every
<a href="https://hg.mozilla.org/hgcustom/version-control-tools/file/573db71cdb79/hgext">Mercurial extension</a>
authored by Mozillians, including
<a href="https://hg.mozilla.org/hgcustom/version-control-tools/file/573db71cdb79/hgext/pushlog-legacy">pushlog</a>.
Having all the code in one repository has been very useful. It has
simplified server deployments: we now pull 1 repository instead of 3. If
there is a dependency between different components, we can do the update
atomically. These are all benefits of using a single repository instead
of N&gt;1.</p>
<p>While version-control-tools was still pretty much my personal
playground, I introduced a short script for running tests. It was pretty
basic: just find test files and invoke them with Mercurial's test
harness. It served my needs pretty well. Over time, as more and more
functionality was rolled into version-control-tools, we expanded the
scope of the test harness.</p>
<p>We can now run Python unit tests (in addition to Mercurial .t tests).
Test all of the things!</p>
<p>We set up <a href="https://ci.mozilla.org/job/version-control-tools/">continuous integration</a>
with Jenkins so tests run after check-in and alert us when things fail.</p>
<p>We added <a href="https://ci.mozilla.org/job/version-control-tools/coveragepy/?">code coverage</a>
so we can see what is and isn't being tested. Using code coverage data,
we've
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1075274">identified a server upgrade bug</a>
before it happens. We're also using the data to ensure that code is tested
as thoroughly as it needs to be. The code coverage data has been
invaluable at assessing the quality of our tests. I'm still shocked that
Firefox developers tolerate not having JavaScript code coverage when
developing Firefox features. (I'm not saying code coverage is perfect,
merely that it is a valuable tool in your arsenal.)</p>
<p>We added support for running tests against multiple versions of
Mercurial. We even test the bleeding edge of Mercurial so we know when
an upstream Mercurial change breaks our code. So, no more surprises on
Mercurial release day. I can tell you today that we have a handful of
extensions that are broken in Mercurial 3.2, due for release around
November 1. (Hopefully we'll fix them before release.)</p>
<p>We have Vagrant configurations so you can start a virtual machine that
runs the tests the same way Jenkins does.</p>
<p>The latest addition to the test harness is the ability to spin up Docker
containers as part of tests. Right now, this is limited to running
Bugzilla during tests. But I imagine the scope will only increase over
time.</p>
<p>Before I go on, I want to quickly explain how amazing Mercurial's
<a href="http://mercurial.selenic.com/wiki/WritingTests#Writing_a_shell_script_test">.t tests</a>
are. These are a flavor of tests used by Mercurial and the dominant form
of new tests added to the version-control-tools repository. These tests
are glorified shell scripts annotated with expected
command output and other metadata. It might be easier to explain by
showing. Take
<a href="https://hg.mozilla.org/hgcustom/version-control-tools/file/573db71cdb79/hgext/bzpost/tests/test-post.t">bzpost's tests</a>
as an example. The bzpost extension automatically posts commit URLs to
Bugzilla during push.
<a href="http://gregoryszorc.com/blog/2014/06/30/update-bugzilla-automatically-on-push/">Read more</a>
if you are interested. What I like so much about .t tests is that they
are actually testing the user experience. The test
<a href="https://hg.mozilla.org/hgcustom/version-control-tools/file/573db71cdb79/hgext/bzpost/tests/test-post.t#l69">actually runs hg push</a>
and verifies the output is exactly what is intended. Furthermore,
since we're running a Dockerized Bugzilla server during the test, we're
able to
<a href="https://hg.mozilla.org/hgcustom/version-control-tools/file/573db71cdb79/hgext/bzpost/tests/test-post.t#l108">verify</a>
that the bzpost extension actually resulted in Bugzilla comments being
added to the appropriate bug(s). Contrast this with unit tests that only
test a subset of functionality. Or, contrast with writing a lot of
boilerplate and often hard-to-read code that invokes processes and uses
regular expressions, etc to compare output. I find .t tests are more
concise and they do a better job of testing user experience. More than
once I've written a .t test and thought <em>this user experience doesn't
feel right, I should change the behavior to be more user friendly</em>. This
happened because I was writing actual end-user commands as part of
writing tests and seeing the exact output the user would see. It is
much harder to attain this sense of understanding when writing unit
tests. I can name a few projects with poor command line interfaces that
could benefit from this approach... I'm not saying .t tests are perfect
or that they should replace other testing methodologies such as unit
tests. I just think they are very useful for accurately testing
higher-level functionality and for assessing user experience. I really
wish we had these tests for mach commands...</p>
<p>Anyway, with a proper testing harness in place for our version control code,
we've been pretty good about ensuring new code is properly tested. When
people submit new hooks or patches to existing hooks, we can push back and
refuse to grant review unless tests are included. When someone requests a
new deployment to the server, we can look at what changed, cross-reference
to test coverage, and assess the riskiness of the deployment. We're getting
to the point where we just trust our tests and server deployments are minor
events. Concerns over accidental regressions due to server changes are
waning. We can tell people <em>if you really care about this not breaking,
you need a test</em> and <em>if you add a test, we'll support it for you.</em>
People are often more than happy to write tests to ensure them peace of
mind, especially when that test's presence shifts maintenance
responsibility away from them. We're happy because we don't have many
surprises (and fire drills) at deployment time. It's a win-win!</p>
<p>So, what's next? Good question! We still have a number of large gaps in
our test coverage. Our code to synchronize repositories from the master
server to read-only slaves is likely the most critical omission. We also
don't yet have a good way of reproducing our server environment.
Ideally, we'd run the continuous integration in an environment that's
very similar to production. Same package versions and everything. This
would also allow us to simulate the actual hg.mozilla.org server
topology during tests. Currently, our tests are more unit-style than
integration-style. We rely on the consistent behavior of Mercurial and
other tools as sufficient proxies for test accuracy and we back those up
with running the tests on the staging server before production
deployment. But these aren't a substitute for an accurate reproduction
of the production servers, especially when it comes to things like the
replication tests. We'll get there some day. I also have plans to
improve Mercurial's test harness to better facilitate some of our
advanced use cases. I would absolutely love to make Mercurial's .t test
harness more consumable outside the context of Mercurial.
(<a href="https://bitbucket.org/brodie/cram">cram</a> is one such attempt at this.)
We also need to incorporate the Git server code into this repository.
Currently, I'm pretty sure everything Git at Mozilla is untested.
Challenge accepted!</p>
<p>In summary, our story for testing version control at Mozilla has gone
from a cobbled together mess to something cohesive and comprehensive.
This has given us confidence to move fast without breaking things. I think
the weeks of people time invested into improving the state of testing
was well spent and will pay enormous dividends going forward. Looking
back, the mountain of technical debt now looks like a mole hill. I feel
good knowing that I played a part in making this change.</p>]]></content:encoded>
    </item>
    <item>
      <title>Mozilla Mercurial Statistics</title>
      <link>http://gregoryszorc.com/blog/2014/09/30/mozilla-mercurial-statistics</link>
      <pubDate>Tue, 30 Sep 2014 13:17:00 PDT</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2014/09/30/mozilla-mercurial-statistics</guid>
      <description>Mozilla Mercurial Statistics</description>
      <content:encoded><![CDATA[<p>I recently gained SSH access to Mozilla's Mercurial servers. This allows
me to run some custom queries directly against the data. I was
interested in some high-level numbers and thought I'd share the results.</p>
<p>hg.mozilla.org hosts a total of 3,445 repositories. Of these, there are
1,223 distinct root commits (i.e. distinct graphs). Altogether, there
are 32,123,211 commits. Of those, there are 865,594 distinct commits (not
double counting commits that appear in multiple repositories).</p>
<p>We have a high ratio of total commits to distinct commits (about 37:1).
This means we have high duplication of data on disk. This basically
means a lot of repos are clones/forks of existing ones. No big surprise
there.</p>
<p>What is surprising to me is the low number of total distinct commits. I
was expecting the number to run into the millions. (Firefox itself
accounts for ~240,000 commits.) Perhaps a lot of the data is sitting in
Git, Bitbucket, and GitHub. Sounds like a good data mining expedition...</p>]]></content:encoded>
    </item>
    <item>
      <title>On Monolithic Repositories</title>
      <link>http://gregoryszorc.com/blog/2014/09/09/on-monolithic-repositories</link>
      <pubDate>Tue, 09 Sep 2014 10:00:00 PDT</pubDate>
      <category><![CDATA[Git]]></category>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2014/09/09/on-monolithic-repositories</guid>
      <description>On Monolithic Repositories</description>
      <content:encoded><![CDATA[<p>When companies or organizations deploy version control, they have to
make many choices. One of them is how many repositories to create.
Your choices are essentially a) a single, monolithic repository that
holds everything b) many separate, smaller repositories that hold
all the individual parts c) something in between.</p>
<p>The prevailing convention today (especially in the open source
realm) is to create many separate and loosely coupled repositories,
each repository mapping to a specific product or service. That does
seem reasonable: if you were organizing files on your filesystem,
you would group them by functionality or role (photos, music,
documents, etc). And, version control tools are functionally
filesystems. So it makes sense to draw repository boundaries at
directory/role levels.</p>
<p>Further reinforcing the separate repository convention is the
scaling behavior of our version control tools. Git, the popular
tool in open source these days, doesn't scale well to very large
repositories due to - among other things - not having narrow clones
(fetching a subset of files). It scales well enough to the
overwhelming majority of projects. But if you are a large
organization generating lots of data (read: gigabytes of data over
hundreds of thousands of files and commits) for version control,
Git is unsuitable in its current form. Other tools (like Mercurial)
don't currently fare that much better (although Mercurial has plans
to tackle these scaling vectors).</p>
<p>Despite popular convention and even limitations in tools, companies
like Google and Facebook opt to run large, monolithic repositories.
Google runs Perforce.
<a href="https://code.facebook.com/posts/218678814984400/scaling-mercurial-at-facebook/">Facebook is on Mercurial</a>,
or at least is in the process of migrating to Mercurial.</p>
<p>Why do these companies run monolithic repositories?
In <a href="http://www.perforce.com/sites/default/files/still-all-one-server-perforce-scale-google-wp.pdf">Google's words</a>:</p>
<p><em>We have a single large depot with almost all of Google's projects
on it. This aids agile development and is much loved by our users,
since it allows almost anyone to easily view almost any code, allows
projects to share code, and allows engineers to move freely from
project to project. Documentation and data is stored on the server
as well as code.</em></p>
<p>So, monolithic repositories are all about moving fast and getting things
done more efficiently. In other words, <strong>monolithic repositories
increase developer productivity.</strong></p>
<p>Furthermore, monolithic repositories are also more compatible with
the ebb and flow of large organizations and large software projects.
Components, features, products, and teams come and go, merge and split.
The only constant is change. And if you are maintaining separate
repositories that attempt to map to this ever-changing organizational
topology, you are going to have a bad time. Either you'll be
constantly copying, moving, merging, splitting, etc data and repositories.
Or your repositories will be organized in a very non-logical and
non-intuitive manner. That translates to overhead and lost productivity.
I think that monolithic repositories handle the realities of large
organizations much better. Big change or reorganization you want
to reflect? You can make a single, atomic, history-preserving commit
to move things around. I think that's much more manageable, especially
when you consider the difficulty and annoyance of history-preserving
changes across repositories.</p>
<p>Naysayers will decry monolithic repositories on principled and practical
grounds.</p>
<p>The principled camp will say that separate repositories
constitute a loosely coupled (dare I say service oriented) architecture
that maps better to how software is consumed, assembled, and deployed
and that erecting barriers in the form of separate repositories
deliberately enforces this architecture. I agree. However, you can
still maintain a loosely coupled architecture with monolithic
repositories. The Subversion model of checking out a single tree
<em>from a larger repository</em> proves this. Furthermore, I would say
architecture decisions should be enforced by people (via code review,
etc), not via version control repository topology. I believe this
principled argument against monolithic repositories to be rather weak.</p>
<p>The principled camp living in the open source realm may also decry
monolithic repositories as an affront to the spirit of open source.
They would say that a monolithic repository creates unfairly strong
ties to the organization that operates it and creates barriers to
forking, etc. This may be true. But monolithic repositories don't
intrinsically infringe on the
<a href="https://www.gnu.org/philosophy/free-sw.html">basic software freedoms</a>,
organizations do. Therefore, I find this principled argument rather
weak.</p>
<p>The practical camp will say that monolithic repositories just don't
scale or aren't suitable for general audiences. These concerns are
real.</p>
<p><em>Fully</em> distributed version control systems (every commit on every
machine) definitely don't scale past certain limits. Depending on your
repository and user base, your scaling limits include disk space
(repository data terabytes in size), bandwidth (repository data terabytes
in size), filesystem (repository hundreds of thousands or millions of
files), CPU and memory (operations on large repositories take too
many system resources), and many heads/branches (tools like Git and
Mercurial don't scale well to tens of thousands of heads/branches).
These limitations with fully distributed version
control are why distributed version control tools like Git and
Mercurial support a partially-distributed mode that behaves more like
your classical server-client model, like those employed by Subversion,
Perforce, etc. Git supports shallow clone and sparse checkout.
Mercurial supports shallow clone (via remotefilelog) and has planned
support for narrow clone and sparse checkout in the next release or
two. Of course, you can avoid the scaling limitations of distributed
version control by employing a non-distributed tool, such as Subversion.
Many companies continue to reach this conclusion today. However,
users adapted to the distributed workflow would likely be
up in arms (they would probably use tools like hg-subversion or git-svn
to maintain their workflows). So, while scaling of version control
can be a real concern, there are solutions and workarounds. However,
they do involve falling back to a partially-distributed model.</p>
<p>Another concern with monolithic repositories is user access control. You
inevitably have code or data that is more sensitive and want to limit
who can change or even access it. Separate repositories seem to
facilitate a simpler model: per-repository access control. With
monolithic repositories, you have to worry about per-directory/subtree
permissions, an increased risk of data leaking, etc. This concern is
more real with distributed version control, as distributed data and
access control aren't naturally compatible. But these issues can be
resolved. And if the tooling supports it, there is only a semantic
difference between managing access control between repositories versus
components of a single repository.</p>
<p>When it comes to repository hosting conversions, I agree with Google
and Facebook: <strong>I prefer monolithic repositories</strong>. When I am interacting
with version control, I just want to get stuff done. I don't want to
waste time dealing with multiple commands to manage multiple
repositories. I don't want to waste time or expend cognitive load
dealing with submodule, subrepository, or big files management. I
don't want to waste time trying to find and reuse code, data, or
documentation. I want everything at my fingertips, where it can be
easily discovered, inspected, and used. Monolithic repositories
facilitate these workflows more than separate repositories and make
me more productive as a result.</p>
<p>Now, if only all the tools and processes we use and love would work
with monolithic repositories...</p>]]></content:encoded>
    </item>
    <item>
      <title>Reproducing Mozilla's Mercurial Server</title>
      <link>http://gregoryszorc.com/blog/2014/09/05/reproducing-mozilla's-mercurial-server</link>
      <pubDate>Fri, 05 Sep 2014 14:50:00 PDT</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2014/09/05/reproducing-mozilla's-mercurial-server</guid>
      <description>Reproducing Mozilla's Mercurial Server</description>
      <content:encoded><![CDATA[<p>Of of my first tasks in my
<a href="/blog/2014/09/05/new-job-role/">new role</a> as a <em>Developer Productivity
Engineer</em> is to help make Mozilla's Mercurial server better. Many of the
awesome things we have planned rely on features in newer versions of
Mercurial. It's therefore important for us to upgrade our Mercurial
server to a modern version (we are currently running 2.5.4) and to keep
our Mercurial server upgraded as time passes.</p>
<p>There are a few reasons why we haven't historically upgraded our
Mercurial server. First, as anyone who has maintained high-availability
systems will tell you, there is the attitude of <em>if it isn't broken,
don't fix it.</em> In other words, Mercurial 2.5.4 is working fine, so why
mess with a good thing. This was all fine and dandy - until Mercurial
started falling over in the last few weeks.</p>
<p>But the blocker towards upgrading that I want to talk about today is
systems verification. There has been extreme caution around upgrading
Mercurial at Mozilla because it is a critical piece of Mozilla's
infrastructure and if the upgrade were to not go well, the outage
would be disastrous for developer productivity and could even jeopardize
an emergency Firefox release.</p>
<p>As much as I'd like to say that a modern version of Mercurial on the
server would be a drop-in replacement (Mercurial has a great committment
to backwards compatibility and has loose coupling between clients and
servers such that upgrading servers should not impact clients), there is
always a risk that something will change. And that risk is compounded by
the amount of custom code we have running on our server.</p>
<p>The way you protect against unexpected changes is testing. In the ideal
world, you have a robust test suite that you run against a staging
instance of a service to validate that any changes have no impact. In
the absence of testing, you are left with fear, uncertainty, and doubt.
FUD is an especially horrible philosophy when it comes to managing
servers.</p>
<p>Unfortunately, we don't really have a great testing infrastructure for
Mozilla's Mercurial server. And I want to change that.</p>
<h2>Reproducing the Server Environment</h2>
<p>When writing tests, it is important for the thing being tested to be as
similar as possible to the real thing. This is why so many people have
an aversion to mocking: every time you alter the test environment, you run
the risk that those differences from reality will mask changes seen in
the real environment.</p>
<p>So, it makes sense that a good first goal for creating a test suite against
our Mercurial server should be to reproduce the production server and
environment as closely as possible.</p>
<p>I'm currently working on a Vagrant environment that attempts to
reproduce the official environment as closely as possible. It starts
one virtual machine for the SSH/master server. It starts a separate
virtual machine for the hgweb/slave servers. The virtual machines are
booting CentOS. This is different than production, where we run RHEL.
But they are similar enough (and can share the same packages) that the
differences shouldn't matter too much, at least for now.</p>
<h2>Using Puppet</h2>
<p>In production, Mozilla is using Puppet to manage the Mercurial servers.
Unfortunately, the actual Puppet configs that Mozilla is running are
behind a firewall, mainly for security reasons. This is potentially
a huge setback for my reproducibility effort, as I'd like to have
my virtual machines use the same exact Puppet configs as whats used
in production so the environments match as closely as possible. This
would also save me a lot of work from having to reinvent the wheel.</p>
<p>Fortunately, Ben Kero has extracted the Mercurial-relevant Puppet
config files into a
<a href="https://github.com/bkero/puppet-module-hg">standalone repository</a>.
Apparently that repository gets rolled into the production Puppet
configs periodically. So, my virtual machines and production can share
the same Mercurial Puppet files. Nice!</p>
<p>It wasn't long after starting to use the standalone Puppet configs that
I realized this would be a rabbit hole. This first manifests in the
standalone Puppet code referencing things that exist in the hidden
Mozilla Puppet files. So the liberation was only partially successful.
Sad panda.</p>
<p>So, I'm now in the process of creating a <em>fake Mozilla</em> Puppet
environment that mimics the base Mozilla environment (from the closed
repo) and am modifying the shared Puppet Mercurial code to work with
both versions. This is a royal pain, but it needs to be done if we want
to reproduce production and maintain peace of mind that test results
reflect reality.</p>
<p>Because reproducing runtime environments is important for reproducing
and solving bugs and for testing, <strong>I call on the maintainers of
Mozilla's closed Puppet repository to liberate it from behind its
firewall</strong>. I'd like to see a public Puppet configuration tree available
for all to use so that anyone anywhere can reproduce the state of a
server or service operated by Mozilla to within reasonable
approximation. Had this already been done, it would have saved me hours
of work. As it stands, I'm reverse engineering systems and trying to
cobble together understanding of how the Mozilla Puppet configs
work and what parts of them can safely be ignored to reproduce an
approximate testing environment.</p>
<p>Along that vein, I finally got access to Mozilla's internal Puppet
repository. This took a few meetings and apparently a lot of
backroom chatter was generated - "developer's don't normally get access,
oh my!" All I wanted was to see how systems are configured so I can
help improve them. Instead, getting access felt like pulling teeth.
This feels like a major roadblock towards productivity, reproducibility,
and testing.</p>
<p>Facebook gives its developers access to most production machines and
trusts them to not be stupid. I know we (Mozilla) like to hold
ourselves to a high standard of security and privacy. But not giving
developers access to the configurations for the systems their code
runs on feels like a very silly policy. I hope Mozilla invests in
opening up this important code and data, if not to the world, at least
to its trusted employees.</p>
<p>Anyway, hopefully I'll soon have a Vagrant environment that allows
people to build a standalone instance of Mozilla's Mercurial server.
And once that's in place, I can start writing tests that basic services
and workflows (including repository syncing) work as expected. Stay
tuned.</p>]]></content:encoded>
    </item>
    <item>
      <title>Submit Feedback about Mercurial</title>
      <link>http://gregoryszorc.com/blog/2014/08/19/submit-feedback-about-mercurial</link>
      <pubDate>Tue, 19 Aug 2014 18:30:00 PDT</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2014/08/19/submit-feedback-about-mercurial</guid>
      <description>Submit Feedback about Mercurial</description>
      <content:encoded><![CDATA[<p>Are you a Mozillian who uses Mercurial? Do you have a complaint,
suggestion, observation, or any other type of feedback you'd like
to give to the maintainers of Mercurial? Now's your chance.</p>
<p>There is a large gathering of Mercurial contributors next weekend
in Munich. The
<a href="http://mercurial.selenic.com/wiki/3.2sprint#Possible_Topics">topics list</a>
is already impressive. But Mozilla's <em>delegation</em> (Mike Hommey,
Ben Kero, and myself) would love to advance Mozilla's concerns to
the wider community.</p>
<p>To leave or vote for feedback, please visit
<a href="https://hgfeedback.paas.allizom.org/e/august-2014-summit">https://hgfeedback.paas.allizom.org/e/august-2014-summit</a>
before August 29 so your voice may be heard.</p>
<p>I encourage you to leave feedback about any small, big or small,
Mozilla-specific or not. Comparisons to Git, GitHub and other
version control tools and services are also welcome.</p>
<p>If you have feedback that can't be captured in that moderator tool,
please email me. gps@mozilla.com.</p>]]></content:encoded>
    </item>
    <item>
      <title>Mercurial hooks move and testing Mercurial</title>
      <link>http://gregoryszorc.com/blog/2014/08/18/mercurial-hooks-move-and-testing-mercurial</link>
      <pubDate>Mon, 18 Aug 2014 15:10:00 PDT</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2014/08/18/mercurial-hooks-move-and-testing-mercurial</guid>
      <description>Mercurial hooks move and testing Mercurial</description>
      <content:encoded><![CDATA[<p>Mozilla has a number of source repositories under
<a href="https://hg.mozilla.org/hgcustom/">https://hg.mozilla.org/hgcustom/</a>
that cumulatively define how version control works at Mozilla.</p>
<p>Back in February, I
<a href="/blog/2014/02/05/new-repository-for-mozilla-version-control-tools/">launched an effort</a>
to establish a unified Mercurial repository for all this code. That
repository is <a href="https://hg.mozilla.org/hgcustom/version-control-tools/">version-control-tools</a>
and it has slowly grown.</p>
<p>The <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1052201">latest addition</a>
to this repository is the import of the <em>hghooks</em> repository. This
now-defunct repository contained all the server-side Mercurial hooks
that Mozilla has deployed on <em>hg.mozilla.org</em>.</p>
<p>Soon after that repository was imported into version-control-tools, we
started executing the hooks tests as part of the existing test suite in
version-control-tools. This means we get
<a href="https://ci.mozilla.org/job/version-control-tools/">continuous integration</a>,
<a href="https://ci.mozilla.org/job/version-control-tools/coveragepy/?">code coverage</a>,
and the ability to run tests against multiple versions of Mercurial
(2.5.4 through 3.1) in one go.</p>
<p><strong>This is new for Mozilla and is a big deal.</strong> For the first time, we
have a somewhat robust testing environment for Mercurial that is testing
things we run in production.</p>
<p>But we still have a long way to go. The ultimate goal is to get everything
rolled into the version-control-tools repository and to write tests for
everything people rely on. We also want the test environment to look as
much like our production environment as possible. Once that's in place,
most of the fear and uncertainty around upgrading or changing the server
goes away. This will allow Mozilla to move faster and issues like our
recent server problems can be diagnosed more quickly (Mercurial has
added better logging in newer versions).</p>
<p>If you want to contribute to this effort, <strong>please write tests for
behavior you rely on.</strong> We're now relying on Mercurial's test harness
and <a href="http://mercurial.selenic.com/wiki/WritingTests">test types</a>
rather than low-level unit tests. This means our tests are now running
a Mercurial server and running actual Mercurial commands. The tests thus
explicitly verify that client-seen behavior is exactly as you intend.
For an example, see the
<a href="https://hg.mozilla.org/hgcustom/version-control-tools/file/abc1c5bdca9b/hghooks/tests/test-prevent-webidl.t">WebIDL hook test</a>.</p>
<p>So what are you waiting for? Find some gaps in code coverage and write
some tests today!</p>]]></content:encoded>
    </item>
    <item>
      <title>Please run mach mercurial-setup</title>
      <link>http://gregoryszorc.com/blog/2014/07/25/please-run-mach-mercurial-setup</link>
      <pubDate>Fri, 25 Jul 2014 10:00:00 PDT</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2014/07/25/please-run-mach-mercurial-setup</guid>
      <description>Please run mach mercurial-setup</description>
      <content:encoded><![CDATA[<p>Hey there, Firefox developer! Do you use Mercurial? Please take the time
right now to run <strong>mach mercurial-setup</strong> from your Firefox clone.</p>
<p>It's been updated to ensure you are running a modern Mercurial version.
More awesomely, it has support for a couple of new extensions to make
you more productive. I think you'll like what you see.</p>
<p><strong>mach mercurial-setup</strong> doesn't change your <em>hgrc</em> without
confirmation. So it is safe to run to see what's available. You should
consider running it periodically, say once a week or so. I wouldn't
be surprised if we add a notification to mach to remind you to do this.</p>]]></content:encoded>
    </item>
    <item>
      <title>Repository-Centric Development</title>
      <link>http://gregoryszorc.com/blog/2014/07/24/repository-centric-development</link>
      <pubDate>Thu, 24 Jul 2014 20:23:00 PDT</pubDate>
      <category><![CDATA[Git]]></category>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2014/07/24/repository-centric-development</guid>
      <description>Repository-Centric Development</description>
      <content:encoded><![CDATA[<p>I was editing a wiki page yesterday and I think I coined a new term
which I'd like to enter the common nomenclature: <em>repository-centric
development</em>. The term refers to development/version control
workflows that place repositories - not patches - first.</p>
<p>When collaborating on version controlled code with modern tools like
Git and Mercurial, you essentially have two choices on how to
share version control data: patches or repositories.</p>
<p>Patches have been around since the dawn of version control. Everyone
knows how they work: your version control system has a copy of
the canonical data and it can export a view of a specific change
into what's called a patch. A patch is essentially a diff with
extra metadata.</p>
<p>When distributed version control systems came along, they brought
with them an alternative to patch-centric development:
repository-centric development. You could still exchange patches if you
wanted, but distributed version control allowed you to <em>pull</em> changes
directly from multiple <em>repositories</em>. You weren't limited to a single
master server (that's what the <em>distributed</em> in <em>distributed version
control</em> means). You also didn't have to go through an intermediate
transport such as email to exchange patches: you communicate directly
with a peer repository instance.</p>
<p>Repository-centric development eliminates the <em>middle man</em> required
for patch exchange: instead of exchanging derived data, you exchange
the actual data, speaking the repository's native language.</p>
<p>One advantage of repository-centric development is it eliminates the
problem of patch non-uniformity. Patches come in many different flavors.
You have plain diffs. You have diffs with metadata. You have Git style
metadata. You have Mercurial style metadata. You can produce patches
with various lines of context in the diff. There are different methods
for handling binary content. There are different ways to express
file adds, removals, and renames. It's all a hot mess. Any system
that consumes patches needs to deal with the non-uniformity. Do you
think this isn't a problem in the real world? Think again. If you are
involved with an open source project that collects patches via email
or by uploading patches to a bug tracker, have you ever seen someone
accidentally upload a patch in the wrong format? That's patch
non-uniformity. New contributors to Firefox do this all the time. I
also see it in the Mercurial project. With repository-centric
development, patches never enter the picture, so patch non-uniformity
is a non-issue. (Don't confuse the superficial formatting of patches
with the content, such as an incorrect commit message format.)</p>
<p>Another advantage of repository-centric development is it makes the
act of exchanging data easier. Just have two repositories talk to
each other. This used to be difficult, but hosting services like
GitHub and Bitbucket make this easy. Contrast with patches, which
require hooking your version control tool up to wherever those patches
are located. The Linux Kernel, like so many other projects,
<a href="https://www.kernel.org/doc/Documentation/SubmittingPatches">uses email for contributing changes</a>.
So now Git, Mercurial, etc all fulfill Zawinski's law. This means your
version control tool is talking to your inbox to send and receive code.
Firefox development uses Bugzilla to hold patches as attachments. So now your
version control tool needs to talk to your issue tracker. (Not the worst
idea in the world I will concede.) While, yes, the tools around using
email or uploading patches to issue trackers or whatever else you are
using to exchange patches exist and can work pretty well, the grim
reality is that these tools are all reinventing the wheel of repository
exchange and are solving a problem that has already been solved by
<em>git push</em>, <em>git fetch</em>, <em>hg pull</em>, <em>hg push</em>, etc. Personally, I would
rather <em>hg push</em> to a remote and have tools like issue trackers and
mailing lists pull directly from repositories. At least that way they
have a direct line into the source of truth and are guaranteed a
consistent output format.</p>
<p>Another area where direct exchange is huge is multi-patch commits
(<em>branches</em> in Git parlance) or where commit data is fragmented. When
pushing patches to email, you need to insert metadata saying which patch
comes after which. Then the email import tool needs to reassemble things
in the proper order (remember that the typical convention is one email
per patch and email can be delivered out of order). Not the most
difficult problem in the world to solve. But seriously, it's been
solved already by <em>git fetch</em> and <em>hg pull</em>! Things are worse for
Bugzilla. There is no bullet-proof way to order patches there. The
convention at Mozilla is to add <em>Part N</em> strings to
commit messages and have the Bugzilla import tool do a sort (I assume it
does that). But what if you have a logical commit series spread across
multiple bugs? How do you reassemble everything into a linear series of
commits? You don't, sadly. Just today I wanted to apply a somewhat
complicated series of patches to the Firefox build system I was asked to
review so I could jump into a debugger and see what was going on so I
could conduct a more thorough review. There were 4 or 5 patches spread
over 3 or 4 bugs. Bugzilla and its patch-centric workflow prevented me
from importing the patches. Fortunately, this patch series was pushed to
Mozilla's Try server, so I could pull from there. But I haven't always
been so fortunate. This limitation means developers have to make
sacrifices such as writing fewer, larger patches (this makes code review
harder) or involving unrelated parties in the same bug and/or review.
In other words, deficient tools are imposing limited workflows. No bueno.</p>
<p>It is a fair criticism to say that not everyone can host a server or
that permissions and authorization are hard. Although I think concerns
about impact are overblown. If you are a small project, just create a
GitHub or Bitbucket account. If you are a larger project, realize that
people time is one of your largest expenses and invest in tools like
proper and efficient repository hosting (often this can be GitHub) to
reduce this waste and keep your developers happier and more efficient.</p>
<p>One of the clearest examples of repository-centric development is
GitHub. There are no patches in GitHub. Instead, you <em>git push</em>
and <em>git fetch</em>. Want to apply someone else's work? Just add a remote
and <em>git fetch</em>! Contrast with first locating patches, hooking up
Git to consume them (this part was always confusing to me - do you
need to retroactively have them sent to your email inbox so you can
import them from there), and finally actually importing them. Just
give me a URL to a repository already. But the benefits of
repository-centric development with GitHub don't stop at pushing and
pulling. GitHub has built code review functionality into pushes. They
call these <em>pull requests</em>. While I have significant issues with
GitHub's implemention of pull requests (I need to blog about those some
day), I can't deny the utility of the repository-centric workflow and
all the benefits around it. Once you switch to GitHub and its
repository-centric workflow, you more clearly see how lacking
patch-centric development is and quickly lose your desire to go back
to the 1990's state-of-the-art methods for software development.</p>
<p>I hope you now know what repository-centric development is and will join
me in championing it over patch-based development.</p>
<p>Mozillians reading this will be very happy to learn that work is under
way to shift Firefox's development workflow to a more repository-centric
world. Stay tuned.</p>]]></content:encoded>
    </item>
    <item>
      <title>Updates to firefoxtree Mercurial extension</title>
      <link>http://gregoryszorc.com/blog/2014/07/16/updates-to-firefoxtree-mercurial-extension</link>
      <pubDate>Wed, 16 Jul 2014 19:55:00 PDT</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2014/07/16/updates-to-firefoxtree-mercurial-extension</guid>
      <description>Updates to firefoxtree Mercurial extension</description>
      <content:encoded><![CDATA[<p>My <a href="/blog/2014/06/23/please-stop-using-mq/">Please Stop Using MQ</a> post,
has been generating a lot of interest for bookmark-based workflows at
Mozilla. To make adoption easier, I
<a href="/blog/2014/06/30/track-firefox-repositories-with-local-only-mercurial-tags/">quickly authored</a>
an <a href="https://hg.mozilla.org/hgcustom/version-control-tools/file/default/hgext/firefoxtree/__init__.py">extension</a>
to add <em>remote refs</em> of Firefox repositories to Mercurial.</p>
<p>There was still a bit of confusion and gripes about workflows that I
thought it would be best to update the extension to make things more
pleasant.</p>
<h2>Automatic tree names</h2>
<p>People wanted an ability to easy pull/aggregate the various Firefox
trees without additional configuration to an hgrc file.</p>
<p>With <em>firefoxtree</em>, you can now <em>hg pull central</em> or <em>hg pull inbound</em>
or <em>hg pull aurora</em> and it just works.</p>
<p>Pushing with aliases doesn't yet work. It is slightly harder to do in
the Mercurial API. I have a solution, but I'm validating some code paths
to ensure it is safe. This feature will likely appear soon.</p>
<h2>fxheads commands</h2>
<p>Once people adopted unified repositories with heads from multiple
repositories, they asked how they could quickly identify the heads of
the pulled Firefox repositories.</p>
<p><em>firefoxtree</em> now provides a <em>hg fxheads</em> command that prints a
concise output of the commits constituting the heads of the Firefox
repos. e.g.</p>
<div class="pygments_murphy"><pre>$ hg fxheads
224969:0ec0b9ac39f0 aurora (sort of) bug 898554 - raise expected hazard count for b2g to 4 until they are fixed, a=bustage+hazbuild-only
224290:6befadcaa685 beta Tagging /src/mdauto/build/mozilla-beta 1772e55568e4 with FIREFOX_RELEASE_31_BASE a=release CLOSED TREE
224848:8e8f3ba64655 central Merge inbound to m-c a=merge
225035:ec7f2245280c fx-team fx-team/default Merge m-c to fx-team
224877:63c52b7ddc28 inbound Bug 1039197 - Always build js engine with zlib. r=luke
225044:1560f67f4f93 release release/default tip Automated checkin: version bump for firefox 31.0 release. DONTBUILD CLOSED TREE a=release
</pre></div>

<p>Please note that the output is based upon local-only knowledge: you'll
need to pull to ensure data is current.</p>
<h2>Reject pushing multiple heads</h2>
<p>People were complaining that bookmark-based workflows resulted in
Mercurial trying to push multiple heads to a remote. This complaint
stems from the fact that Mercurial's default push behavior is to find
all commits missing from the remote and push them. This behavior is
extremely frustrating for Firefox development because the Firefox repos
only have a single head and pushing multiple heads will only result in
a server hook rejecting the push (after wasting a lot of time
transferring that commit data).</p>
<p><em>firefoxtree</em> now will refuse to push multiple heads to a known Firefox
repo before any commit data is sent. In other words, we fail fast so
your time is saved.</p>
<p><em>firefoxtree</em> also changes the default behavior of <em>hg push</em> when
pushing to a Firefox repo. If no <em>-r</em> argument is specified, <em>hg push</em>
to a Firefox repo will automatically remap to <em>hg push -r .</em>. In other
words, we attempt to push the working copy's commit by default. This
change establishes sensible default and likely working behavior when
typing just <em>hg push</em>.</p>
<p>I am a bit on the fence about changing the default behavior of <em>hg
push</em>. On one hand, it makes total sense. On the other, silently
changing the default behavior of a built-in command is a little
dangerous. I can easily see this backfiring when people interact with
non-Firefox repos. I encourage people to get in the habit of typing
<em>hg push -r <rev></em> because that's what you should be doing.</p>
<h2>Installing firefoxtree</h2>
<p>Within the next 48 hours, <em>mach mercurial-setup</em> should prompt to
install <em>firefoxtree</em>. Until then, clone
<em>https://hg.mozilla.org/hgcustom/version-control-tools</em> and ensure your
<em>~/.hgrc</em> file has the following:</p>
<pre><code>[extensions]
firefoxtree = /path/to/version-control-tools/hgext/firefoxtree
</code></pre>
<p>You likely already have a copy of version-control-tools
in <em>~/.mozbuild/version-control-tools</em>.</p>
<p>It is completely safe to install <em>firefoxtree</em> globally: the extension
will only modify behavior of repositories that are clones of Firefox
repositories.</p>]]></content:encoded>
    </item>
    <item>
      <title>Update Bugzilla Automatically on Push</title>
      <link>http://gregoryszorc.com/blog/2014/06/30/update-bugzilla-automatically-on-push</link>
      <pubDate>Mon, 30 Jun 2014 23:15:00 PDT</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2014/06/30/update-bugzilla-automatically-on-push</guid>
      <description>Update Bugzilla Automatically on Push</description>
      <content:encoded><![CDATA[<p>Do you manually create Bugzilla comments when you push changes to a
Firefox source repository? Yeah, I do too.</p>
<p>That's always annoyed me.</p>
<p>It is screaming to be automated.</p>
<p>So I automated it.</p>
<p>You can too. From a Firefox source checkout:</p>
<p>$ ./mach mercurial-setup</p>
<p>That should clone the
<a href="https://hg.mozilla.org/hgcustom/version-control-tools/">version-control-tools</a>
repository into <em>~/.mozbuild/version-control-tools</em>.</p>
<p>Then, add the following to your <em>~/.hgrc</em> file:</p>
<div class="pygments_murphy"><pre><span class="k">[extensions]</span>
<span class="na">bzpost</span> <span class="o">=</span> <span class="s">~/.mozbuild/version-control-tools/hgext/bzpost</span>

<span class="k">[bugzilla]</span>
<span class="na">username</span> <span class="o">=</span> <span class="s">me@example.com</span>
<span class="na">password</span> <span class="o">=</span> <span class="s">password</span>
</pre></div>

<p>Now, when you <em>hg push</em> to a Firefox repository, the commit URLs will
get posted to referenced bugs automatically.</p>
<p>Please note that pushing to <em>release</em> trees such as mozilla-central is
not yet supported. In due time.</p>
<p>Please let me know if you run into any issues.</p>
<h2>Estimated Cost Savings</h2>
<p>Assuming the following:</p>
<ul>
<li>It costs Mozilla $200,000 per year per full-time engineer working on
  Firefox (a general rule of thumb for non-senior positions is that your
  true employee cost is 2x your base salary).</li>
<li>Each full-time engineer works 40 hours per week for 46 weeks out of
  the year.</li>
<li>It takes 15 seconds to manually update Bugzilla for each push.</li>
<li>There are 20,000 pushes requiring Bugzilla attention per year.</li>
</ul>
<p>We arrive at the following:</p>
<ul>
<li>Cost per employee per hour worked: $108.70</li>
<li>Total person-time to manually update Bugzilla: ~83 hours</li>
<li>Total cost to manually update Bugzilla after push: $9,058.</li>
</ul>
<p>I was intentionally conservative with all the inputs except time
worked (I think many of us work more than 40 hour weeks).
My estimates also don't take into account the lost productivity
associated with getting mentally derailed by interacting with Bugzilla.
With this in mind, I could very easily justify a total cost at
least 2x-3x higher.</p>
<p>It took me maybe 3 hours to crank this out. I could spend another few
weeks on it full time and Mozilla would still save money (assuming
100% adoption).</p>
<p>I encourage people to run their own cost calculations on other tasks
that can be automated. Inefficiencies multiplied by millions of dollars
(your collective employee cost) result in large piles of money. Not
having tools (even simple ones like this) is equivalent to setting
loads of cash on fire.</p>]]></content:encoded>
    </item>
  </channel>
</rss>

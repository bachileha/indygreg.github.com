<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:wfw="http://wellformedweb.org/CommentAPI/"
     >
  <channel>
    <title>Gregory Szorc's Digital Home</title>
    <link>http://gregoryszorc.com/blog</link>
    <description>Rambling on</description>
    <pubDate>Wed, 13 Nov 2013 17:23:23 GMT</pubDate>
    <generator>Blogofile</generator>
    <sy:updatePeriod>hourly</sy:updatePeriod>
    <sy:updateFrequency>1</sy:updateFrequency>
    <item>
      <title>Importance of Hosting Your Version Control Server</title>
      <link>http://gregoryszorc.com/blog/2013/11/13/importance-of-hosting-your-version-control-server</link>
      <pubDate>Wed, 13 Nov 2013 09:25:00 PST</pubDate>
      <category><![CDATA[Git]]></category>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2013/11/13/importance-of-hosting-your-version-control-server</guid>
      <description>Importance of Hosting Your Version Control Server</description>
      <content:encoded><![CDATA[<p>The subject of where to host version control repositories comes up a lot
at Mozilla. It takes many forms:</p>
<ul>
<li>We should move the Firefox repository to GitHub</li>
<li>I should be allowed to commit to GitHub</li>
<li>I want the canonical repository to be hosted by Bitbucket</li>
</ul>
<p>When Firefox development is concerned, Release Engineerings puts down
their foot and insists the canonical repository be hosted by Mozilla,
under a Mozilla hostname. When that's not possible, they set up a mirror
on Mozilla infrastructure.</p>
<p>I think a
<a href="https://groups.google.com/d/topic/jenkinsci-dev/-myjRIPcVwU/discussion">recent issue with the Jenkins project</a>
demonstrates why hosting your own version control server is important.
The gist is someone force pushed to a bunch of repos hosted on GitHub.
They needed to involve GitHub support to recover from the issue. While
it appears they largely recovered (and GitHub support deserves kudos - I
don't want to take away from their excellence), this problem would have
been avoided or the response time significantly decreased if the Jenkins
people had direct control over the Git server: they either could have
installed a custom hook that would have prevented the pushes or had
access to the reflog so they could have easily seen the last pushed
revision and easily forced pushed back to it. GitHub doesn't have a
mechanism for defining pre-* hooks, doesn't allow defining custom
hooks (a security and performance issue for them), and doesn't
expose the reflog data.</p>
<p>Until repository hosting services expose full repository data (such as
reflogs) and allow you to define custom hooks, accidents like these will
happen and the recovery time will be longer than if you hosted the repo
yourself.</p>
<p>It's possible repository hosting services like GitHub and Bitbucket will
expose these features or provide a means to quickly recover. If so,
kudos to them. But larger, more advanced projects will likely employ
custom hooks and considering custom hooks are a massive security and
performance issue for any hosted service provider, I'm not going to
hold my breath this particular feature is rolled out any time soon.
This is unfortunate, as it makes projects seemingly choose between
low risk/low convenience and GitHub's vibrant developer community.</p>]]></content:encoded>
    </item>
    <item>
      <title>Mercurial 2.8 released</title>
      <link>http://gregoryszorc.com/blog/2013/11/08/mercurial-2.8-released</link>
      <pubDate>Fri, 08 Nov 2013 14:30:00 PST</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2013/11/08/mercurial-2.8-released</guid>
      <description>Mercurial 2.8 released</description>
      <content:encoded><![CDATA[<p><a href="http://mercurial.selenic.com/">Mercurial</a> 2.8 has been released.</p>
<p>The <a href="http://mercurial.selenic.com/wiki/WhatsNew#Mercurial_2.8_.282013-11-1.29">changes</a>
aren't as sexy as previous releases. But there are a handful of bug
fixes that seem useful to pull in. People may also find the new <em>shelve</em>
extension useful.</p>
<p>I encourage Mozillians to keep their Mercurial up to date. I once went
around the San Francisco office and stood behind people as they
upgraded to a modern Mercurial. For the next few weeks I was hearing a
lot of "OMG Mercurial is so much better now." Don't handicap yourself by
running an older, buggy Mercurial.</p>
<p>If you don't yet feel comfortable running 2.8, 2.7 should be safe.</p>]]></content:encoded>
    </item>
    <item>
      <title>Using Mercurial to query Mozilla metadata</title>
      <link>http://gregoryszorc.com/blog/2013/11/08/using-mercurial-to-query-mozilla-metadata</link>
      <pubDate>Fri, 08 Nov 2013 09:42:00 PST</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2013/11/08/using-mercurial-to-query-mozilla-metadata</guid>
      <description>Using Mercurial to query Mozilla metadata</description>
      <content:encoded><![CDATA[<p>I have updated my
<a href="https://hg.mozilla.org/users/gszorc_mozilla.com/hgext-gecko-dev">Mercurial extension tailored for Gecko/Firefox development</a>
with features that support rich querying of Mozilla/Gecko-development
specific metadata!</p>
<p>The extension now comes with a bug full of
<a href="http://www.selenic.com/hg/help/revsets">revision set</a> selectors and
<a href="http://www.selenic.com/hg/help/templates">template keywords</a>. You can
use them to query and format Mozilla-central metadata from the
repository.</p>
<h2>Revision set selectors</h2>
<p>You can now select changesets referencing a specific bug number:</p>
<pre><code>hg log -r 'bug(931383)'
</code></pre>
<p>Or that were reviewed by a specific person:</p>
<pre><code>hg log -r 'reviewer(gps)'
</code></pre>
<p>Or were reviewed or not reviewed:</p>
<pre><code>hg log -r 'reviewed()'
hg log -r 'not reviewed()'
</code></pre>
<p>You can now select changesets that are present in a specific tree:</p>
<pre><code>hg log -r 'tree(central)'
</code></pre>
<p>I've also introduced support to query changesets <em>you</em> influenced:</p>
<pre><code>hg log -r 'me()'
</code></pre>
<p>(This finds changesets you authored or reviewed.)</p>
<p>You can select changesets that initially landed on a specific tree:</p>
<pre><code>hg log -r 'firstpushtree(central)'
</code></pre>
<p>You can select changesets marked as <em>DONTBUILD</em>:</p>
<pre><code>hg log -r 'dontbuild()'
</code></pre>
<p>You can select changesets that don't reference a bug:</p>
<pre><code>hg log -r 'nobug()'
</code></pre>
<p>You can select changesets that were <em>push heads</em> for a tree:</p>
<pre><code>hg log -r 'pushhead(central)'
</code></pre>
<p>(This would form the basis of a push-aware bisection tool - an excellent
idea for a future feature in this extension.)</p>
<p>You can combine these revset selector functions with other revset
selectors to do some pretty powerful things.</p>
<p>To select all changesets on inbound but not central:</p>
<pre><code>hg log -r 'tree(inbound) - tree(central)'
</code></pre>
<p>To find all your contributions on beta but not release:</p>
<pre><code>hg log -r 'me() &amp; (tree(beta) - tree(release))'
</code></pre>
<p>To find all changesets referencing a specific bug that have landed in
Aurora:</p>
<pre><code>hg log -r 'bug(931383) and tree(aurora)'
</code></pre>
<p>To find all changesets marked <em>DONTBUILD</em> that landed directly on central:</p>
<pre><code>hg log -r 'dontbuild() and firstpushtree(central)'
</code></pre>
<p>To find all non-merge changesets that don't reference a bug:</p>
<pre><code>hg log -r 'not merge() and nobug()'
</code></pre>
<p>Neato!</p>
<h2>Template keywords</h2>
<p>You can also now print some Mozilla information when using templates.</p>
<p>To print the main bug of a changeset, use:</p>
<pre><code>{bug}
</code></pre>
<p>To retrieve all referenced bugs:</p>
<pre><code>{bugs} {join(bugs, ', ')}
</code></pre>
<p>To print the reviewers:</p>
<pre><code>{reviewer} {join(reviewers, ', ')}
</code></pre>
<p>To print the first version a changeset appeared in a specific channel:</p>
<pre><code>{firstrelease} {firstbeta} {firstaurora} {firstnightly}
</code></pre>
<p>To print the <strong>estimated</strong> first Aurora and Nightly date for a
changeset, use:</p>
<pre><code>{auroradate} {nightlydate}
</code></pre>
<p>(Getting the exact first Aurora and Nightly dates requires consulting
3rd party services, which we don't currently do. I'd like to
eventually integrate these into the extension. For now, it just
estimates dates from the pushlog data.)</p>
<p>You can also print who and where pushed a changeset:</p>
<pre><code>{firstpushuser} {firstpushtree}
</code></pre>
<p>You can also print the TBPL URL with the results of the first push:</p>
<pre><code>{firstpushtbpl}
</code></pre>
<p>Here is an example that prints channel versions and dates for each
changesets:</p>
<pre><code>hg log --template '{rev} Nightly: {firstnightly} {nightlydate}; Aurora {firstaurora} {auroradate}; Beta: {firstbeta}; Release: {firstrelease}\n'
</code></pre>
<h2>Putting it all together</h2>
<p>Of course, you can combine selectors and templates to create some
mighty powerful queries.</p>
<p>To look at your impact on Mozilla, do something like:</p>
<pre><code>hg log --template '{rev} Bug {bug}; Release {firstrelease}\n' -r 'me()'
</code></pre>
<p>You can easily forumate a status report for your activity in the past
week:</p>
<pre><code>hg log --template '{firstline(desc)}\n' -r 'firstpushdate(-7) and me()'
</code></pre>
<p>You can also query Mercurial to see where changesets have been landing
in the past 30 days:</p>
<pre><code>hg log --template '{firstpushtree}\n' -r 'firstpushdate(-30)' | sort | uniq -c
</code></pre>
<p>You can see who has been reviewing lots of patches lately:</p>
<pre><code>hg log --template '{join(reviewers, "\n")}\n' -r 'firstpushdate(-30)' | sort | uniq -c | sort -n
</code></pre>
<p>(smaug currently has the top score, edging out my 116 reviews with 137.)</p>
<p>If you want to reuse templates (instead of having to type them on the
command line), you can save them as <em>style files</em>. Search
<a href="https://www.google.com/search?q=mercurial+style+files">the Internets</a>
to learn how to use them. You can even change your default style so
the default output from <em>hg log</em> contains everything you'd ever want to
know about a changeset!</p>
<h2>Keeping it running</h2>
<p>Many of the queries rely on data derived from multiple repositories and
pushlog data that is external to the repository.</p>
<p>To get best results, you'll need to be running a monolithic/unified
Mercurial repository. You can either assemble one locally with this
extension by periodically pulling from the separate repos:</p>
<pre><code>hg pull releases
hg pull integration
</code></pre>
<p>Or, you can pull from
<a href="http://hg.gregoryszorc.com/gecko">my personal unified repo</a>.</p>
<p>You will also need to ensure the pushlog data is current. If you pull
directly from the official repos, this will happen automatically. To be
sure, run:</p>
<pre><code>hg pushlogsync
</code></pre>
<p>Finally, you can force a repopulation of cached bug data by running:</p>
<pre><code>hg buginfo --reset
</code></pre>
<p>Over time, I want all this to automagically work. Stay tuned.</p>
<h2>Comments and future improvements</h2>
<p>I implemented this feature to save myself from having to go troving
through Bugzilla and repository history to answer questions and to
obtain metrics. I can now answer many questions via simple Mercurial
one-liners.</p>
<p>Custom revision set selectors and template keywords are a pretty nifty
feature of Mercurial. They demonstrate how you can extend Mercurial to
be aware of more than just tracking commits and files. As I've
<a href="/blog/2013/05/12/thoughts-on-mercurial-%28and-git%29/">said before</a>
and will continue to say, the extensibility of Mercurial is
really its killer feature, especially for organizations with
well-defined processes (like Mozilla). The kind of extensibility I
achieved with this extension with custom queries and formatting
functions is just not possible with Git (at least not with the reference
C implementation that the overwhelming majority of Git users use).</p>
<p>There are numerous improvements that can be made to the extension.
Obviously more revision set selectors and template keywords can be
added. The parsing routine to extract bugs and reviewers isn't the most
robust in the world. I copied some existing Mozilla code. It does well
at detecting string patters but doesn't cope well with extracting lists.</p>
<p>I'd also love to better integrate Mercurial with automation
results so you can do things like expose a <em>greenpush()</em> selector and do
things like <em>hg up -r 'last(tree(inbound)) and greenpush()'</em> (which
of course could be exposed as <em>lastgreen(inbound)</em>. Wouldn't
that be cool! (This would be possible if we had better APIs for querying
individual push results.) It would also be possible to have the
Mercurial server expose this data as repository data so clients pull it
automatically. That would prevent clients from all needing to query the
same 3rd party services. Just a crazy thought.</p>
<p>Speed can be an issue. Calculating the release information
(<em>{firstnightly}</em> etc) is currently slower than I'd like. This is mostly
due to me using inefficient algorithms and not caching things where I
should. Speed issues should be fixed in due time.</p>
<p>Please let me know if you run into any problems or have suggestions for
improvements. If you want to implement your own revision set selectors
or template keywords, it's <a href="https://hg.mozilla.org/users/gszorc_mozilla.com/hgext-gecko-dev/file/35bb3c96d786/__init__.py#l705">easier</a>
than you think! I will happily accept patches. Keep in mind that
Mercurial can integrate with 3rd party services. So if you want to
supplement repository data with data from a HTTP+JSON web service,
that's very doable. The sky is the limit.</p>]]></content:encoded>
    </item>
    <item>
      <title>MacBook Pro Firefox Build Times Comparison</title>
      <link>http://gregoryszorc.com/blog/2013/11/05/macbook-pro-firefox-build-times-comparison</link>
      <pubDate>Tue, 05 Nov 2013 10:00:00 PST</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <category><![CDATA[build system]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2013/11/05/macbook-pro-firefox-build-times-comparison</guid>
      <description>MacBook Pro Firefox Build Times Comparison</description>
      <content:encoded><![CDATA[<p>Many developers use MacBook Pros for day-to-day Firefox development.
So, I thought it would be worthwhile to perform a comparison of
Firefox build times for various models of MacBook Pros.</p>
<h2>Test setup</h2>
<p>The numbers in this post are obtained from 3 generations of MacBook
Pros:</p>
<ol>
<li>
<p>A 2011 Sandy Bridge 4 core x 2.3 GHz with 8 GB RAM and an aftermarket
   SSD.</p>
</li>
<li>
<p>A 2012 Ivy Bridge retina with 4 core x 2.6 GHz, 16 GB RAM, and a
   factory SSD (or possibly flash storage).</p>
</li>
<li>
<p>A 2013 Haswell retina with 4 core x 2.6 GHz, 16 GB RAM, and flash
   storage.</p>
</li>
</ol>
<p>All machines were running OS X 10.9 Mavericks and were using the
Xcode 5.0.1 toolchain (<em>Xcode 5 clang: Apple LLVM version 5.0
(clang-500.2.79) (based on LLVM 3.3svn)</em>) to build.</p>
<p>The power settings prevented machine sleep and machines were plugged
into A/C power during measuring. I did not use the machines while
obtaining measurements.</p>
<p>The 2012 and 2013 machines were very vanilla OS installs. However,
the 2011 machine was my primary work computer and may have had a
few background services running and may have been slower due to
normal wear and tear. The 2012 machine was a loaner machine from
IT and has an unknown history.</p>
<p>All data was obtained from mozilla-central revision d4a27d8eda28.</p>
<p>The mozconfig used contained:</p>
<p>export MOZ_PSEUDO_DERECURSE=1
  mk_add_options MOZ_OBJDIR=@TOPSRCDIR@/obj-firefox.noindex</p>
<p>Please note that the objdir name ends with <em>.noindex</em> to prevent Finder
from indexing build files.</p>
<p>I performed all tests multiple times and used the fastest time. I used
<em>time</em> command for obtaining measurements of wall, user, and system
time.</p>
<h2>Results</h2>
<h3>Configure Times</h3>
<p>The result of <em>mach configure</em> is as follows:</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>29.748</td>
    <td>17.921</td>
    <td>11.644</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>26.765</td>
    <td>15.942</td>
    <td>10.501</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>21.581</td>
    <td>12.597</td>
    <td>8.595</td>
  </tr>
</table>

<h3>Clobber build no ccache</h3>
<p><em>mach build</em> was performed <em>after</em> running <em>mach configure</em>. ccache was
not enabled.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
    <th>Total CPU time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>22:29 (1349)</td>
    <td>145:35 (8735)</td>
    <td>12:03 (723)</td>
    <td>157:38 (9458)</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>15:00 (900)</td>
    <td>94:18 (5658)</td>
    <td>8:14 (494)</td>
    <td>102:32 (6152)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>11:13 (673)</td>
    <td>69:55 (4195)</td>
    <td>6:04 (364)</td>
    <td>75:59 (4559)</td>
  </tr>
</table>

<h3>Clobber build with empty ccache</h3>
<p><em>mach build</em> was performed <em>after</em> running <em>mach configure</em>. ccache was
enabled. The ccache ccache was cleared before running <em>mach configure</em>.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
    <th>Total CPU time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>25:57 (1557)</td>
    <td>161:30 (9690)</td>
    <td>18:21 (1101)</td>
    <td>179:51 (10791)</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>16:58 (1018)</td>
    <td>104:50 (6290)</td>
    <td>12:32 (752)</td>
    <td>117:22 (7042)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>12:59 (779)</td>
    <td>79:51 (4791)</td>
    <td>9:24 (564)</td>
    <td>89:15 (5355)</td>
  </tr>
</table>

<h3>Clobber build with populated ccache</h3>
<p><em>mach build</em> was performed after running <em>mach configure</em>. ccache was
enabled and the ccache was populated with the results of a prior build.
In theory, all compiler invocations should be serviced by ccache
entries.</p>
<p>This measure is a very crude way to measure how fast clobber builds
would be if compiler invocations were nearly instantaneous.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>3:59 (239)</td>
    <td>8:04 (484)</td>
    <td>3:21 (201)(</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>3:11 (191)</td>
    <td>6:45 (405)</td>
    <td>2:53 (173)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>2:31 (151)</td>
    <td>5:22 (322)</td>
    <td>2:12 (132)</td>
  </tr>
</table>

<h3>No-op builds</h3>
<p><em>mach build</em> was performed on a tree that was already built.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>1:58 (118)</td>
    <td>2:25 (145)</td>
    <td>0:41 (41)</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>1:42 (102)</td>
    <td>2:02 (122)</td>
    <td>0:37 (37)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>1:20 (80)</td>
    <td>1:39 (99)</td>
    <td>0:28 (28)</td>
  </tr>
</table>

<h3>binaries no-op</h3>
<p><em>mach build binaries</em> was performed on a fully built tree. This results
in nothing being executed. It's a way to test the overhead of the
<em>binaries</em> make target.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>4.21</td>
    <td>4.38</td>
    <td>0.92</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>3.17</td>
    <td>3.37</td>
    <td>0.71</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>2.67</td>
    <td>2.75</td>
    <td>0.56</td>
  </tr>
</table>

<h3>binaries touch single .cpp</h3>
<p><em>mach build binaries</em> was performed on a fully built tree after touching
the file <em>netwerk/dns/nsHostResolver.cpp</em>. ccache was enabled but
cleared before running this test. This test simulates common C++
developer workflow of changing C++ and recompiling.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>12.89</td>
    <td>13.88</td>
    <td>1.96</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>10.82</td>
    <td>11.63</td>
    <td>1.78</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>8.57</td>
    <td>9.29</td>
    <td>1.23</td>
  </tr>
</table>

<h3>Tier times</h3>
<p>The times of each build system <em>tier</em> were measured on the 2013 Haswell
MacBook Pro. These timings were obtained out of curiosity to help
isolate the impact of different parts of the build. ccache was not
enabled for these tests.</p>
<table border="1">
  <tr>
    <th>Action</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
    <th>Total CPU time</th>
  </tr>
  <tr>
    <td>export clobber</td>
    <td>15.75</td>
    <td>66.11</td>
    <td>11.33</td>
    <td>77.44</td>
  </tr>
  <tr>
    <td>compile clobber</td>
    <td>9:01 (541)</td>
    <td>64:58 (3898)</td>
    <td>5:08 (308)</td>
    <td>70:06 (4206)</td>
  </tr>
  <tr>
    <td>libs clobber</td>
    <td>1:34 (94)</td>
    <td>2:15 (135)</td>
    <td>0:39 (39)</td>
    <td>2:54 (174)</td>
  </tr>
  <tr>
    <td>tools clobber</td>
    <td>9.33</td>
    <td>13.41</td>
    <td>2.48</td>
    <td>15.89</td>
  </tr>
  <tr>
    <td>export no-op</td>
    <td>3.01</td>
    <td>9.72</td>
    <td>3.47</td>
    <td>13.19</td>
  </tr>
  <tr>
    <td>compile no-op</td>
    <td>3.18</td>
    <td>18.02</td>
    <td>2.64</td>
    <td>20.66</td>
  </tr>
  <tr>
    <td>libs no-op</td>
    <td>58.2</td>
    <td>46.9</td>
    <td>13.4</td>
    <td>60.3</td>
  </tr>
  <tr>
    <td>tools no-op</td>
    <td>8.82</td>
    <td>12.68</td>
    <td>1.72</td>
    <td>14.40</td>
  </tr>
</table>

<h2>Observations and conclusions</h2>
<p>The data speaks for itself: <strong>the 2013 Haswell MacBook Pro is
significantly faster than its predecessors.</strong> It clocks in at 2x faster
than the benchmarked 2011 Sandy Bridge model (keep in mind the 300 MHz
base clock difference) and is ~34% faster than the 2012 Ivy Bridge (at
similar clock speed). Personally, I was surprised by this. I was
expecting speed improvements over Ivy Bridge, but not 34%.</p>
<p>It should go without saying: <strong>if you have the opportunity to upgrade
to a new, Haswell-based machine: do it.</strong> If possible, purchase
the upgrade to a 2.6 GHz CPU, as it contains ~13% more MHz than the
base 2.3 GHz model: this will make a measurable difference in build
times.</p>
<p>It's worth noting the increased efficiency of Haswell over its
predecessors. The total CPU time required to build decreased from ~158
minutes to ~103 minutes to 76 minutes! That 76 minute number is worth
highlighting because it means if we get 100% CPU saturation during
builds, we'll be able to build the tree in under 10 wall time minutes!</p>
<p>I hadn't performed crude benchmarks of high-level build system actions
since the <em>MOZ_PSEUDO_DERECURSE</em> work landed and I wanted to use the
opportunity of this hardware comparison to grab some numbers.</p>
<p>The overhead of ccache continues to surprise me. On the 2013
machine, enabling ccache increased the wall time of a clobber build by
1:46 and added 13:16 of CPU time. This is an increase of 16% and 17%,
respectively.</p>
<p>It's worth highlighting just how much time is spent compiling C/C++. In
our artificial tier measuring results, our clobber build time was ~660
wall time seconds (11 minutes) and used ~4473s CPU time (74:33). Of
this, 9:01 wall time and 70:06 CPU time was spent compiling C/C++. This
represents ~82% wall time and ~94% CPU time! Please note this does not
include linking. <strong>Anything we can do to decrease the CPU time used by
the compiler will make the build faster.</strong></p>
<p>I also found it interesting to note variances in obtained times. Even on
my brand new 2013 Haswell MacBook Pro where I know there aren't many
background processes running, wall times could vary significantly. I
<em>think</em> I isolated it to CPU bursting and heat issues. If I wait a few
minutes between CPU intensive tests, results are pretty consistent. But
if I perform CPU intensive tests back-to-back, the run times often vary.
The only other thing coming into play could be page caching or
filesystem indexing. I accounted for the latter by disabling Finder
on the object directory. And, I'd like to think that flash storage is
fast enough to remove I/O latency from the equation. Who knows. At the
end of the day, laptops aren't servers and OS X is a consumer OS, so I
don't expect ultra consistency.</p>
<p>Finally, I want to restate just how fast Haswell is. If you have the
opportunity to upgrade, do it.</p>]]></content:encoded>
    </item>
    <item>
      <title>Distributed Compiling and Firefox</title>
      <link>http://gregoryszorc.com/blog/2013/10/31/distributed-compiling-and-firefox</link>
      <pubDate>Thu, 31 Oct 2013 11:35:00 PDT</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <category><![CDATA[build system]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2013/10/31/distributed-compiling-and-firefox</guid>
      <description>Distributed Compiling and Firefox</description>
      <content:encoded><![CDATA[<p>If you had infinite CPU cores available and the Firefox build system
could distribute them all for concurrent compilation, Firefox
clobber build times would likely be 3-5 minutes instead of ~15
minutes on modern machines. This is a massive win. It therefore
should come as no surprise that distributed compiling is very
interesting to us.</p>
<p>Up until recently, the benefits of distributed compiling in the Firefox
build system couldn't be fully realized. This was because the build
system was performing recursive make traversal and make only <em>knew</em>
about a tiny subset of the tree's total C++ files at one time. For
example, when visiting <em>/layout/base</em> it only knew about 35 of the
close to 6000 files that get compiled as part of building Firefox. This
meant there was a hard ceiling to the max concurrency the build system
could achieve. This ceiling was often higher than the number of cores in
an individual machine, so it wasn't a huge issue for single machine
builds. But it did significantly limit the benefits of distributed
compiling. This all changed recently.</p>
<p><strong>As of a few weeks ago, the build system no longer encounters a low
ceiling preventing distributed compilation from reaping massive
benefits.</strong> If you have build with <em>make -j128</em>, make will spawn
128 compiler processes when processing the <em>compile</em> tier (which
is where most compilation occurs). If your compiler is set to a
distributed compiler, you will win.</p>
<p>So, what should you do about it?</p>
<p>I encourage people to set up distributed compilation <em>networks</em>
to reap the benefits of distributed compilation. Here are some tools you
should know about and some things to keep in mind.</p>
<p><a href="https://code.google.com/p/distcc/">distcc</a> is the tried and proven tool
for performing distributed compilation. It's heavily used and gets the
job done. It even works on Windows and can perform remote processing,
which is a huge win for our tree, where preprocessing can be
computationally expensive because of excessive includes. But, it has
a few significant drawbacks. Read the next paragraph.</p>
<p>I'm personally more excited about
<a href="https://github.com/icecc/icecream">icecream</a>. It has some very
compelling advantages to distcc. It has a scheduler that can
intelligently distribute load between machines. It uses network
broadcast to discover the scheduler. So, you just start the client
daemon and if there is a scheduler on the local network, it's all
set up. Icecream transfers the compiler toolchain between nodes
so you are guaranteed to have consistent output. (With distcc,
output may not be idempotent if the nodes aren't homogenous since distcc
relies on the system-local toolchain. If different versions are
installed on different nodes, you are out of luck). Icecream also
supports cross-compiling. In theory, you can have Linux machines
building for OS X, 32-bit machines building for 64-bit, etc. This
is all very difficult (if not impossible) to do with distcc.
Unfortunately, icecream doesn't work on Windows and doesn't appear
to support server-side preprocessing. Although, I imagine
both could be made to work if someone put in the effort.</p>
<p>Distributed compilation is very network intensive. I haven't measured,
but I suspect Wi-Fi bandwidth and latency constraints might make it
prohibitive there. It certainly won't be good for Wi-Fi saturation!
<strong>If you are in a Mozilla office, please do not attempt to perform
distributed compilation over Wi-Fi!</strong> For the same reasons, distributed
compilation will likely not benefit you if you are attempting to compile
on network-distant nodes.</p>
<p>I have set up an icecream server in the Mozilla San Francisco office. If
you install the icecream client daemon (iceccd) on your machine, it
should just work. I'm not sure what broadcast nets are configured as,
but I've successfully had machines on the 7th floor discover it
automatically. I guarantee no SLA for this server. Ping me privately
if you have difficulty connecting.</p>
<p>I've started very preliminary talks with Mozilla IT about setting up
dedicated <em>compiler farms</em> in Mozilla offices. I'm not saying this is
coming any time soon. I feel this will have a major impact on developer
productivity and I wanted to get the ball rolling months in advance
so nobody can claim this is a fire drill.</p>
<p>For distributed compilation to work well, the build system really needs
to be aware of distributed compilation. For example, to yield the
benefits of distributed compilation with make, you need to pass -j64 or
some other large value for concurrency. However, this value would be
universal for <em>every</em> task in the build. There are still thousands of
processes that must run locally. Using -j64 on these local tasks could
cause memory exhaustion, I/O saturation, excessive context switching,
etc. But if you decrease the concurrency ceiling, you lose the benefits
of distributed compilation! The build system thus needs to be taught
when distributed compilation is available and what tasks can be made
concurrent so it can intelligently adjust the -j concurrency limit at
run-time. This is why we have a higher-level build wrapper tool: <em>mach
build</em>. (This is another reason why people should be building through
mach instead of invoking make directly.)</p>
<p>No matter what technical solution we employ, I would like the build
system to automatically discover and use distributed compilation if
it is available. If we need to hardcode Mozilla IP addresses or
hostnames into the build system, I'm fine with that. I just don't want
developers not achieving much-faster build times because they are
ignorant. If you are in a physical location with distributed compilation
support, you should get that automatically: fast builds should not be
hard.</p>
<p>We can and should investigate distributed compilation as part of release
automation. Icecream should mitigate the concerns about build
reproducibility since the toolchain is transferred at build time.</p>
<p>I have had success getting Icecream to work with Linux builds. However,
OS X is problematic. Specifically, Icecream is unable to create the
build environment for distribution (likely modern OS X/Xcode
compatibility issue). Details are in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=927952">bug 927952</a>.</p>
<p>Build peers have a lot on our plate this quarter and making distributed
compilation work well is not in our official goals. <strong>I would love, love,
love if someone could step up and be a hero to make distributed
compilation work better with the build system.</strong> If you are interested,
pop into #build on irc.mozilla.org.</p>
<p>In summary, there are massive developer productivity wins waiting to be
realized through distributed compiling. There is nobody tasked to work
on this officially. Although, I'd love it if there were. If you find
yourself setting up ad-hoc networks in offices, I'd <em>really</em> like to see
some kind of discovery in <em>mach</em>. If not, there will be people left
behind and that really stinks for those individuals. If you do any
work around distributed compiling, please have it tracked under
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=485559">bug 485559</a>.</p>]]></content:encoded>
    </item>
    <item>
      <title>OS X Mavericks and the Firefox Build System</title>
      <link>http://gregoryszorc.com/blog/2013/10/22/os-x-mavericks-and-the-firefox-build-system</link>
      <pubDate>Tue, 22 Oct 2013 13:30:00 PDT</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2013/10/22/os-x-mavericks-and-the-firefox-build-system</guid>
      <description>OS X Mavericks and the Firefox Build System</description>
      <content:encoded><![CDATA[<p>OS X Mavericks is available today as a free upgrade. People at Mozilla
are probably asking if it is safe to upgrade: will it affect my ability
to build Firefox.</p>
<p>A few people (myself included) have been running OS X Mavericks
developer previews for a few months. I believe all the Firefox build
system issues have been worked out for at least a few weeks now. So,
upgrading to OS X Mavericks should not impact your ability to build a
stock Firefox configuration from mozilla-central.</p>
<p>There might still be some non-default features and code paths that need
fixed to work with Mavericks. Support for the OS X 10.9 SDK might also
be problematic. In addition, if you build older trees such as Aurora
and Beta, you may run into issues building on Mavericks because those
trees may not have all required fixes uplifted.</p>
<p>While I won't encourage you to upgrade, I will say that Mavericks should
build Firefox without any issue. And since the number of Mavericks users
will only increase in the days ahead, it should be safe to assume that
regressions will be promptly fixed.</p>
<p>If you run into any issues with Firefox and Mavericks,
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=883824">bug 883824</a> is the
master tracking bug.
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=894090">Bug 894090</a> tracks
build system issues.</p>]]></content:encoded>
    </item>
    <item>
      <title>Alternate Mercurial Server for Firefox Development</title>
      <link>http://gregoryszorc.com/blog/2013/10/17/alternate-mercurial-server-for-firefox-development</link>
      <pubDate>Thu, 17 Oct 2013 07:30:00 PDT</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2013/10/17/alternate-mercurial-server-for-firefox-development</guid>
      <description>Alternate Mercurial Server for Firefox Development</description>
      <content:encoded><![CDATA[<p>I have <a href="/blog/2013/05/13/the-state-of-mercurial-at-mozilla/">long opined</a>
about the sad state of Mercurial at Mozilla. The short version is
Mozilla has failed to use Mercurial optimally, at least for Firefox
development. It's easy to see why so many Mozillians are quick to
discredit Mercurial when compared to Git!</p>
<p>I have a <a href="/blog/category/mercurial/">history</a> attempting to address the
deficiencies. Up to this point, I've been able to make things better
through local tooling. But, for my next set of tricks, I reached an
impasse with the Mercurial server at
<a href="https://hg.mozilla.org/">hg.mozilla.org</a>. So, I stood up my own
Mercurial server at
<a href="http://hg.gregoryszorc.com">hg.gregoryszorc.com/</a>!</p>
<p>This server is running Mercurial 2.7 and has a few nice features the
official Mercurial server at hg.mozilla.org does not.</p>
<h2>The repositories</h2>
<p><a href="http://hg.gregoryszorc.com/gecko">http://hg.gregoryszorc.com/gecko</a> is
a read-only unified Mercurial repository containing the commits for the
major Firefox/Gecko repositories. If you look at its
<a href="http://hg.gregoryszorc.com/gecko/bookmarks">bookmarks</a>, you'll see
something special: the heads of all the separate Mercurial repos it is
aggregating are being stored as bookmarks! (Bookmarks are effectively
Git branches.) The tip of mozilla-central is at the bookmark
<strong>central/default</strong>. The tip of Beta is at <strong>beta/default</strong>.
You get the idea. Once you clone this repo, you can easily switch
between <em>project branches</em> by running e.g. <strong>hg up central/default</strong>.
When you pull the repo, you get changesets for all repos by connecting
to one server, not several (this reduces load on Mozilla's servers and
is faster for clients).</p>
<p>This repository shares the same changesets/SHA-1's as the official
repositories. It just has everything under one roof. You can work out of
this repository and push to the official repositories. Although, you may
want to use the <em>pushtree</em> command from my
<a href="/blog/2013/07/22/mercurial-extension-for-gecko-development/">custom extension</a>
to make your life easier (<em>hg push</em> with no arguments will attempt to
push all changesets, which you definitely don't want when pushing to
e.g. mozilla-central).</p>
<p><a href="http://hg.gregoryszorc.com/gecko-collab">http://hg.gregoryszorc.com/gecko-collab</a>
is an offshoot of the <em>gecko</em> repo that you can push to. Changesets from
the <em>gecko</em> repo are pulled into it automatically.</p>
<p>What makes the <em>gecko-collab</em> repository special is that it has
<em>obsolescence</em> enabled. That is the core Mercurial feature enabling
<a href="http://mercurial.selenic.com/wiki/ChangesetEvolution">changeset evolution</a>.
More on that feature and why it is amazing in a future blog post. Stay tuned.</p>
<h2>Cloning</h2>
<p>If you would like to clone one of these unified repos, please do my
paltry EC2 server a favor and bootstrap your clone from an existing
clone. e.g. if you have a copy of mozilla-central sitting around but
don't want my repo's changesets to <em>pollute</em> it, do the following:</p>
<div class="pygments_murphy"><pre>hg clone mozilla-central gecko
<span class="nb">cd </span>gecko
hg pull http://hg.gregoryszorc.com/gecko
</pre></div>

<p>Or, if you are OK with your clone accumulating the extra changesets from
all the project branches, just run:</p>
<div class="pygments_murphy"><pre>hg pull http://hg.gregoryszorc.com/gecko
</pre></div>

<p>Don't forget to update the <em>[paths]</em> section in your <em>.hg/hgrc</em> file
to point to hg.gregoryszorc.com! e.g.</p>
<div class="pygments_murphy"><pre>[paths]
gecko = http://hg.gregoryszorc.com/gecko
collab = http://hg.gregoryszorc.com/gecko-collab
</pre></div>

<h2>Setting up push support and SSH keys</h2>
<p>If you would like to push to the
<a href="http://hg.gregoryszorc.com/gecko-collab">gecko-collab</a> repository,
you'll need to give me your SSH public key. But don't give me your key -
give an automated process your key!</p>
<p>Head on over to
<a href="http://phabricator.gregoryszorc.com">http://phabricator.gregoryszorc.com/</a>
and log in (look for the Persona button). Once you've logged in, go to your
settings by clicking the wrench icon in the top right. Then look for
<em>SSH Public Keys</em> to add your key(s). If you can't find it, just go to
<a href="http://phabricator.gregoryszorc.com/settings/panel/ssh/">http://phabricator.gregoryszorc.com/settings/panel/ssh/</a>.</p>
<p>Once your SSH public key is added, it will take up to a minute for it to
be added to my system. It's all automatic. You don't need to wait for
any manual action.</p>
<p>To connect to my server over SSH, you'll need to log in as the <em>hgssh</em>
user. e.g. in your <em>hgrc</em> file, add:</p>
<pre><code>[paths]
gecko = ssh://hgssh@hg.gregoryszorc.com/gecko
collab = ssh://hgssh@hg.gregoryszorc.com/gecko-collab
</code></pre>
<p>Then, you should be able to pull and push over SSH!</p>
<h2>Other Notes</h2>
<p>This server is running on an EC2 instance that isn't as powerful as I'd
like. Expect some operations to be slower than desired.</p>
<p>I don't guarantee an SLA for this service. It could go down at any
moment. However, Mercurial being a distributed version control system,
there should be little to no data loss assuming people pull frequently.
I know I have a backup on all my machines now.</p>
<p>I'm running this server for two main reasons.</p>
<p>First, I want to demonstrate the utility of a unified Mercurial server
for Firefox development in hopes we can run one officially. I've been
running a unified repo locally for a few months and I have little doubt
I'm more productive because of it. I want others to realize the
awesomeness.</p>
<p>Second, I needed a server that supported
<a href="http://mercurial.selenic.com/wiki/ChangesetEvolution">changeset evolution</a>
so I could play around with it. I <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=925383">asked</a>
the powers at be to enable it on hg.mozilla.org and didn't get a
response that met my timeline. So, I figured setting up my own server
was easier.</p>
<p>Please let me know if you have any questions or issues with this server.
I'd also love to hear whether people like the unified repo approach!</p>]]></content:encoded>
    </item>
    <item>
      <title>The State of the Firefox Build System (2013 Q3 Review)</title>
      <link>http://gregoryszorc.com/blog/2013/10/15/the-state-of-the-firefox-build-system-(2013-q3-review)</link>
      <pubDate>Tue, 15 Oct 2013 13:00:00 PDT</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <category><![CDATA[build system]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2013/10/15/the-state-of-the-firefox-build-system-(2013-q3-review)</guid>
      <description>The State of the Firefox Build System (2013 Q3 Review)</description>
      <content:encoded><![CDATA[<p>As we look ahead to Q4 planning for the Firefox build system, I wanted
to take the time to reflect on what was accomplished in Q3 and to
simultaneously look forward to Q4 and beyond.</p>
<h2>2013 Q3 Build System Improvements</h2>
<p>There were notable improvements in the build system during the last
quarter.</p>
<p>The issues our <em>customers</em> care most about is speed. Here is a list of
accomplishments in that area:</p>
<ul>
<li>
<p><em>MOZ_PSEUDO_DERECURSE</em> work to change how make directory traversal
  works. This enabled the <em>binaries</em> make target, which can do no-op
  libxul-only builds in just a few seconds. Of all the changes that
  landed this quarter, this is the most impactful to local build
  times. This change also enables C++ compilation to scale out to
  as many cores as you have. Previously, the build system was
  <em>starved</em> in many parts of the tree when compiling C++. Mike Hommey
  is responsible for this work. I reviewed most of it.</p>
</li>
<li>
<p>WebIDL and IPDL bindings are now compiled in <em>unified</em> mode,
  reducing compile times and linker memory usage. Nathan Froyd wrote the
  code. I reviewed the patches.</p>
</li>
<li>
<p>XPIDL files are generated much more efficiently. This removed a
  few minutes of CPU core time from builds. I wrote these patches and
  Mike Hommey reviewed.</p>
</li>
<li>
<p>Increased reliance on install manifests to process file installs.
  They have drastically reduced the number of processes required to
  build by performing all actions inside Python processes as system
  calls and removing the clownshoes of having to delete parts of the
  object directory at the beginning of builds. When many mochitests
  were converted to manifests, no-op build times dropped by ~15%
  on my machine. Many people are responsible for this work. Mike Hommey
  wrote the original install code for packaging a few months ago. I
  built in manifest file support, support for symlinks, and made the
  code a bit more robust and faster. Mike Hommey reviewed these
  patches.</p>
</li>
<li>
<p>Many bugs and issues around dependency files on Windows have been
  discovered and fixed. These were a common source of clobbers.
  Mike Hommey found most of these, many during his work to make
  MOZ_PSEUDO_DERECURSE work.</p>
</li>
<li>
<p>The effort to reduce C++ include hell is resulting in significantly
  shorter incremental builds. While this effort is largely outside the
  build config module, it is worth mentioning. Ehsan Akhgari is leading
  this effort. He's been assisted by too many people to mention.</p>
</li>
<li>
<p>The build system now has different build modes favoring faster
  building vs release build options depending on the environment. Mike
  Hommey wrote most (all?) of the patches.</p>
</li>
</ul>
<p>A number of other non-speed related improvements have been made:</p>
<ul>
<li>
<p>The build system now monitors resource usage during builds and can
  graph the results. I wrote the code. Ted Mielczarek, Mike Hommey,
  and Mike Shal had reviews.</p>
</li>
<li>
<p>Support for test manifests has been integrated with the build system.
  This enabled some build speed wins and is paving the road for better
  testing UX, such as the automagical <em>mach test</em> command, which will
  run the appropriate test suite automatically. Multiple people were
  involved in the work to integrate test manifests with the build
  system. I wrote the patches. But Ted Mielczarek got primary review.
  Joel Maher, Jeff Hammel, and Ms2ger provided excellent assistance
  during the design and implementation phase. The work around
  mochitest manifests likely wouldn't have happened this quarter if
  all of us weren't attending an A*Team work week in August.</p>
</li>
<li>
<p>There are now in-tree build system docs. They are
  <a href="https://ci.mozilla.org/job/mozilla-central-docs/Build_Documentation/index.html">published automatically</a>.
  Efforts have been made to purge MDN of cruft. I am responsible for
  writing the code and most of the docs. Benjamin Smedberg and Mike Shal
  performed code reviews.</p>
</li>
<li>
<p>Improvements have been made to object directory detection in mach.
  This was commonly a barrier to some users using mach. I am responsible
  for the code. Nearly every peer has reviewed patches.</p>
</li>
<li>
<p>We now require Python 2.7.3 to build, making our future Python 3
  compatibility story much easier while eliminating a large class
  of Python 2.7.2 and below bugs that we constantly found ourselves
  working around.</p>
</li>
<li>
<p>mach bootstrap has grown many new features and should be more robust
  than ever. There are numerous contributors here, including many
  community members that have found and fixed bugs and have added
  support for additional distributions.</p>
</li>
<li>
<p>The boilerplate from Makefile.in has disappeared. Mike Hommey is to
  thank.</p>
</li>
<li>
<p>dumbmake integrated with mach. Resulted in friendlier build interface
  for a nice UX win. Code by Nick Alexander. I reviewed.</p>
</li>
<li>
<p>Many variables have been ported from Makefile.in to moz.build. We
  started Q3 with support for 47 variables and now support 73. We
  started with 1226 Makefile.in and 1517 moz.build and currently
  have 941 Makefile.in and 1568 moz.build. Many people contributed to
  this work. Worth mentioning are Joey Armstrong, Mike Shal, Joshua
  Cranmer, and Ms2ger.</p>
</li>
<li>
<p>Many build actions are moving to Python packages. This enabled pymake
  <em>inlining</em> (faster builds) and is paving the road towards no .pyc
  files in the source directory. (pyc files commonly are the source of
  clobber headaches and make it difficult to efficiently perform builds
  on read-only filesystems.) I wrote most of the patches and Mike Shal
  and Mike Hommey reviewed.</p>
</li>
<li>
<p>moz.build is now more strict about what it accepts. We check for
  missing files at config parse time rather than build time, causing
  errors to surface faster. Many people are responsible for this work.
  Mike Shal deserves kudos for work around C/C++ file validation.</p>
</li>
<li>
<p>mach has been added to the B2G repo. Jonathan Griffin and Andrew
  Halberstadt drove this.</p>
</li>
</ul>
<h2>Current status of the build bystem</h2>
<p>Q3 was a very significant quarter for the build system. For the first
time in years, we made fundamental changes to how the build system
goes about building. The moz.build work to free our build config from
the shackles of make files had enabled us to consume that data and do
new and novel things with it. This has enabled improvements in build
robustness and - most importantly - speed.</p>
<p>This is most evident with the MOZ_PSEUDO_DERECURSE work, which
effectively replaces how make traverses directories. The work there
has allowed Gecko developers focused on libxul to go from e.g. 50s
no-op build times to less than 5s. Combined with optimized building
of XPIDL, IPDL, and WebIDL files, processing of file installs via
manifests, and C++ header dependency reduction, and a host of other
changes, and we are finally turning a corner on build times! Much of
this work wouldn't have been possible without moz.build files providing
a whole world view of our build config.</p>
<p>The quarter wasn't all roses. Unfortunately, we also broke things. A lot.
The total number of required clobbers this quarter grew slightly from
38 in Q2 to 43 in Q3. Many of these clobbers were regressions from
supposed improvements to the build system. Too many of these
regressions were Windows/pymake only and surely would have been found
prior to landing if more build peers were actively building on Windows.
There are various reasons we aren't. We should strive to fix them so
more build development occurs on Windows and Windows users aren't
unfairly punished.</p>
<p>The other class of avoidable clobbers mostly revolves
around the theme that <em>the build system is complicated</em>, particularly
when it comes to integration with release automation. Build automation
has its build logic currently coded in Buildbot config files. This means
it's all but impossible for build peers to test and reproduce that build
environment and flow without time-intensive, stop-energy abundant
excessive try pushes or loading out build slaves. The RelEng effort
to extract this code from buildbot to mozharness can't come soon enough. See
<a href="/blog/2013/07/16/analysis-of-firefox%27s-build-automation/">my overview</a>
on how automation works for more.</p>
<p>This quarter, the sheriffs have been filing bugs whenever a clobber is
needed. This has surfaced clobber issues to build peers better and I
have no doubt their constant pestering caused clobber issues to be
resolved sooner. It's a terrific incentive for us to fix the build
system.</p>
<p>I have mixed feelings on the personnel/contribution front in Q3. Kyle
Huey no longer participates in active build system development or patch
review. Ted Mielczarek is also starting to drift away from active coding
and review. Although, he does constantly provide knowledge and historical
context, so not all is lost. It is disappointing to see fantastic
people and contributors no longer actively participating on the coding
front. But, I understand the reasons behind it. Mozilla doesn't have a
build team with a common manager and decree (a mistake if you ask me).
Ted and Kyle are both insanely smart and talented and they work for
teams that have other important goals. They've put in their time (and
suffering). So I see why they've moved on.</p>
<p>On the plus side, Mike Hommey has been spending a lot more time on build
work. He was involved in many of the improvements listed above. Due to
review load and Mike's technical brilliance, I don't think many of our
accomplishments would have happened without him. If there is one
Mozillian who should be commended for build system work in Q3, it should
be Mike Hommey.</p>
<p>Q3 also saw the addition of new build peers. Mike Shal is now a full
build config module peer. Nick Alexander is now a peer of a submodule
covering just the Fennec build system. Aside from his regular patch
work, Mike Shal has been developing his review skills and
responsibilities. Without him, we would likely be drowning in review
requests and bug investigations due to the departures of Kyle and Ted.
Nick is already doing what I'd hope he'd do when put in charge of the
Fennec build system: looking at a proper build backend for Java (not
make) and Eclipse project generation. (I still can't believe many of
our Fennec developers code Java in vanilla text editors, not powerful
IDEs. If there is one language that would miss IDEs the most, I'd think
it would be Java. Anyway.)</p>
<p>There was a steady stream of contributions from people not in the build
config module. Joshua Cranmer has been keeping up with moz.build
conversions for comm-central. Nathan Froyd and Boris Zbarsky have helped
with all kinds of IDL work. Trevor Saunders has helped keep things
clean. Ms2ger has been eager to provide assistance through code and
reviews. Various community contributors have helped with moz.build
conversion patches and improvements to mach and the bootstrapper. Thank
you to everyone who contributed last quarter!</p>
<h2>Looking to the future</h2>
<p>At the beginning of the quarter, I didn't think it would be possible
to attain no-op build speeds with make as quickly as <em>make binaries</em> now
does. But, Mike Hommey worked some magic and this is now possible.
This was a game changer. The code he wrote can be applied to other
build actions. And, our other solutions involving moz.build files to
autogenerated make files seems to be working pretty well too.
This raises some interesting questions with regards to priortization.</p>
<p>Long term, we know we want to move away from make. It is old
and clumsy. It's easy to do things wrong. It doesn't scale to handle a
single DAG as large as our build system. The latter is particularly
important if we are to ever have a build system that doesn't require
clobbers periodically.</p>
<p>Up to this point we've prioritized work on moz.build conversion, with
the rationale being that it would more soon enable a clean break from
make and thus we'd arrive at drastically faster builds sooner. The assumption in that
argument was that drastically faster builds weren't attainable with
make. Between the directory traversal overhaul and the release of GNU
make 4.0 last week (which actually seems to work on Windows, making the
pymake slowness a non-issue), the importance of breaking away from make
now seems much less pressing.</p>
<p>While we would like to actively move off make, developments in the past
few weeks seem to say that we can reassess priorities. I believe that we
can drive down no-op builds with make to a time that satisfies many -
let's say under 10s to be conservative. Using clever tricks optimizing
for common developer workflows, we can probably get that under 5s
everywhere, including Windows (people only caring about libxul can
get 2.5s on mozilla-central today). This isn't the 250ms we could get
with Tup. But it's much better than 45s. If we got there, I don't think
many people would be complaining.</p>
<p>So, the big question for goals setting this quarter will be whether we
want to focus on a new build backend (likely Tup) or whether we should
continue with an emphasis on make. Now, a lot of the work involved
applies to both make and any other build backend. But, I have little
doubt it would be less overall work to support one build backend (make)
than two. On the other hand, we know we want to support multiple build
backends eventually. Why wait? In the balance are
<a href="https://etherpad.mozilla.org/build-system-goals">numerous other projects</a>
that have varying impact for developers and release automation. While
important in their own right, it is difficult to balance them against
build speed. While we could strive towards instantaneous builds, at some
point we'll hit <em>good enough</em> and the diminishing returns that accompany
them. There is already a small vocal faction advocating for Ninja
support, even though it would only decrease no-op libxul build times
from ~2.5s to 250ms. While a factor of 10x improvement, I think this is
dangerously close to diminishing returns territory and our time
investment would be better spent elsehwere. (Of course, once we can
support building libxul with Ninja, we could easily get it for Tup. And,
I believe Tup wins that tie.). Anyway, I'm sure it will be an
interesting discussion!</p>
<p>Whatever the future holds, it was a good quarter for the build system and
the future is looking brighter than ever. We have transitioned from a
maintain-and-react mode (which I understand has largely been the norm
since the dawn of Firefox) to a proactive and future-looking approach
that will satisfy the needs of Firefox and its developers for the next
ten years. All of this progress is even more impressive when you consider
that we still react to an aweful lot of fire drills and unwanted
maintenance!</p>
<p>The Firefox build system is improving. I'm as anxioux as you are to see
various milestones in terms of build speed and other features. But it's
hard work. Wish us luck. Please help out where you can.</p>]]></content:encoded>
    </item>
    <item>
      <title>Phabricator is Awesome</title>
      <link>http://gregoryszorc.com/blog/2013/10/14/phabricator-is-awesome</link>
      <pubDate>Mon, 14 Oct 2013 11:00:00 PDT</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2013/10/14/phabricator-is-awesome</guid>
      <description>Phabricator is Awesome</description>
      <content:encoded><![CDATA[<p>When I talk to Mozillians who now work at Facebook, they all say
something similar: <em>the tools at Facebook are amazing and put what
Mozilla uses to shame</em>. Having worked at places with decent tools, I
do know that Mozilla is behind the times. So it was easy for me to
dismiss these observations as obvious. But, when you start asking them
about specifics, one tool they are quick to name is
<a href="http://phabricator.org/">Phabricator</a>.</p>
<p>For those who don't want to follow the link, Phabricator is your
all-in-on software engineering web application and platform. It has
issue/bug tracking, code review, repository navigation, wikis, etc. It's
the kitchen sink for software lifecycle management. And, it's open
source and easy to extend. Sounds promising.</p>
<p>After hearing Facebookers rave about Phabricator and having casually
interacted with an instance to review patches to Clang, I was keen
to have a closer look.</p>
<p>So, I spent a lazy afternoon and installed Phabricator on an EC2
instance (connection details below). Having interacted with the
default setup for a few hours, I can say with high confidence
that the Facebookers can back up their claim that Phabricator is
pretty damn amazing. My initial impressions are that it's one of
those tools that's so good that once you start using it, you'll
never tolerate anything subpar again. Again, hearing the
Mozillians-turned-Facebookers opine about Bugzilla, code review,
etc, I think this initial impression might be right.</p>
<p>In the sections below, I'll talk a bit about Phabricator and why I
think it is superior to what Mozilla uses.</p>
<h2>Integrated UI</h2>
<p>One thing I really love about Phabricator is the integrated UI.
Phabricator is essentially a collection of <em>applications</em> tied together
by a single web interface. So, everything is readily available under one
site/domain/service.</p>
<p>This means everything is easier to find. You search for something and
all the different components have their results surfaced. Contrast with
Mozilla as of today, where you need separate searches for Bugzilla,
MXR/DXR, wiki.mozilla.org, etherpad, MDN, etc.</p>
<p>For IT, it means there is only a single service to run and scale. Less
overhead to operate. Less effort to secure.</p>
<h2>Arcanist command line tool</h2>
<p>Phabricator ships with a command line tool called
<a href="http://www.phabricator.com/docs/phabricator/article/Arcanist_User_Guide.html">Arcanist</a>.
It is amazing.</p>
<p>Projects put <em>.arcconfig</em> files under version control which contain the
settings used to configure Arcanist for that project. They essentially
point back towards the Phabricator instance for that project.</p>
<p>You can do a lot with the Arcanism command line interface. Want to
create a code review? <em>arc diff</em>. It opens up an editor and allows you
to fill in details about the review. It then automatically publishes it
for review. No leaving the command line necessary.</p>
<p>You can download and apply patches undergoing code review by
specifying their review identifier. e.g. <em>arc patch D1</em>.</p>
<p>You can create tasks for yourself by running <em>arc todo</em>. The tasks are
uploaded to Phabricator automatically and show up in your dashboard.</p>
<p>If your repo has configured which tests apply to which paths, <em>arc unit</em>
will run all tests impacted by the current patch. (If we ever get around
to annotating this, it would significantly reduce load in automation by
eliminating unnecessary tests.)</p>
<p>There is an <em>arc land</em> command to land patches on the appropriate
landing branch.</p>
<p>Arcanist abstracts the differences between version control systems
pretty well. You can use the same commands for Mercurial, Git, or
Subversion.</p>
<p>Arcanist is pretty nice. It reminds me a lot of mach and what I
originally wanted mach to become with regard to helping to improve
developer workflow.</p>
<h2>Real Code Review</h2>
<p>Phabricator features a real code review tool -
<a href="http://www.phabricator.com/docs/phabricator/article/Differential_User_Guide.html">Differential</a>.</p>
<p>Things like interdiff actually work. It integrates with the code
repository, which means you can expand context right from the
review interface. It can detect blocks
of code that moved between files. It has a nice file tree for navigating
changed files (optional feature). It hides whitespace only changes by
default. You can specify a group of people for review and reviews will
show up in the dashboard of individuals in that group. It has a flag
to say whether a patch underwent <em>linting</em> before upload. (You can
configure linting through Arcanist and have your patches linted before
upload. If you properly deploy linting, style nits all but go away. As I
like to say, every time I write a style nit in code review, my time is
wasted and Mozilla is throwing away part of my salary.)</p>
<p>Mozilla is apparently integrating ReviewBoard into Bugzilla. This is
good. ReviewBoard's review features are infinitely better than Splinter
(Bugzilla's current review interface). However, ReviewBoard is mostly a
standalone tool. What makes Phabricator's approach better is that code
review integrates tightly with everything else. This enables some pretty
awesome scenarios. Keep reading for more.</p>
<h2>Auditing</h2>
<p>An interesting and potentially very useful feature of Phabricator is
<a href="http://www.phabricator.com/docs/phabricator/article/Audit_User_Guide.html">auditing</a>.
Where Differential handles pre-push code review, the Audit
application supports post-push code review. You may say <em>but all changes
at Mozilla must go through pre-push code review - there's no use for
post-push code review</em>. Yes, but post-push review opens up a whole new
realm of possibilities.</p>
<p>It's possible for individual users or projects to set up rules to
automatically trigger audits. For example, as build module owner, I'm
very interested in ensuring people follow the code review policy of
having a build peer review changes to make files. With Phabricator, I
was able to easily configure a rule that automatically creates an audit
every time a make file has changed but it wasn't signed off by a build
peer. Front and center on my dashboard are a list of commits that I
should probably look at. Neat!</p>
<p>Audits are potentially useful for reviews that focus less on code. For
example, Firefox Health Report and Telemetry are two Firefox features
that collect data and send it (anonymously) to Mozilla. Audits could be
used to flag a privacy review when probes are changed. We often don't
want this privacy review to hold up code landing. But we do want to
track that this review occurs before a patch is shipped to our Beta
channel users. I think audits would be great for facilitating this.</p>
<p>Of course, there is a web interface to create new audits. Any individual
can watch anything they have access to. No process involved. Just log in
and create a rule.</p>
<p>Mozilla has audits today, but it isn't user intuitive. They commonly
take the form of Bugzilla keywords or whiteboard entries. Phabricator's
feature is much more powerful.</p>
<h2>Creating rules as a result of actions</h2>
<p>Phabricator has an application called <em>Herald</em> that allows users to
install rules to do something as a result of an action.</p>
<p>For example, I can create a rule against new review requests that will
CC me or automatically add me as a reviewer if a certain file is touched
by a patch.</p>
<p>I can have Phabricator email me whenever a specific user makes a commit
or when a commit touching a specific file is made.</p>
<p>This feature is self-service. You just open the web interface and
program custom rules to your heart's content.</p>
<p>Herald is insanely useful. To my knowledge, Mozilla has nothing quite
like it today. I wish we did. If Mozilla doesn't official deploy
Phabricator, I may continue to run my own personal instance just so I
can have this feature.</p>
<p>Of course, there's an
<a href="http://www.phabricator.com/docs/phabricator/article/Events_User_Guide_Installing_Event_Listeners.html">Event Listener API</a>
so you can write your own events and rules. The sky is literally the
limit here. For example, we could have all uploaded patches
automatically submitted to Try so they run the release automation
gamut. And, we could have Phabricator's background daemons poll for try
results and report them directly in the web interface!</p>
<h2>Module ownership defined inside Phabricator</h2>
<p>Phabricator has a <em>modules</em> concept built into it called
<a href="http://www.phabricator.com/docs/phabricator/article/Owners_Tool_User_Guide.html">Owners</a>. You
create a <em>package</em> that has a single owner and a number of members. This
package can be associated with multiple repositories and individual
paths inside repositories.</p>
<p>The power of this feature is realized when it is integrated with other
components of Phabricator.</p>
<p>For example, there is a checkbox for each <em>package</em> where you can
automatically have Phabricator ensure that a package member is involved
with code review touching files belonging to a package. It will also
automatically report commits not reviewed by members of a package. How
insanely useful is that!</p>
<h2>Other applications and features.</h2>
<p>Phabricator ships with a number of other applications and features.</p>
<p>There's a blogging platform called
<a href="http://www.phabricator.com/docs/phabricator/article/Phame_User_Guide.html">Phame</a>.</p>
<p>There's a simple wiki called
<a href="http://www.phabricator.com/docs/phabricator/article/Phriction_User_Guide.html">Phriction</a>.</p>
<p>There's a simple polling application called
<a href="http://www.phabricator.com/docs/phabricator/article/Slowvote_User_Guide.html">Slowvote</a>.</p>
<p>There's a mechanism to upload and view files.</p>
<p>There's a pastebin-like application called Paste. It integrates with
authentication and authorization, so you can limit the audience of
pastes.</p>
<p>There's a JSON over HTTP API that allows you to do nearly everything.
(I assume this is what Arcanist uses for everything.)</p>
<p>There's a built-in badges mechanism called Tokens.</p>
<p>You can exchange messages and chats with other users (similar to IRC)
using Conpherence.</p>
<p>There is a question and answer application called Ponder. People ask
questions and other people answer them. You can search questions, of
course. This helps build up a searchable knowledge base.</p>
<p>There is a mockups viewing and collaboration tool called Pholio. You can
upload mockups as photos and then annotate images through the web
interface. e.g. you can create a rectangle and ask a question about what
you see in that rectangle.</p>
<p>There is a time tracking application called Phrequent.</p>
<p>Phabricator can receive inbound email to update issues, reviews, etc.
You can even file new bugs via email! Having used an email interface to
Bugzilla at a previous job, I can say from experience this is extremely
useful.</p>
<p>Phabricator allows you to cherry pick which applications you have
enabled. Want just code review and repository browsing without issue
tracking? You can do that.</p>
<h2>Test instance for Mozilla</h2>
<p>As I alluded to above, I have installed an instance of Phabricator on
EC2. My intention for this instance is for Mozillians to start playing
with it and seeing if it's something they'll like.</p>
<p>The test instance is available at
<a href="http://phabricator.gregoryszorc.com/">http://phabricator.gregoryszorc.com/</a>.</p>
<p>You can log in using OAuth with one of the configured service providers
or by creating an account. Please note that I'm only serving on plain
HTTP, so your password are sent in the clear.</p>
<p>I have configured a few popular Mozilla repositories with the install.
It's easy to configure new repositories. Send me their info and I'll add
them!</p>
<p>While the web UI is nice, Arcanist is essential to get the most out of
Phabricator. To get <em>arc</em> working with your machine, follow the
<a href="http://www.phabricator.com/docs/phabricator/article/Arcanist_Quick_Start.html">official instructions</a>
to install Arcanist. For your <em>.arcconfig</em> file, use something like:</p>
<pre><code>{
  "project_id": "gecko",
  "conduit_uri": "http://phabricator.gregoryszorc.com/"
}
</code></pre>
<p>Then, have Arcanist fetch authentication credentials:</p>
<pre><code>$ arc install-certificate
</code></pre>
<p>From there, run <em>arc help</em> and see what you can do!</p>
<p>Of course, you'll need to adjust the <em>project_id</em> when appropriate.</p>
<p>When you use this Phabricator instance, please keep the following in
mind:</p>
<ul>
<li>I'm hosting this on my own dime and have the most powerful EC2
  instance I felt like paying out of pocket. That instance sadly isn't
  powerful enough. I installed Phabricator on my desktop at home and it
  flies like a rocket ship. Please don't blame slowness on Phabricator.</li>
<li>I didn't even attempt to tune the HTTP or MySQL servers yet. Expect
  more slowness.</li>
<li>The service and all the data inside could go away at any time. I don't
  have monitoring of the service (yet). <strong>Use at your own risk.</strong></li>
<li>At the time I wrote this, Phabricator was still indexing some
  repositories, notably mozilla-central. Anything interacting with
  source navigation appears to be slow as a result.</li>
<li>The install is effectively a vanilla, out-of-the-box install. Things
  like Mozilla styling could presumably be added. There are likely also
  many sub-par configuration settings. Leave comments and I'll see about
  changing things.</li>
<li>The front page insists on a sign-in. However, I believe all of the
  content should be accessible to the public. Contact me if you know of
  a way to fix this!</li>
<li>This could be hooked up with Persona. I couldn't find a Persona auth
  provider and coding one is beyond my current PHP skills. If someone
  writes one, let me know and I'll install it!</li>
<li>I could hook up authentication against Mozilla's LDAP server. However,
  I don't want your Mozilla credentials going to my personal server nor
  traveling over the wire in the clear.</li>
<li>I'm not an expert on Phabricator. I'll try to help where appropriate.
  But don't count on me being a support desk.</li>
</ul>
<h2>Next steps at Mozilla</h2>
<p>How should we use Phabricator at Mozilla? Good question!</p>
<p>I encourage people to play around with my personal instance. Upload some
patches. Perform some code reviews. Set up Herald rules to notify you of
repository change events. Just keep in mind that I don't guarantee an
SLA for my instance. So please don't rely on it.</p>
<p>I anticipate that people will come to the conclusion that Phabricator is
awesome and that Mozilla should install an officially supported instance
on a mozilla.org domain with proper hardware. I'll likely be reaching
out to IT shortly to see how feasible that is. But, I imagine it will
get shuffled to the bottom of the priority queue unless people make
noise. If you like Phabricator, tell other people about it. Let your
management chain know how amazing it is. If enough of or the right
people clamor for it, priorities can get changed.</p>
<p>I hope you enjoy Phabricator!</p>]]></content:encoded>
    </item>
    <item>
      <title>Why Firefox builds are slow</title>
      <link>http://gregoryszorc.com/blog/2013/10/01/why-firefox-builds-are-slow</link>
      <pubDate>Tue, 01 Oct 2013 01:30:00 PDT</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2013/10/01/why-firefox-builds-are-slow</guid>
      <description>Why Firefox builds are slow</description>
      <content:encoded><![CDATA[<p>Many people ask/complain about Firefox builds being slow. They are slow.
You have every right to complain.</p>
<p>Now in the <a href="https://ci.mozilla.org/job/mozilla-central-docs/Build_Documentation/index.html">official build system docs</a>
is a <a href="https://ci.mozilla.org/job/mozilla-central-docs/Build_Documentation/slow.html">page</a>
explaining the major reasons why the build system is slow. I encourage
everyone to read it. If you have any questions, ping me and I'll update
the docs.</p>
<p>Not yet documented there are some new insights we've been getting from
Mike Hommey's <a href="https://groups.google.com/d/msg/mozilla.dev.platform/4dp9WTQ6F60/9ypVOMk55zkJ">terrific work</a>
to optimize how make traversal works in the current build system.</p>
<p>As part of that work, Mike established a new <em>compile</em> tier in the build
system. This tier compiles C/C++ and little else. Before, C/C++
compiling was interleaved with all the other build steps (install JS
files, xpt processing, etc), so it was somewhat difficult to isolate the
impact of compilation against all other build actions.</p>
<p>Now that we have all compiling happening in one isolated phase, it's pretty
obvious that compiling accounts for the majority of CPU and wall time in
the build system (at least with non no-op builds). We suspected this
before, but we didn't have concrete numbers.</p>
<p>As I've been pulling and rebuilding inbound since this change landed,
it's become increasing clear to me the impact of header dependency hell
on build times. Even simple changesets touching a few .h files are
resulting in hundreds or even thousands of C/C++ files being recompiled.
This increases incremental build times from say 1.5 minutes to often
over 10 minutes.</p>
<p>With Mike Hommey's work, I feel we finally are on a path to make no-op
build times reasonable for many developers. However, until the header
dependency graph is significantly reduced, developers will continue to
see excessively long build times for incremental builds, especially on
pulls. (I notice that my daily inbound pulls take about as long as a
clobber build, which means practically every .cpp file is invalidated
every day due to .h changes.)</p>
<p>Fortunately, <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=785103">great work</a>
has been happening to minimize C/C++ header dependency hell recently.
To everyone working on that, everyone who builds Firefox owes you a
giant <strong>thank you</strong>. However, there's much more that can be done. While
you've made terrific progress, please don't slow down any time soon.</p>]]></content:encoded>
    </item>
  </channel>
</rss>

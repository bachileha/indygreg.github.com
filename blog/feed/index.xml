<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:wfw="http://wellformedweb.org/CommentAPI/"
     >
  <channel>
    <title>Gregory Szorc's Digital Home</title>
    <link>http://gregoryszorc.com/blog</link>
    <description>Rambling on</description>
    <pubDate>Sun, 25 Jan 2015 07:10:23 GMT</pubDate>
    <generator>Blogofile</generator>
    <sy:updatePeriod>hourly</sy:updatePeriod>
    <sy:updateFrequency>1</sy:updateFrequency>
    <item>
      <title>End to End Testing with Docker</title>
      <link>http://gregoryszorc.com/blog/2015/01/24/end-to-end-testing-with-docker</link>
      <pubDate>Sat, 24 Jan 2015 23:10:00 PST</pubDate>
      <category><![CDATA[Docker]]></category>
      <category><![CDATA[Mozilla]]></category>
      <category><![CDATA[testing]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2015/01/24/end-to-end-testing-with-docker</guid>
      <description>End to End Testing with Docker</description>
      <content:encoded><![CDATA[<p>I've written an extensive testing <em>framework</em> for Mozilla's
<a href="https://mozilla-version-control-tools.readthedocs.org/">version control tools</a>.
Despite it being a little rough around the edges, I'm a bit proud of it.</p>
<p>When you run tests for MozReview, Mozilla's heavily modified
<a href="https://www.reviewboard.org/">Review Board</a> code review tool, the
following things happen:</p>
<ul>
<li>A MySQL server is started in a Docker container.</li>
<li>A Bugzilla server (running the same code as
  <a href="https://bugzilla.mozilla.org/">bugzilla.mozilla.org</a>) is started on
  an Apache httpd server with mod_perl inside a Docker container.</li>
<li>A RabbitMQ server mimicking
  <a href="https://pulse.mozilla.org/">pulse.mozilla.org</a> is started in a Docker
  container.</li>
<li>A Review Board Django development server is started.</li>
<li>A Mercurial HTTP server is started</li>
</ul>
<p>In the future, we'll likely also need to add support for various other
services to support MozReview and other components of version control
tools:</p>
<ul>
<li>The Autoland HTTP service will be started in a Docker container, along
  with any other requirements it may have.</li>
<li>An IRC server will be started in a Docker container.</li>
<li>Zookeeper and Kafka will be started on multiple Docker containers</li>
</ul>
<p>The entire setup is pretty cool. You have actual services running on
your local machine. Mike Conley and Steven MacLeod even did some pair
coding of MozReview while on a plane last week. I think it's pretty cool
this is even possible.</p>
<p>There is very little mocking in the tests. If we need an external
service, we try to spin up an instance inside a local container.
This way, we can't have unexpected test successes or failures due to
bugs in mocking. We have very high confidence that if something works
against local containers, it will work in production.</p>
<p>I currently have each test file owning its own set of Docker
containers and processes. This way, we get full test isolation and can
run tests concurrently without race conditions. This drastically reduces
overall test execution time and makes individual tests easier to reason
about.</p>
<p>As cool as the test setup is, there's a bunch I wish were better.</p>
<p>Spinning up and shutting down all those containers and processes takes a
lot of time. We're currently sitting around 8s startup time and 2s
shutdown time. 10s overhead per test is unacceptable. When I make a one
line change, I want the tests to be instantenous. 10s is too long for
me to sit idly by. Unfortunately, I've already gone to great pains to
make test overhead as short as possible.
<a href="http://www.fig.sh/">Fig</a> wasn't good enough for me for various reasons.
I've reimplemented my own orchestration directly on top of the
<a href="https://docker-py.readthedocs.org/en/latest/">docker-py package</a> to
achieve some significant performance wins. Using
<a href="http://pythonhosted.org//futures/">concurrent.futures</a> to perform
operations against multiple containers concurrently was a big win.
<em>Bootstrapping</em> containers (running their first-run entrypoint scripts
and committing the result to be used later by tests) was a bigger win
(first run of Bugzilla is 20-25 seconds).</p>
<p>I'm at the point of optimizing startup where the longest pole is the
initialization of the services inside Docker containers themselves.
MySQL takes a few seconds to start accepting connections. Apache +
Bugzilla has a semi-involved initialization process. RabbitMQ takes
about 4 seconds to initialize. There are some cascading dependencies in
there, so the majority of startup time is waiting for processes to
finish their startup routine.</p>
<p>Another concern with running all these containers is memory usage. When
you start running 6+ instances of MySQL + Apache, RabbitMQ, + ..., it
becomes really easy to exhaust system memory, incur swapping, and have
performance fall off a cliff. I've spent a non-trivial amount of time
figuring out the minimal amount of memory I can make services consume
while still not sacrificing too much performance.</p>
<p>It is quite an experience having the problem of trying to minimize
resource usage and startup time for various applications. Searching the
internet will happily give you recommended settings for applications.
You can find out how to make a service start in 10s instead of 60s or
consume 100 MB of RSS instead of 1 GB. But what the internet won't tell
you is how to make the service start in 2s instead of 3s or consume as
little memory as possible. I reckon I'm past the point of diminishing
returns where most people don't care about any further performance wins.
But, because of how I'm using containers for end-to-end testing and I
have a surplus of short-lived containers, it is clearly I problem I need
to solve.</p>
<p>I might be able to squeeze out a few more seconds of reduction by
further optimizing startup and shutdown. But, I doubt I'll reduce things
below 5s. If you ask me, that's still not good enough. I want no more
than 2s overhead per test. And I don't think I'm going to get that
unless I start utilizing containers across multiple tests. And I really
don't want to do that because it sacrifices test purity. Engineering is
full of trade-offs.</p>
<p>Another takeaway from implementing this test harness is that the
pre-built Docker images available from the Docker Registry almost always
become useless. I eventually make a customization that can't be
shoehorned into the readily-available image and I find myself having
to reinvent the wheel. I'm not a fan of the <em>download and run a binary</em>
model, especially given Docker's less-than-stellar history on the
security and cryptography fronts (I'll trust Linux distributions to get
package distribution right, but I'm not going to be trusting the Docker
Registry quite yet), so it's not a huge loss. I'm at the point where
I've lost faith in Docker Registry images and my default position is to
implement my own builder. Containers are supposed to do one thing, so
it usually isn't that difficult to roll my own images.</p>
<p>There's a lot to love about Docker and containerized test execution. But
I feel like I'm foraging into new territory and solving problems
like startup time minimization that I shouldn't really have to be
solving. I think I can justify it given the increased accuracy from the
tests and the increased confidence that brings. I just wish the cost
weren't so high. Hopefully as others start leaning on containers and
Docker more for test execution, people start figuring out how to make
some of these problems disappear.</p>]]></content:encoded>
    </item>
    <item>
      <title>Bugzilla and the Future of Firefox Development</title>
      <link>http://gregoryszorc.com/blog/2015/01/16/bugzilla-and-the-future-of-firefox-development</link>
      <pubDate>Fri, 16 Jan 2015 10:50:00 PST</pubDate>
      <category><![CDATA[Bugzilla]]></category>
      <category><![CDATA[Mozilla]]></category>
      <category><![CDATA[code review]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2015/01/16/bugzilla-and-the-future-of-firefox-development</guid>
      <description>Bugzilla and the Future of Firefox Development</description>
      <content:encoded><![CDATA[<p><a href="https://bugzilla.mozilla.org">Bugzilla</a> has played a major role in the
Firefox development process for over 15 years. <strong>With upcoming changes
to how code changes to Firefox are submitted and reviewed, I think it is
time to revisit the central role of Bugzilla and bugs in the Firefox
development process.</strong> I know this is a contentious thing to say. Please,
gather your breath, and calmly read on as I explain why I believe this.</p>
<p>The current Firefox change process defaults to requiring a Bugzilla bug
for everything. It is rare (and from my experience frowned upon) when a
commit to Firefox doesn't reference a bug number. We've essentially made
Bugzilla and a bug prerequisites for changing anything in the Firefox
version control repository. For the remainder of this post, I'm going to
say that we <em>require</em> a bug for any change, even though that statement
isn't technically accurate. Also, when I say <em>Bugzilla</em>, I mean
<em>bugzilla.mozilla.org</em>, not the generic project.</p>
<p>Before I go on, let's boil the Firefox change process down to basics.</p>
<p>At the heart of any change to the Firefox source repository is a diff.
The diff (a representation of the differences between a set of files)
is the smallest piece of data necessary to represent a change to the
Firefox code. I argue that anything more than the vanilla diff is
overhead and could contribute to
<a href="/blog/2015/01/09/firefox-contribution-process-debt/">process debt</a>.
Now, there is some essential overhead. Version control tools supplement
diffs with metadata, such as the author, commit message, and date. Mozilla
has also instituted a near-mandatory code review policy, where changes
need to be signed off by a set of trusted individuals. I view both of
these additions to the vanilla diff as essential for Firefox development
and non-negotiable. Therefore, the bare minimum requirements for changing
Firefox code are a diff plus metadata (a commit/patch) and (almost
always) a review/sign-off. That's it. Notably absent from this list is a
Bugzilla bug. <strong>I argue that a bug is not strictly required to
change Firefox.</strong> Instead, we've instituted a near-universal policy
that we should have bugs. We've <strong>chosen</strong> to add overhead and process
debt - interaction with Bugzilla - to our Firefox change process.</p>
<p>Now, this choice to require all changes be associated with bugs has its
merits. Bugs provide excellent anchor points for historical context and
for additional information after the change has been committed and is
forever set in stone in the repository (commits are immutable in
Mercurial and Git and you can't easily attach metadata to the commit
after the fact). Bugs are great to track relationships between different
problems or units of work. Bugs can even be used to track progress
towards a large feature. Bugzilla components also provide a decent
mechanism to follow related activity. There's also a lot of tooling and
familiar process standing on top of the Bugzilla <em>platform</em>. There's a
lot to love here and I don't want diminish the importance of all these
things.</p>
<p><strong>When I look to the future, I see a world where the current, central
role of Bugzilla and bugs as part of the Firefox change process begin to
wane.</strong> I see a world where the benefits to maintaining our current
Bugzilla-centric workflow start to erode and the cost of maintaining
it becomes higher and harder to justify. You actually don't have to look
too far into the future: that world is already here and I've already
started to feel the pains of it.</p>
<p>A few days ago, I blogged about
<a href="/blog/2015/01/10/code-first-and-the-rise-of-the-dvcs-and-github/">GitHub and its code first approach to change</a>.
That post was spun off from an early draft of this post (as were the
posts about <a href="/blog/2015/01/09/firefox-contribution-process-debt/">Firefox contribution debt</a>
and <a href="/blog/2015/01/12/utilizing-github-for-firefox-development/">utilizing GitHub for Firefox development</a>).
I wanted to introduce the concept of <em>code first</em> because it is
central to my justification for changing how we do things. In summary,
<strong>code first capitalizes on the fact that any change to software
involves code and therefore puts code front and center in the change
process.</strong> (In hindsight, I probably should have used the term <em>code
centric</em>, because that's how I want people to think about things.) So
how does <em>code first</em> relate to Bugzilla and Firefox development?</p>
<p>Historically, code review has occurred in Bugzilla: upload a patch to
Bugzilla, ask for review, and someone will look at it. And, since
practically every change to Firefox requires review, you need a bug in
Bugzilla to contain that review. Thus, <strong>one way to view a bug is as a
vehicle for code review</strong>. Not every bug is <em>just</em> a code review, of
course. But a good number of them are.</p>
<p>The only constant is change. And <strong>the way Mozilla conducts code review
for changes to Firefox (and other projects) is changing</strong>. We now have
<a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/mozreview.html">MozReview</a>,
a code review tool that is <em>not Bugzilla</em>. If we start accepting GitHub
pull requests, we <em>may</em> perform reviews exclusively on GitHub, another
tool that is <em>not Bugzilla</em>.</p>
<p>(Before I go on, I want to quickly point out that MozReview is nowhere
close to its final form. Parts of MozReview are pretty bad right now.
The maintainers all know this and we have plans to fix it. We'll be in
Toronto all of next week working on it. If you don't think you'll ever
use it because parts are bad today, I ask you to withhold judgement for
a few more months.)</p>
<p>In case you were wondering, the question on whether Bugzilla should
always be used for code review for Firefox has been answered and that
answer is <em>no</em>. People, including maintainers of Bugzilla, realized
that better-than-Splinter/Bugzilla code review tools exist and that
continuing to invest time to develop Bugzilla/Splinter into a
best-in-class code review tool would be better spent <em>integrating</em>
Bugzilla with an existing tool. This is why we now have a
<a href="https://www.reviewboard.org/">Review Board</a> based code review tool -
MozReview - integrated with Bugzilla. If you care about code quality and
more powerful workflows, you should be rejoicing at this because
<a href="/blog/2014/10/27/implications-of-using-bugzilla-for-firefox-patch-development/">the implementation of code review in Bugzilla does not maximize optimal outcomes</a>.</p>
<p>The world we're moving to is one where code review occurs outside of
Bugzilla. This raises an important question: <strong>if Bugzilla was being used
primarily as a vehicle for code review, what benefit and/or role should
Bugzilla play when code review is conducted outside of Bugzilla?</strong></p>
<p><strong>I posit that there are a class of bugs that won't need to exist
going forward because bugs will provide little to no value.</strong> Put
another way, I believe that a growing number of commits to the Firefox
repository won't reference bugs.</p>
<p>Come with me on a journey to the future.</p>
<p>MozReview is purposefully being designed in a code and repository
centric way. To initiate the formal process for considering a change to
code, you push to a Mercurial (or Git!) repository. This could be
directly to Mozilla's review repository. If I have my way, this could
even be kicked off by submitting a pull request on GitHub or Bitbucket.
No Bugzilla attachment uploading here: our systems talk in terms of
repositories and commits. Again, this is by design: we don't want
submitting code to Mozilla to be any harder than <em>hg push</em> or <em>git
push</em> so as to not introduce <em>process debt</em>. If you have code, you'll be
able to send it to us.</p>
<p>In the near future, MozReview will stop cross-posting detailed review
updates to Bugzilla. Instead, we'll use Review Board's e-mail feature
to send its flavor of emails. These will have rich HTML content (or
plain text if you insist) and will provide a better experience
than Bugzilla ever will. We'll adopt the model of tools like
Phabricator and GitHub and only post summaries or links of activity,
not full content, to bugs. You may be familiar with the concept as
applied to the web: it's called hyperlinking.</p>
<p>Work is being invested into Autoland. Autoland is an automated landing
queue that pushes/lands commits semi-automatically once they are ready
(have review, pass automation, etc). Think of Autoland as a bot that
does all the labor intensive and menial actions around pushing that
you do now. I believe Autoland will eventually handle near 100% of
pushes to the Firefox repository. And, if I have my way, Autoland will
result in the abolishment of <em>integration branches</em> and merge commits in
the Firefox repository. Good riddance.</p>
<p>MozReview and Autoland will be highly integrated. MozReview will be the
primary user interface for interacting with Autoland. (Some of this
should be in place by the end of the quarter.)</p>
<p>In this world, MozReview and its underlying version control repositories
essentially become a <em>database</em> of all submitted, pending, and discarded
commits to Firefox. The metaphorical <em>primary keys</em> of this <em>database</em>
are not bug numbers: they are code/commits. (Code first!) Some of the
flags stored in this <em>database</em> tell Autoland what it should do. And the
MozReview user interface (and API) provide a mechanism into controlling
those flags.</p>
<p>Landing a change in Firefox will be initiated by a simple action such as
clicking a checkbox in MozReview. (That could even be the <em>Grant Review</em>
checkbox.) Commits cleared for landing will be picked up by
Autoland and eventually automatically pushed to the Firefox repository
(assuming the build and test automation is happy, of course). Once
Autoland takes control, humans are just passengers. We won't be bothered
with menial tasks like updating the commit message to reflect a review
was performed: this will happen automatically inside MozReview or
Autoland. (Although, there's a chance we may adopt some PGP-based
signing to more strongly convey review for some code changes in order to
facilitate stronger auditing and trust guarantees. Stay tuned.)
Likewise, if a commit becomes associated with a bug, we can add that
metadata to the commit before it is landed, no human involvement
necessary beyond specifying the link in the MozReview web UI (or API).
Autoland/MozReview will close review requests and/or bugs automatically.
(Are you excited about performing less work yet?)</p>
<p>When commits are added to MozReview, <strong>MozReview will read metadata from
the repository they came from to automatically determine an appropriate
reviewer</strong>. (We <a href="https://groups.google.com/d/msg/mozilla.dev.platform/iXr70VgapWk/GkTCcKRjNi8J">plan</a>
to leverage moz.build files for this in the case of Firefox.) This
should eliminate a lot of <em>process debt</em> around choosing a reviewer.
<strong>Similar metadata will also be used to determine what Bugzilla component
a change is related to, static analysis rules to use to critique the
phsyical structure of the change, and even automation jobs that should
be executed given the set of files that changed.</strong> The use of this
metadata will erode significant <em>process debt</em> around the change
contribution workflow.</p>
<p>As commits are pushed into MozReview/Autoland, the systems will be
intelligent about automatically tracking dependencies and facilitating
complex development workflows that people run into on a daily basis.</p>
<p>If I create a commit on top of someone else's commit that hasn't been
checked in yet, MozReview will detect the dependency between
my changes and the parent ones. This is an advantage of being code
first: by interfacing with repositories rather than patch files, you
have an explicit dependency graph embedded in the repository commit DAG
that can be used to aid machines in their activities.</p>
<p>It will also be possible to partially land a series of commits. If I get
review on the first 5 of 10 commits but things stall on commit 6, I can ask
Autoland to land the already-reviewed commits so they don't get bit
rotted and so you have partial progress (psychological studies show that
a partial reward for work results in greater happiness through a sense
of accomplishment).</p>
<p>Since initiating actions in MozReview is light weight (just <em>hg push</em>),
itch scratching is encouraged. I don't know about you, but in the course
of working on the Firefox code base, I frequently find myself wanting to
make small, 15-30s changes to fix something really minor. In today's world,
the overhead for these small changes is often high. I need to upload a
separate patch to Bugzilla. Sometimes I even need to create a new bug to
hold that patch. If that patch depends on other work I did, I need to
set up bug dependencies then worry about landing everything in the right
order. All of a sudden, the overhead isn't worth it and my positive
intentions go unacted on. Multiplied by hundreds of developers over
many years, and you can imagine the effect on software quality. With
MozReview, the overhead for itch scratching like this is minor. Just
make a small commit, push, and the system will sort everything out.
(These small commits are where I think a <em>bugless</em> process really
shines.)</p>
<p>This future world revolves around code and commits and operations on
them. While <em>MozReview</em> has <em>review</em> in its name, it's more than a
review tool: it's a <em>database</em> and interface to code and its state.</p>
<p><strong>In this code first world, Bugzilla performs an ancillary role.</strong>
Bugzilla is still there. Bugs are still there. MozReview review requests
and commits <em>link</em> to bugs. But it is the code, not bugs, that are king.
If you want to do anything with code, you interact with the code
tools. And Bugzilla is not one of them.</p>
<p>Another way of looking at this is that nearly everything involving code
or commits becomes excised from Bugzilla. This would relegate Bugzilla
to, well, an issue/bug tracker. And - ta da - that's something it excels
at since that's what it was originally designed to do! MozReview will
provide an adequate platform to discuss code (a platform that Bugzilla
provides today since it hosts code review). So if <em>not Bugzilla</em>
tools are handling everything related to code, do you really need a bug
any more?</p>
<p>This is the future we're trying to build with MozReview and Autoland.
And this is why I think bugs and Bugzilla will play a less central role
in the development process of Firefox in the future.</p>
<p>Yes, there are many consequences and concerns about making this shift.
You would be rational to be skeptical and doubt that this is the right
thing to do. I have another post in the works that attempts to outline
some common conerns and propose solutions to many of them. Before writing
a long comment pointing out every way in which this will fail to work,
I encourage you to wait for that post to be published. Stay tuned.</p>]]></content:encoded>
    </item>
    <item>
      <title>Modern Mercurial Documentation for Mozillians</title>
      <link>http://gregoryszorc.com/blog/2015/01/15/modern-mercurial-documentation-for-mozillians</link>
      <pubDate>Thu, 15 Jan 2015 14:45:00 PST</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2015/01/15/modern-mercurial-documentation-for-mozillians</guid>
      <description>Modern Mercurial Documentation for Mozillians</description>
      <content:encoded><![CDATA[<p>Mozilla's Mercurial documentation has historically been pretty bad. The
documentation on MDN (which I refuse to link to) is horribly disjointed
and contains a lot of outdated recommendations. I've made attempts to
burn some of it to the ground, but it is just too overwhelming.</p>
<p>I've been casually creating my own Mercurial documentation tailored for
Mozillians. It's called
<a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmozilla/index.html">Mercurial for Mozillians</a>.</p>
<p>It started as a way to document extensions inside the
<a href="https://hg.mozilla.org/hgcustom/version-control-tools/">version-control-tools</a>
repository. But, it has since evolved to cover other topics, like how to
install Mercurial, how to develop using bookmarks, and how to interact
with a unified Firefox repository. The documentation is nowhere near
complete. But it already has some very useful content beyond what MDN
offers.</p>
<p>I'm not crazy about the idea of having generic Mercurial documentation
on a Mozilla domain (this should be part of the official Mercurial
documentation). Nor am I crazy about moving content off MDN. I'm sure
content will move to its appropriate location later. Until then,
enjoy some curated Mercurial documentation!</p>
<p>If you would like to contribute to Mercurial for Mozillians,
<a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/contributing.html">read the docs</a>.</p>]]></content:encoded>
    </item>
    <item>
      <title>Major bzexport Updates</title>
      <link>http://gregoryszorc.com/blog/2015/01/13/major-bzexport-updates</link>
      <pubDate>Tue, 13 Jan 2015 15:55:00 PST</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2015/01/13/major-bzexport-updates</guid>
      <description>Major bzexport Updates</description>
      <content:encoded><![CDATA[<p>The <em>bzexport</em> Mercurial extension - an extension that enables you to
easily create new Bugzilla bugs and upload patches to Bugzilla for
review - just received some
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1033394">major updates</a>.</p>
<p>First, we now have automated test coverage of bzexport! This is built on
top of the version control test harness I
<a href="/blog/2014/10/14/robustly-testing-version-control-at-mozilla/">previously blogged about</a>.
As part of the tests, we start Docker containers that run the same code
that's running on <a href="https://bugzilla.mozilla.org/">bugzilla.mozilla.org</a>,
so interactions with Bugzilla are properly tested. This is much, much
better than mocking HTTP requests and responses because if Bugzilla
changes, our tests will detect it. Yay continuous integration.</p>
<p>Second, bzexport now uses Bugzilla' REST API instead of the legacy bzAPI
endpoint for all but 1 HTTP request. This should make BMO maintainers
very happy.</p>
<p>Third and finally, bzexport now uses shared code for obtaining Bugzilla
credentials. The behavior is
<a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmozilla/auth.html">documented</a>,
of course. Behavior is <strong>not backwards compatible</strong>. If you were using some
old configuration values, you will now see warnings when running bzexport.
These warnings are actionable, so I shouldn't need to describe them
here.</p>
<p>Please obtain the new code by pulling the
<a href="https://hg.mozilla.org/hgcustom/version-control-tools">version-control-tools</a>
repository. Or, if you have a Firefox clone, run <em>mach mercurial-setup</em>.</p>
<p>If you find any regressions, file a bug in the
<a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Developer%20Services&amp;component=Mercurial%3A%20bzexport">Developers Services :: Mercurial: bzexport</a>
component and have it depend on
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1033394">bug 1033394</a>.</p>
<p>Thanks go out to Steve Fink, Ed Morley, and Ted Mielczarek for looking
at the code.</p>]]></content:encoded>
    </item>
    <item>
      <title>Utilizing GitHub for Firefox Development</title>
      <link>http://gregoryszorc.com/blog/2015/01/12/utilizing-github-for-firefox-development</link>
      <pubDate>Mon, 12 Jan 2015 11:00:00 PST</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2015/01/12/utilizing-github-for-firefox-development</guid>
      <description>Utilizing GitHub for Firefox Development</description>
      <content:encoded><![CDATA[<p>Recent posts on my blog have talked about the
<a href="/blog/2015/01/09/firefox-contribution-process-debt/">difficulty submitting changes to Firefox</a>
and the <a href="/blog/2015/01/10/code-first-and-the-rise-of-the-dvcs-and-github/">rise of GitHub</a>.
I encourage you to stop reading this post and read them now if you
haven't already.</p>
<p>As I was looking at the
<a href="/blog/2015/01/09/firefox-contribution-process-debt/#list-of-process-debt">list of process debt contributing to Firefox</a>,
one thought kept creeping into my mind: <strong>how many of these items go
away if we utilize GitHub?</strong></p>
<p>As I mentioned in these two posts, GitHub's popularity has essentially
commoditized many items on this list, especially the parts around source
control and submitting patches for consideration (just fork and open a
pull request). It seems that everyone these days is on GitHub and asking
people to use GitHub to send changes to Firefox would almost certainly
be well-received by contributors and even Mozilla staff.</p>
<p>Here's what I think: <strong>Mozilla should utilize GitHub for Firefox
development.</strong></p>
<p>The verb in that sentence is important: I purposefully said <em>utilize</em>
and not something like <em>switch to</em>. <strong>To switch or not to switch to
GitHub for Firefox development is a false dillemma and a logical
fallacy.</strong> So is the question about <em>switching to Git</em>. As I explain later,
there is a spectrum of options available and <em>switching</em> or <em>not
switching</em> are on the extremes. <em>Utilize</em> doesn't preclude a binary
<em>switch</em> or <em>don't switch</em> outcome, but it does keep an array of options
on the table for consideration.</p>
<p>So, how should Mozilla <em>utilize</em> GitHub for Firefox development?</p>
<p>I think that insisting people establish Bugzilla accounts and upload
patches to Bugzilla/bugs is an anitquated practice in desperate need of
an overhaul. I think that if someone has written code, they should be
able to essentially throw it over a wall to initiate the change process.
They should be able to do this in a manner that incurs little to no
<em>process debt</em>. We, Mozilla, should be able to take only code and
integrate it into Firefox, assuming a trusted person - a module owner
or peer - agrees and grants review. <strong>GitHub pull requests would
facilitate a lesser-involved code contribution mechanism.</strong></p>
<p>Another benefit of GitHub is that the web interface goes further than
just code submission: they also have facilities for editing files. It's
possible to
<a href="https://help.github.com/articles/editing-files-in-another-user-s-repository/">edit a file in someone else's repository and create a pull request</a>
direct from the web interface! My
<a href="/blog/2015/01/09/firefox-contribution-process-debt/">post on process debt</a>
began by comparing the process of <em>edit a wiki</em> versus the current
Firefox change process. GitHub's web-based editing essentially reduces
the gap to cosmetic differences. <strong>GitHub's ease of contributing purely
via the browser would open the door to more contribution for
lesser-involved changes</strong> (sometimes referred to as <em>good first bugs</em>).</p>
<p>To state it explicitly, <strong>I support the use of GitHub pull requests for
submitting changes to Firefox</strong>.</p>
<p>Now, there are some concerns and challenges about doing this. These
include:</p>
<ul>
<li>Fragmentation of code review and tracking could be problematic for
  Mozilla staff and other highly-active individuals.</li>
<li>GitHub can lose some parts of code review after rebasing and force
  pushes. <strong>Edit: Comments below indicate this is no longer a problem.
  Great!</strong></li>
<li>You can only assign 1 reviewer per pull request.</li>
<li>GitHub sends an email/notification per review comment. This can be
  extremely annoying for some mail clients.</li>
<li>GitHub doesn't have a mechanism for dealing with security bugs.</li>
<li>Data sovereignty concerns (all data hosted on GitHub and subject to
  their data retention and access policies). Their API has query limits,
  which can limit machine use somewhat.</li>
<li>GitHub's model favors merges over rebases. Merges have a number of
  downsides, especially for large projects, and we strongly prefer to
  maintain our mostly-linear Firefox repository history.</li>
<li>GitHub's model favors appending commits rather than rewriting commits.
  (This is due to Git badness when you force push.) Mozilla favors a
  world where the final commit is what's reviewed and landed.</li>
<li>Git != Mercurial. Firefox is canonically stored in Mercurial. There is
  some impedence mismatch here. But nothing tools can't overcome.</li>
<li>The <em>Merge Pull Request</em> button is almost completely useless for
  Firefox's existing and future workflows. This partially invalidates
  other niceness the pure GitHub pull request workflow buys you.</li>
<li>Everything is lumped into a single bucket. We lose component-level
  subscriptions, making following harder.</li>
<li>Following the entire Firefox project on GitHub would produce an
  overwhelming fire hose of data.</li>
<li>We don't control GitHub and our options for extending it to extract
  even more process optimization are limited to what their APIs support
  and what they choose to implement.</li>
<li>We are at the whim of GitHub should they ever change a feature or API.</li>
<li>See also <a href="https://github.com/servo/servo/wiki/Github-challenges">Servo's list of challenges</a>.</li>
</ul>
<p>Some of these issues can be overcome by tools and automation (which I
would happily build in my capacity as a Developer Productivity Engineer
at Mozilla). Others are more fundamental and seemingly would require
buy-in and/or support from very senior Mozillians.</p>
<p>If Mozilla were to go forward utilizing GitHub pull requests for
Firefox, I think it should be done incrementally rather than going
all-in and attempting the entire GitHub workflow from the start.
Although, this would mean diverging from GitHub's well-known practices,
which would <em>increase</em> process debt from the GitHub base level. I don't
like that. But I think it is a step in the right direction. Partial
reduction in process debt is better than no reduction.</p>
<p>What do I mean by <em>incrementally</em> start accepting pull requests? Well,
<strong>I don't think code review should initially be conducted on GitHub</strong>.
When you look at the above list of concerns, many of them are around code
review and interacting with pull requests. I think there's too much
badness and risk there to make me comfortable about <em>moving</em> things to
GitHub and giving GitHub exclusive domain over this important data,
at least initially.</p>
<p>But if code review isn't conducted on GitHub, what's the value of a pull
request? <strong>A pull request would be a well-defined and well-understood
mechanism for importing data into Mozilla's systems</strong>. For example,
submitting a pull request would automatically result in the creation
of a review request on
<a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/mozreview.html">MozReview</a>
or even a bug/attachment/review on Bugzilla.
This would allow people to send code to Mozilla easily while
simultaneously allowing Mozillians to use familiar tools and processes
without the aforementioned concerns with GitHub. That appears to be
win-win.</p>
<p>Once we have a simple mechanism in place for turning pull requests into
MozReview's review requests, we can start playing around with the
syncing of code review activity between Mozilla and GitHub so review
activity on either system results in cross-posting. There is precedent
for this today. <a href="http://gerrithub.io/">GerritHub</a> has bi-directional
syncing of code review activity between GitHub and Gerrit. Facebook also
does something similar, syncing data between their internal Phabricator
instance. Mozilla to GitHub sync would not be difficult: we control all
those systems and I'm pretty confident in our ability to make a GitHub API
call when a MozReview review request is updated (we already make
Bugzilla API calls, so we know this works). GitHub to Mozilla is a bit more
difficult. But, others have done it: I'm confident we can too.</p>
<p>I see bi-directional syncing of GitHub pull request / code review data
between GitHub and Mozilla as achievable and relatively free from
controversy. I think we should experiment with this sometime in 2015,
probably in Q2, once MozReview is in better condition to <em>host</em> GitHub
pull requests. Although, supporting Git in MozReview is on my Q1 goals
list, so maybe I sneak this into Q1. Time will tell.</p>
<p>At this time, I believe using GitHub for the ingestion of proposed
Firefox commits into existing Mozilla systems should be the limit of
Firefox's GitHub presence, at least as far as day-to-day development
goes. If other groups want to use GitHub more actively and they find a
way to make that work while placating everyone who cares, power to them.
But I think moving the pendulum any further toward GitHub - including
things like making GitHub the exclusive location for code review data,
utilizing GitHub Issues, and making Git[Hub] the canonical Firefox
repository - remain difficult and controverial propositions. I believe
each of these to be medium to high cost and risk with low to medium
reward. I believe it would be wise to defer these questions until we
have data about the value of GitHub pull requests for Firefox
development.</p>
<p>To summarize, I propose using GitHub pull requests as an alternate,
supported front end to the code contribution pathway. We would eliminate
a lot of <em>process debt</em> for non-Mozillians by supporting a known process.
Mozillians on the review and code submission side of the process
shouldn't have to worry about change because, well, it shouldn't matter
if a commit came from GitHub or elsewhere: it will all appear mostly
the same. I'm not saying that we will never expand our utilization
of GitHub for Firefox development beyond this scope. But I am saying
that I don't think it would be prudent to do so today.</p>
<p>And that's how and why I think Mozilla should utilize GitHub for Firefox
development.</p>
<h2>Addendum</h2>
<p>While I'm here, <strong>it's important to note that GitHub does not and will
likely never solve many items from our list of Firefox contribution
process debt</strong>. GitHub is not a build system nor a tool for running
and analyzing code and tests. We still have many, many deficiencies
and usability concerns here. We have historically under-invested in
this area and utilizing GitHub in any capacity won't address these
other issues. In addition, <strong>Firefox is a magnitude larger and more
complex than the vast majority of projects on GitHub. We will always
be burdened with the cost of our success - of coping with and
maintaining the additional complexity associated with that scale</strong>.
Firefox is <em>at least</em> the 0.1%. There's a good chance GitHub and/or many
of the amazing services associated with it (like Travis-CI) won't scale to
our needs. I'd love to be proved wrong here, but the reality is
supporting a marginal use case like Firefox likely isn't at the top of
goals for GitHub and related organizations unless it is in their
business interest (read: financial interest) to do so. One can hope that
as these companies try to capture more of the enterprise market via
offerings such as GitHub Enterprise that they invest in the features
and scalability that large projects and organizations like Mozilla and
Firefox need.</p>]]></content:encoded>
    </item>
    <item>
      <title>Code First and the Rise of the DVCS and GitHub</title>
      <link>http://gregoryszorc.com/blog/2015/01/10/code-first-and-the-rise-of-the-dvcs-and-github</link>
      <pubDate>Sat, 10 Jan 2015 12:35:00 PST</pubDate>
      <category><![CDATA[Git]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2015/01/10/code-first-and-the-rise-of-the-dvcs-and-github</guid>
      <description>Code First and the Rise of the DVCS and GitHub</description>
      <content:encoded><![CDATA[<p>The ascendancy of GitHub has very little to do with its namesake tool,
Git.</p>
<p>What GitHub did that was so radical for its time and the strategy that
GitHub continues to execute so well on today is the approach of
putting <em>code first</em> and enabling change to be a frictionless process.</p>
<p>In case you weren't around for the pre-GitHub days or don't remember,
they were not pleasant. Tools around code management were a far cry
from where they are today (I still argue the tools are pretty bad, but
that's for another post). Centralized version control systems were
prevalent (CVS and Subversion in open source, Perforce, ClearCase,
Team Foundation Server, and others in the corporate world). Tools for
looking at and querying code had horrible, ugly interfaces and came out
of a previous era of web design and browser capabilities. It felt like
a chore to do anything, including committing code. Yes, the world
had awesome services like <a href="https://sourceforge.net/">SourceForge</a>,
but they weren't the same as GitHub is today.</p>
<p>Before I get to my central thesis, I want to highlight some supporting
reasons for GitHub's success. There were two developments in the second
half of the 2000s the contributed to the success of GitHub: the rises
of the distributed version control system (DVCS) and the modern web.</p>
<p>While distributed version control systems like Sun WorkShop TeamWare and
BitKeeper existed earlier, it wasn't until the second half of the 2000s
that DVCS systems took off. You can argue part of the reason for this
was open source: my recollection is there wasn't a well-known DVCS
available as free software before 2005. Speaking of 2005, it was a big
year for DVCS projects: Git, Mercurial, and Bazaar all had initial
releases. Suddenly, there were old-but-new ideas on how to do source
control being exposed to new and willing-to-experiment audiences. DVCS
were a critical leap from traditional version control because they
(theoretically) impose less process and workflow limitations on users.
With traditional version control, you needed to be online to commit,
meaning you were managing patches, not commits, in your local
development workflow. There were some forms of branching and merging,
but they were a far cry from what is available today and were often too
complex for mere mortals to use. As more and more people were exposed to
<em>distributed</em> version control, they welcomed its less-restrictive and
more powerful workflows. They realized that source control tools don't
have to be so limiting. <em>Distributed</em> version control also promised all
kinds of revamped workflows that could be harnessed. There were
potential wins all around.</p>
<p>Around the same time that open source DVCS systems were emerging, web
browsers were evolving from an application to render static pages to a
platform for running web <em>applications</em>. Web sites using JavaScript
to dynamically manipulate web page content (DHTML as it was known back
then) were starting to hit their stride. I believe it was GMail that
turned the most heads as to the full power of the <em>modern web</em>
experience, with its novel-for-its-time extreme reliance on
XMLHttpRequest for dynamically changing page content. People were
realizing that powerful, desktop-like applications could be built for
the web and could run everywhere.</p>
<p>GitHub launched in April 2008 standing on the shoulders of both the
emerging interest in the Git content tracking tool and the capabilities
of modern browsers.</p>
<p>I wasn't an early user of GitHub. My recollection is that GitHub was
mostly a Rubyist's playground back then. I wasn't a Ruby programmer, so
I had little reason to use GitHub in the early stages. But people did
start using GitHub. And in the spirit of Ruby (on Rails), GitHub moved
fast, or at least was projecting the notion that they were. While other
services built on top of DVCS tools - like Bitbucket - did exist back then,
GitHub seemed to have momentum associated with it. (Look at the archives
for <a href="https://github.com/blog">GitHub's</a> and
<a href="https://blog.bitbucket.org/">Bitbucket's</a> respective blogs. GitHub has
hundreds of blog entries; Bitbucket numbers in the dozens.) Developers
everywhere up until this point had all been dealing with sub-optimal tools
and workflows. Some of us realized it. Others hadn't. Many of those who
did saw GitHub as a beacon of hope: we have all these new ideas and new
potentials with distributed version control and here is a service under
active development trying to figure out how to exploit that. Oh, and
it's free for open source. Sign me up!</p>
<p>GitHub did capitalize on a market opportunity. They also capitalized on
the value of marketing and the perception that they were moving fast and
providing features that people - especially in open source - wanted.
This captured the early adopters market. But I think what really set
GitHub apart and led to the success they are enjoying today is their
<em>code first</em> approach and their desire to make contribution easy, and
even fun and sociable.</p>
<p>As developers, our job is to solve problems. We often do that by writing
and changing code. And this often involves working as part of a team, or
collaborating. To collaborate, we need tools. You eventually need some
processes. And as I
<a href="/blog/2015/01/09/firefox-contribution-process-debt/">recently blogged</a>,
this can lead to <em>process debt</em> and inefficiencies associated with them.</p>
<p>Before GitHub, the <em>process debt</em> for contributing to other projects was
high. You often had to subscribe to mailing lists in order to submit
patches as emails. Or, you had to create an account on someone's bug
tracker or code review tool before you could send patches. Then you had
to figure out how to use these tools and any organization or
project-specific extensions and workflows attached to them. It was quite
involved and a lot could go wrong. Many projects and organizations (like
Mozilla) still practice this traditional methology. Furthermore (and as
I've
<a href="/blog/2014/10/27/implications-of-using-bugzilla-for-firefox-patch-development/">written before</a>),
these traditional, single patch/commit-based tools often aren't
effective at ensuring the desired output of high quality software.</p>
<p>Before GitHub solved <em>process debt</em> via commoditization of knowledge via
market dominance, they took another approach: emphasizing <em>code first</em>
development.</p>
<p>GitHub is all about the <strong>code</strong>. You load a project page and you see
<strong>code</strong>. You may think a README with basic project information would be
the first thing on a <em>project</em> page. But it isn't. <em>Code</em>, like data,
is king.</p>
<p>Collaboration and contribution on GitHub revolve around the <em>pull
request</em>. It's a way of saying, <em>hey, I made a change, will you take
it?</em> There's nothing too novel in the concept of the <em>pull request</em>:
it's fundamentally no different than sending emails with patches to a
mailing list. But what is so special is GitHub's execution. Gone are
the days of configuring and using one-off tools and processes. Instead,
we have the friendly confines of a clean, friendly, and modern web
experience. While GitHub is built upon the Git tool, you don't even
need to use Git (a tool
<a href="http://git-man-page-generator.lokaltog.net/">lampooned</a>
for its
<a href="http://stevelosh.com/blog/2013/04/git-koans/">horrible usability and approachability</a>)
to contribute on GitHub! Instead, you can
<a href="https://help.github.com/articles/github-flow-in-the-browser/">do everything from your browser</a>.
That warrants repeating: <strong>you don't need to leave your browser to
contribute on GitHub</strong>. GitHub has essentially reduced <em>process debt</em>
to <em>edit a text document</em> territory, and pretty much anybody who has
used a computer can do that. This has enabled GitHub to dabble into
non-code territory, such as its
<a href="https://government.github.com/">GitHub and Government</a> initiative to
foster community involvement in government. (GitHub is really a platform
for easily seeing and changing <em>any</em> content or data. But, please, let
me continue using <em>code</em> as a stand-in, since I want to focus on the
developer audience.)</p>
<p>GitHub took an overly-complicated and fragmented world of varying
contribution processes and made the new world revolve around code and a
unified and simple process for change - the <em>pull request</em>.</p>
<p>Yes, there are other reasons for GitHub's success. You can make strong
arguments that GitHub has capitalized on the social and psychological
aspects of coding and human desire for success and happiness. I agree.</p>
<p>You can also argue GitHub succeeded because of Git. That statement is
more or less technically accurate, but I don't think it is a sound
argument. Git may have been the most feature complete open source
DVCS at the time GitHub came into existence. But that doesn't mean there
is something special about Git that no other DVCS has that makes GitHub
popular. Had another tool been more feature complete or had the backing
of a project as large as Linux at the time of GitHub's launch, we could
very well be looking at a successful service built on something that
isn't Git. Git had early market advantage and I argue its popularity
today - a lot of it via GitHub - is largely a result of its early
advantages over competing tools. And, I would go so far to say that when
you consider the poor usability of Git and the pain that its users go
through when first learning it, more accurate statements would be that
<em>GitHub succeeded in spite of Git</em> and <em>Git owes much of its success to
GitHub</em>.</p>
<p>When I look back at the rise of GitHub, I see a service that has
succeeded by putting people first by allowing them to capitalize
on more productive workflows and processes. They've done this by
emphasizing <em>code</em>, not process, as the means for change. Organizations
and projects should take note.</p>]]></content:encoded>
    </item>
    <item>
      <title>Firefox Contribution Process Debt</title>
      <link>http://gregoryszorc.com/blog/2015/01/09/firefox-contribution-process-debt</link>
      <pubDate>Fri, 09 Jan 2015 16:45:00 PST</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2015/01/09/firefox-contribution-process-debt</guid>
      <description>Firefox Contribution Process Debt</description>
      <content:encoded><![CDATA[<p>As I was
<a href="/blog/2014/12/30/firefox-source-documentation-versus-mdn/">playing around with source-derived documentation</a>,
I grasped the reality that any attempt to move documentation out of
MDN's wiki and into something derived from source code (despite the
argued technical and quality advantages) would likely be met with fierce
opposition because the change process for Firefox is much more involved
than <em>edit a wiki</em>.</p>
<p>This observation casts light on something important: <strong>the very act of
contributing <em>any</em> change to Firefox is too damn hard.</strong></p>
<p>I've always believed this statement to be true. I even like to think I'm
one of the few people that has consistently tried to do something about
it (inventing mach, overhauling the build system, bootstrap scripting,
MozReview, etc). But I, like many of the seasoned Firefox developers,
often lose sight of this grim reality. (I think it's fair to say that
new contributors often complain about the development experience and
as we grow accustomed to it, the complaint volume and intensity wanes).</p>
<p><strong>But when you have the simplicity of editing a wiki page on MDN juxtaposed
against the Firefox change contribution process of today, the inefficiency
of the Firefox process is clearly seen.</strong></p>
<p>The amount of knowledge required to change Firefox is obscenely absurd. Sure,
some complex components will always be difficult to change. But I'm talking
about <em>any</em> component: the base set of knowledge required to contribute
<em>any</em> change to Firefox is vast. This is <strong>before</strong> we get into any
domain-specific knowledge inside Firefox. <strong>I have always believed and
will continue to believe that this is a grave institutional issue for
Mozilla.</strong> It should go without saying that I believe this is an issue worth
addressing. After all, <strong>any piece of knowledge required for
contribution is essentially an obstacle to completion. Elimination of
required knowledge lowers the barrier to contribution.</strong> This, in turn,
allows increased contribution via more and faster change. This advances
the quality and relevance of Firefox, which enables Mozilla to advance
its <a href="https://www.mozilla.org/mission/">Mission</a>.</p>
<p>Seasoned contributors have probably internalized most of the knowledge
required to contribute to Firefox. Here is a <strong>partial</strong> list to remind
everyone of the sheer scope of it:</p>
<p><a name="list-of-process-debt"></a></p>
<ul>
  <li>Before you do anything
  <ul>
   <li>Am I able to contribute?</li>
   <li>Do I meet the minimum requirements (hardware, internet access, etc)?</li>
   <li>Do I need any accounts?</li>
  </ul></li>
  </li>
  <li>Source control
  <ul>
    <li>What is source control?</li>
    <li>How do I install Mercurial/Git?</li>
    <li>How do I use Mercurial/Git?</li>
    <li>Where can I get the Firefox source code?</li>
    <li>How do I *optimally* acquire the Firefox source code?</li>
    <li>Are there any recommended configuration settings or extensions?</li>
  </ul></li>
  <li>Building Firefox
  <ul>
   <li>Do I even need to build Firefox?</li>
   <li>How do I build Firefox?</li>
   <li>What prerequisites need to be installed?</li>
   <li>How do I install prerequisites?</li>
   <li>How do I configure the Firefox build to be appropriate for my needs?</li>
   <li>What are mozconfigs?</li>
   <li>How do I get Firefox to build faster?</li>
   <li>What do I do after a build?</li>
  </ul></li>
  <li>Changing code
  <ul>
   <li>Is there IDE support?</li>
   <li>Where can I find macros and aliases to make things easier?</li>
  </ul></li>
  <li>Testing
  <ul>
    <li>How do I run tests?
  <li>Which tests are relevant for a given change?</li>
  <li>What are all these different test types?</li>
  <li>How do I debug tests?</li>
  </ul></li>
  <li>Try and Automation
  <ul>
   <li>What is Try?</li>
   <li>How do I get an account?</li>
   <li>What is vouching and different levels of access?</li>
   <li>What is SSH?</li>
   <li>How do I configure SSH?</li>
   <li>When will my tests run?</li>
   <li>What is Tree Herder?</li>
   <li>What do all these letters and numbers mean?</li>
   <li>What are all these colors?</li>
   <li>What's an *intermittent failure*?</li>
   <li>How do I know if something is an *intermittent failure*?</li>
   <li>What amount of *intermittent failure* is acceptable?</li>
   <li>What do these logs mean?</li>
   <li>What's buildbot?</li>
   <li>What's mozharness?</li>
  </ul></li>
  <li>Sending patch to Mozilla
  <ul>
   <li>Do I need to sign a CLA?</li>
   <li>Where do I send patches?</li>
   <li>Do I need to get an account on Bugzilla?</li>
   <li>Do I need to file a bug?</li>
   <li>What component should I file a bug in?</li>
   <li>What format should patches be sent in?</li>
   <li>How should I format commit messages?</li>
   <li>How do I upload patches to Bugzilla?</li>
   <li>How does code review work?
   <ul>
    <li>What's the modules system?</li>
    <li>What modules does my change map to?</li>
    <li>Who are the possible reviewers?</li>
    <li>How do I ask someone for review?</li>
    <li>When can I expect review?</li>
    <li>What does r+ vs r- vs f+ vs f- vs cancelling review all mean?</li>
    <li>How do I submit changes to my initial patch?</li>
    <li>What do I do after review?</li>
   </ul></li>
  </ul></li>
  <li>Landing patches
  <ul>
   <li>What repository should a patch land on?</li>
   <li>How do you rebase?</li>
   <li>What's a tree closure?</li>
   <li>What do I do after pushing?</li>
   <li>How do I know the result of the landing?</li>
  </ul></li>
</ul>

<p>Holy #$%@, that's a lot of knowledge. Not only is this list incomplete,
it's also not encompassing a lot of the domain-specific knowledge around
the content being changed.</p>
<p>Every item on this list represents a point where a potential contributor
could throw up their arms out of despair and walk away, giving their
time and talents to another project. Every item on this list that takes
10 minutes instead of 5 could be the tipping point. For common actions,
things that take 5 seconds instead of 1 could be the difference maker.
<strong>This list thus represents reasons that people do not contribute to
Firefox or contribute ineffectively (in the case of common contributors,
like paid Mozilla staff).</strong></p>
<p>I view items on this list as <strong>process debt</strong>. <em>Process debt</em> is a term
I'm coining (perhaps someone has beat me to it - I'm writing this on a
plane without Internet access) that is a sibling of <em>technical debt</em>.
<em>Process debt</em> is overhead and inefficiency associated with <em>processes</em>.
The border between <em>process debt</em> and <em>technical debt</em> in computers is
the code itself (although that border may sometimes not be very
well-defined, as code and process are oftentimes similar, such as most
interactions with version control or code review tools).</p>
<p>When I see this list of <em>process debt</em>, I'm inspired by the opportunity
to streamline the processes and bask in the efficiency gains. But I am
also simultaneously overwhelmed by the vast scope of things that need
improved. When I think about the amount of energy that will need to be
exerted to fight the <em>OMG change</em> crowd, the list becomes <em>depressing</em>.
But discussing institutional resistance to change, the <em>stop energy</em>
associated with it, and Mozilla's historical record of failing to invest
in fixing process (and technical) debt is for another post.</p>
<p>When looking at the above list, I can think of the following general
ways to make it more approachable:</p>
<ol>
<li>Remove an item completely. If it isn't on the list, there is nothing
   to know and no overhead. The best way to solve a problem is to make
   it not exist.</li>
<li>Automate an item and makes its existence largely transparent. If an
   item is invisible, does it exist in the mind of a contributor? (This
   is also known as solving the problem by adding a layer of
   indirection.)</li>
<li>Change an item so that it is identical to another, more familiar
   process. If you use a well-defined process, there is no new knowledge
   that must be learned and the cost of on-boarding someone already
   familiar with that knowledge is practically zero.</li>
</ol>
<p>When you start staring at this list of Firefox contribution process debt,
you start thinking about priorities, groupings, and strategies. You look
around at what others are doing to see if you can borrow good ideas.</p>
<p>I've done a lot of thinking on the subject and have some ideas and
recommendations. Stay tuned for some additional posts on the topic.</p>]]></content:encoded>
    </item>
    <item>
      <title>Style Changes on hg.mozilla.org</title>
      <link>http://gregoryszorc.com/blog/2015/01/09/style-changes-on-hg.mozilla.org</link>
      <pubDate>Fri, 09 Jan 2015 15:25:00 PST</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2015/01/09/style-changes-on-hg.mozilla.org</guid>
      <description>Style Changes on hg.mozilla.org</description>
      <content:encoded><![CDATA[<p>Starting today and continuing through next week, there will be a number
of styling changes made to <a href="https://hg.mozilla.org/">hg.mozilla.org</a>.</p>
<p>The main goal of the work is to bring the style up-to-date with upstream
Mercurial. This will result in more features being available to the web
interface, hopefully making it more useful. This includes display of
bookmarks and the Mercurial help documentation. As part of this work,
we're also removing some files on the server that shouldn't be used. If
you start getting 404s or notice an unexpected theme change, this is
probably the reason why.</p>
<p>If you'd like to look over the changes before they are made or would
like to file a bug against a regression (we suspect there will be
minor regressions due to the large nature of the changes), head on
over to <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1117021">bug 1117021</a>
or ping people in #vcs on IRC.</p>]]></content:encoded>
    </item>
    <item>
      <title>Mercurial Pushlog Is Now Robust Against Interrupts</title>
      <link>http://gregoryszorc.com/blog/2014/12/30/mercurial-pushlog-is-now-robust-against-interrupts</link>
      <pubDate>Tue, 30 Dec 2014 12:25:00 PST</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <category><![CDATA[Firefox]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2014/12/30/mercurial-pushlog-is-now-robust-against-interrupts</guid>
      <description>Mercurial Pushlog Is Now Robust Against Interrupts</description>
      <content:encoded><![CDATA[<p><a href="https://hg.mozilla.org">hg.mozilla.org</a> - Mozilla's Mercurial server -
has functionality called the <a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmo/pushlog.html">pushlog</a>
which records who pushed what when. Essentially, it's a log of when
a repository was changed. This is separate from the commit log because
the commit log can be spoofed and the commit log doesn't record when
commits were actually pushed.</p>
<p>Since its inception, the pushlog has suffered from data consistency
issues. If you aborted the push at a certain time, data was not inserted
in the pushlog. If you aborted the push at another time, data existed in
the pushlog but not in the repository (the repository would get rolled
back but the pushlog data wouldn't).</p>
<p><strong>I'm pleased to announce that the pushlog is now robust against
interruptions and its updates are consistent with what is recorded by
Mercurial.</strong> The pushlog database commit/rollback is tied to Mercurial's
own transaction API. What Mercurial does to the push transaction, the
pushlog follows.</p>
<p>This former inconsistency has caused numerous problems over the years.
When data was inconsistent, we often had to close trees until someone
could SSH into the machines and manually run SQL to fix the problems.
This also contributed to a culture of <em>don't press ctrl+c during push:
it could corrupt Mercurial.</em> (Ctrl+c should be safe to press any time: if
it isn't, there is a bug to be filed.)</p>
<p>Any time you remove a source of tree closures is a cause for celebration.
Please join me in celebrating your new freedom to abort pushes without
concern for data inconsistency.</p>
<p>In case you want to test things out, aborting pushes and (and rolling
back the pushlog) should now result in something like:</p>
<pre><code>pushing to ssh://hg.mozilla.org/mozilla-central
searching for changes
adding changesets
adding manifests
adding file changes
added 1 changesets with 1 changes to 1 files
Trying to insert into pushlog.
Inserted into the pushlog db successfully.
^C
rolling back pushlog
transaction abort!
rollback completed
</code></pre>]]></content:encoded>
    </item>
    <item>
      <title>Firefox Source Documentation Versus MDN</title>
      <link>http://gregoryszorc.com/blog/2014/12/30/firefox-source-documentation-versus-mdn</link>
      <pubDate>Tue, 30 Dec 2014 12:00:00 PST</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2014/12/30/firefox-source-documentation-versus-mdn</guid>
      <description>Firefox Source Documentation Versus MDN</description>
      <content:encoded><![CDATA[<p>The Firefox source tree has had in-tree documentation powered by
<a href="https://gecko.readthedocs.org/en/latest/">Sphinx</a> for a while now.
However, its canonical home has been a
<a href="https://ci.mozilla.org/job/mozilla-central-docs/Tree_Documentation/index.html">hard-to-find URL on ci.mozilla.org</a>.
I finally <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1115278">scratched an itch</a>
and wrote patches to enable the docs to be built easier. So,
starting today, the docs are now available on Read the Docs at
<a href="https://gecko.readthedocs.org/en/latest/">https://gecko.readthedocs.org/en/latest/</a>!</p>
<p>While I was scratching itches, I decided to play around with another
documentation-related task: automatic API documentation. I have a
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1115452">limited proof-of-concept for automatically generating XPIDL interface
documentation</a>.
Essentially, we use the in-tree XPIDL parser to parse <em>.idl</em> files and
turn the Python object representation into reStructured Text, which Sphinx
parses and renders into pretty HTML for us. The concept can be applied to any
source input, such as WebIDL and JavaScript code. I chose XPIDL because a
parser is readily available and I know Joshua Cranmer has expressed
interest in automatic XPIDL documentation generation. (As an aside,
JavaScript tooling that supports the flavor of JavaScript used
internally by Firefox is very limited. We need to prioritize removing
Mozilla extensions to JavaScript if we ever want to start using awesome
tooling that exists in the wild.)</p>
<p>As I was implementing this proof-of-concept, I was looking at XPIDL
interface documentation on MDN to see how things are presented today.
After perusing MDN for a bit and comparing its content against what I
was able to derive from the source, something became extremely clear:
MDN has significantly more content than the canonical source code.
Obviously the <em>.idl</em> files document the interfaces, their attributes,
their methods, and all the types and names in between: that's the very
definition of an IDL. But what was generally missing from the source
code is comments. <em>What does this method do?</em> <em>What is each argument
used for?</em> Things like example usage are almost non-existent in the
source code. MDN, by contrast, typically has no shortage of all these
things.</p>
<p>As I was grasping the reality that MDN has a lot of out-of-tree
supplemental content, I started asking myself <em>what's the point
in automatic API docs? Is manual document curation on MDN good
enough?</em> <strong>This question has sort of been tearing me apart.</strong> Let me try
to explain.</p>
<p>MDN is an amazing site. You can tell a lot of love has gone into making
the experience and much of its content excellent. However, the content
around the technical implementation / internals of Gecko/Firefox generally
sucks. There are some exceptions to the rule. But I find that things like
internal API documentation to be lackluster on average. It is rare for
me to find documentation that is up-to-date and useful. It is common to
find documentation that is partial and incomplete. It is very common to
find things like JSMs not documented at all. <strong>I think this is a
problem.</strong> I argue the lack of good documentation raises the barrier to
contributing. <strong>Furthermore, writing and maintaining excellent
low-level documentation is too much effort.</strong></p>
<p><strong>My current thoughts on API and low-level documentation are that I
question the value of this documentation existing on MDN.</strong>
Specifically, I think things like JSM API docs
(like <a href="https://developer.mozilla.org/en-US/docs/Mozilla/JavaScript_code_modules/Sqlite.jsm">Sqlite.jsm</a>)
and XPIDL interface documentation (like
<a href="https://developer.mozilla.org/en-US/docs/Mozilla/Tech/XPCOM/Reference/Interface/nsIFile">nsIFile</a>)
don't belong on MDN - at least not in wiki form. <strong>Instead, I believe
that documentation like this should live in and be derived from source
code.</strong> Now, if the MDN site wants to expose this as read-only content
or if MDN wants to enable the content to be annotated in a wiki-like
manner (like how MSDN and PHP documentation allow user comments), that's
perfectly fine by me. Here's why.</p>
<p>First, if I must write separate-from-source-code API documentation on
MDN (or any other platform for that matter), I must now perform extra
work or forgo either the source code or external documentation. In other
words, if I write in-line documentation in the source code, I must spend
extra effort to essentially copy large parts of that to MDN. And I must
continue to spend extra effort to keep updates in sync. If I don't
want to spend that extra effort (I'm as lazy as you), I have to choose
between documenting the source code or documenting MDN. If I choose the
source code, people either have to read the source to read the docs
(because we don't generate documentation from source today) or someone
else has to duplicate the docs (overall more work). If I choose to
document on MDN, then people reading the source code (probably because
they want to change it) are deprived of additional context useful to
make that process easier. <strong>This is a lose-lose scenario and it is a
general waste of expensive people time.</strong></p>
<p>Second, I prefer having API documentation derived from source code
because I feel it results in more accurate documentation that has the
higher liklihood of remaining accurate and in sync with reality. Think
about it: when was the last time you reviewed changes to a JSM and
searched MDN for content that needed updated? I'm sure there are some
pockets of people that do this right. But I've written dozens of
JavaScript patches for Firefox and I'm pretty sure I've been asked to
update <em>external</em> documentation less than 5% of the time. Inline source
documentation, however, is another matter entirely. Because the
documentation is often proximal to code that changed, I frequently a) go
ahead and make the documentation changes because everything is right there
and it's low overhead to change as I adjust the source b) am asked to
update in-line docs when a reviewer sees I forgot to. Generally
speaking, things tend to stay in sync and fewer bugs form when
everything is proximally located. By fragmenting documentation between
source code and external services like MDN, we increase the liklihood
that things become out of sync. This results in misleading information
and increases the barriers to contribution and change. In other words,
developer inefficiency.</p>
<p>Third, having API documentation derived from source code opens up
numerous possibilities to further aid developer productivity and improve
the usefullness of documentation. For example:</p>
<ul>
<li>We can parse <em>@param</em> references out of documentation and issue
  warnings/errors when documentation doesn't match the AST.</li>
<li>We can issue warnings when code isn't documented.</li>
<li>We can include in-line examples and execute and verify these as part
  of builds/tests.</li>
<li>We can more easily cross-reference APIs because everything is
  documented consistently. We can also issue warnings when
  cross-references no longer work.</li>
<li>We can derive files so editors and IDEs can display in-line API docs
  as you type or can complete functions as you type, allowing people to
  code faster.</li>
</ul>
<p>While we don't generally do these things today, they are all within the
realm of possibility. Sphinx supports doing many of these things. Stop
reading and run <em>mach build-docs</em> right now and look at the warnings
from malformed documentation. I don't know about you, but I love when my
tools tell me when I'm creating a burden for others.</p>
<p>There really is so much more we could be doing with source-derived
documentation. And I argue managing it would take less overall work and
would result in higher quality documentation.</p>
<p>But the world of source-derived documentation isn't all roses. MDN has a
very important advantage: it's a wiki. Just log in, edit in a WYSIWYG,
and save. It's so easy. The moment we move to source-derived
documentation, we introduce the massive Firefox source repository, the
Firefox code review process, bugs/Bugzilla, version control overhead
(although versioning documentation is another plus for source-derived
documentation), landing changes, extra cost to Mozilla for building and
running those checkins (even if they contain docs-only changes, sadly),
and the time and cognitive burden associated with each one. That's a
lot of extra work compared to clicking a few buttons on MDN! <strong>Moving
documentation editing out of MDN and into the Firefox patch submission
world would be a step in the wrong direction in terms of fostering
contributions.</strong> Should someone really have to go through all that just
to correct a typo? I have no doubt we'd lose contributors if we switched
the change contribution process. And considering our lackluster track
record of writing inline documentation in source, I don't feel great
about losing <em>any</em> person who contributes documentation, no matter how
small the contribution.</p>
<p>And this is my dilemma: the existing source-or-MDN solution is sub-par
for pretty much everything except ease of contribution on MDN and
deploying nice tools (like Sphinx) to address the suckitude will result
in more difficulty contributing. Both alternatives suck.</p>
<p>I intend to continue this train of thought in a subsequent post. Stay
tuned.</p>]]></content:encoded>
    </item>
  </channel>
</rss>

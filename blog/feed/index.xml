<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:wfw="http://wellformedweb.org/CommentAPI/"
     >
  <channel>
    <title>Gregory Szorc's Digital Home</title>
    <link>http://gregoryszorc.com/blog</link>
    <description>Rambling on</description>
    <pubDate>Fri, 10 Jan 2014 00:04:46 GMT</pubDate>
    <generator>Blogofile</generator>
    <sy:updatePeriod>hourly</sy:updatePeriod>
    <sy:updateFrequency>1</sy:updateFrequency>
    <item>
      <title>mach now lives in mozilla-central</title>
      <link>http://gregoryszorc.com/blog/2014/01/09/mach-now-lives-in-mozilla-central</link>
      <pubDate>Thu, 09 Jan 2014 10:55:00 PST</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <category><![CDATA[mach]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2014/01/09/mach-now-lives-in-mozilla-central</guid>
      <description>mach now lives in mozilla-central</description>
      <content:encoded><![CDATA[<p><a href="https://pypi.python.org/pypi/mach/">mach</a> -- the generic command
line interface framework that is behind the <em>mach</em> tool used to
build Firefox -- now has its canonical home in
<a href="https://hg.mozilla.org/mozilla-central/file/default/python/mach/">mozilla-central</a>,
the canonical repository for Firefox. The
<a href="https://github.com/indygreg/mach">previous home</a> has been updated to
reflect the change.</p>
<p>mach will continue to be released on
<a href="https://pypi.python.org/pypi/mach/">PyPI</a> and installable via <strong>pip
install mach</strong>.</p>
<p>I made the change because keeping multiple repositories in sync
wasn't something I wanted to spend time doing. Furthermore,
Mozillians have been contributing a steady stream of improvements to
the mach core recently and it makes sense to leverage Mozilla's
familiar infrastructure for patch contribution.</p>
<p>This decision may be revisited in the future. Time will tell.</p>]]></content:encoded>
    </item>
    <item>
      <title>Why do Projects Support old Python Releases</title>
      <link>http://gregoryszorc.com/blog/2014/01/08/why-do-projects-support-old-python-releases</link>
      <pubDate>Wed, 08 Jan 2014 17:00:00 PST</pubDate>
      <category><![CDATA[Python]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2014/01/08/why-do-projects-support-old-python-releases</guid>
      <description>Why do Projects Support old Python Releases</description>
      <content:encoded><![CDATA[<p>I see a number of open source projects supporting old versions
of Python. Mercurial supports 2.4, for example. I have to ask: why do
projects continue to support old Python releases?</p>
<p>Consider:</p>
<ul>
<li><a href="http://python.org/download/releases/2.4.6/">Python 2.4</a> was last
  released on December 19, 2008 and <strong>there will be no more releases of
  Python 2.4</strong>.</li>
<li><a href="http://python.org/download/releases/2.5.6/">Python 2.5</a> was last
  released on May 26, 2011 and <strong>there will be no more releases of
  Python 2.5</strong>.</li>
<li><a href="http://python.org/download/releases/2.6.9/">Python 2.6</a> was last
  released on October 29, 2013 and <strong>there will be no more releases of
  Python 2.6</strong>.</li>
<li><strong>Everything before Python 2.7 is end-of-lifed</strong></li>
<li>Python 2.7 continues to see periodic releases, but mostly for bug fixes.</li>
<li>Practically all of the work on CPython is happening in the 3.3 and 3.4
  branches. Other implementations continue to support 2.7.</li>
<li>Python 2.7 has been available since July 2010</li>
<li>Python 2.7 provides some very compelling language features over
  earlier releases that developers want to use</li>
<li>It's much easier to write dual compatible 2/3 Python when 2.7 is the
  only 2.x release considered.</li>
<li>Python 2.7 can be installed in userland relatively easily (see
  projects like <a href="https://github.com/yyuu/pyenv">pyenv</a>).</li>
</ul>
<p>Given these facts, I'm not sure why projects insist on supporting old
and end-of-lifed Python releases.</p>
<p><strong>I think maintainers of Python projects should seriously consider
dropping support for Python 2.6 and below.</strong> Are there really that many
people on systems that don't have Python 2.7 easily available? Why are
we Python developers inflicting so much pain on ourselves to support
antiquated Python releases?</p>
<p>As a data point, I successfully transitioned Firefox's build system
from requiring Python 2.5+ to 2.7.3+ and it was relatively
<a href="https://groups.google.com/d/msg/mozilla.dev.platform/djN02O03APc/OS8A9LuHX0sJ">pain</a>
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=870420">free</a>.
Sure, a few people complained. But as far as I know, not very many new
developers are coming in and complaining about the requirement.
If we can do it with a few thousand developers, I'm guessing your
project can as well.</p>
<p><strong>Update 2014-01-09 16:05:00 PST</strong>: This post is being discussed on
<a href="http://developers.slashdot.org/story/14/01/09/1940232/why-do-projects-continue-to-support-old-python-releases">Slashdot</a>. A lot of the comments
talk about Python 3. Python 3 is its own set of
considerations. The intended focus of this post is strictly about
dropping support for Python 2.6 and below. Python 3 is related
in that porting Python 2.x to Python 3 is much easier the higher
the Python 2.x version. This especially holds true when you want
to write Python that works simultaneously in both 2.x and 3.x.</p>]]></content:encoded>
    </item>
    <item>
      <title>On Multiple Patches in Bugs</title>
      <link>http://gregoryszorc.com/blog/2014/01/07/on-multiple-patches-in-bugs</link>
      <pubDate>Tue, 07 Jan 2014 16:40:00 PST</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2014/01/07/on-multiple-patches-in-bugs</guid>
      <description>On Multiple Patches in Bugs</description>
      <content:encoded><![CDATA[<p>There is a common practice at Mozilla for developing patches with
multiple parts. Nothing wrong with that. In fact, I think it's a best
practice:</p>
<ul>
<li>Smaller, self-contained patches are much easier to grok and
  review than larger patches.</li>
<li>Smaller patches can land as soon as they are reviewed. Larger patches
  tend to linger and get bit rotted.</li>
<li>Smaller patches contribute to a culture of being fast and nimble, not
  slow and lethargic. This helps with developer confidence, community
  contributions, etc.</li>
</ul>
<p>There are some downsides to multiple, smaller patches:</p>
<ul>
<li>The bigger picture is harder to understand until all parts of a
  logical patch series are shared. (This can be alleviated through
  commit messages or reviewer notes documenting future intentions.
  And of course reviewers can delay review until they are comfortable.)</li>
<li>There is more overhead to maintain the patches (rebasing, etc).
  IMO the solutions provided by Mercurial and Git are sufficient.</li>
<li>The process overhead for dealing with multiple patches and/or bugs
  can be non-trivial. (I would like to think good tooling coupled with
  continuous revisiting of policy decisions is sufficient to counteract
  this.)</li>
</ul>
<p>Anyway, the prevailing practice at Mozilla seems to be that multiple
patches related to the same logical change are attached to the same
bug. I would like to challenge the effectiveness of this practice.</p>
<p>Given:</p>
<ul>
<li>An individual commit to Firefox should be standalone and should not
  rely on future commits to unbust it (i.e. bisects to any commit should
  be safe).</li>
<li>Bugzilla has no good mechanism to isolate review comments from
  multiple attachments on the same bug, making deciphering simultaneous
  reviews on multiple attachments difficult and frustrating. This leads
  to review comments inevitably falling through the cracks and the
  quality of code suffering.</li>
<li>Reiterating the last point because it's important.</li>
</ul>
<p>I therefore argue that attaching multiple reviews to a single Bugzilla
bug is not a best practice and it should be avoided if possible. If that
means filing separate bugs for each patch, so be it. That process can
be automated. Tools like
<a href="https://hg.mozilla.org/users/tmielczarek_mozilla.com/bzexport">bzexport</a>
already do it. Alternatively (and even better IMO), we ditch
Bugzilla's code review interface (Splinter) and integrate something like
<a href="https://reviewboard.allizom.org/">ReviewBoard</a> instead. We limit
Bugzilla to tracking, high-level discussion, and metadata aggregation.
Code review happens elsewhere, without all the clutter and chaos that
Bugzilla brings to the table.</p>
<p>Thoughts?</p>]]></content:encoded>
    </item>
    <item>
      <title>Python Package Providing Clients for Mozilla Services</title>
      <link>http://gregoryszorc.com/blog/2014/01/06/python-package-providing-clients-for-mozilla-services</link>
      <pubDate>Mon, 06 Jan 2014 10:45:00 PST</pubDate>
      <category><![CDATA[Python]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2014/01/06/python-package-providing-clients-for-mozilla-services</guid>
      <description>Python Package Providing Clients for Mozilla Services</description>
      <content:encoded><![CDATA[<p>I have a number of Python projects and tools that interact with
various Mozilla services. I had authored clients for all these services
as standalone Python modules so they could be reused across projects.</p>
<p>I have consolidated all these Python modules into a unified source
control
<a href="https://bitbucket.org/indygreg/python-mozautomation">repository</a>
and have made the project available on
<a href="https://pypi.python.org/pypi/mozautomation">PyPI</a>. You can install it
by running:</p>
<p>$ pip install mozautomation</p>
<p>Currently included in the Python package are:</p>
<ul>
<li>A client for <a href="https://treestatus.mozilla.org/">treestatus.mozilla.org</a></li>
<li>Module for extracting cookies from Firefox profiles (useful for
  programmatically getting Bugzilla auth credentials).</li>
<li>A client for reading and interpretting the
  <a href="http://builddata.pub.build.mozilla.org/buildjson/">JSON dumps of automation jobs</a></li>
<li>An interface to a SQLite database to manage associations between
  Mercurial changesets, bugs, and pushes.</li>
<li>Rudimentary parsing of commit messages to extract bugs and reviewers.</li>
<li>A client to obtain information about Firefox releases via the
  <a href="http://releases-api.mozilla.org/">releases API</a></li>
<li>A module defining common Firefox source repositories, aliases, logical
  groups (e.g. twigs and integration trees), and APIs for fetching
  pushlog data.</li>
<li>A client for the <a href="https://secure.pub.build.mozilla.org/buildapi/self-serve/">self serve API</a></li>
</ul>
<p>Documentation and testing is currently sparse. Things aren't up to my
regular high quality standard. But something is better than nothing.</p>
<p>If you are interested in contributing, drop me a line or send pull
requests my way!</p>]]></content:encoded>
    </item>
    <item>
      <title>Importance of Hosting Your Version Control Server</title>
      <link>http://gregoryszorc.com/blog/2013/11/13/importance-of-hosting-your-version-control-server</link>
      <pubDate>Wed, 13 Nov 2013 09:25:00 PST</pubDate>
      <category><![CDATA[Git]]></category>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2013/11/13/importance-of-hosting-your-version-control-server</guid>
      <description>Importance of Hosting Your Version Control Server</description>
      <content:encoded><![CDATA[<p>The subject of where to host version control repositories comes up a lot
at Mozilla. It takes many forms:</p>
<ul>
<li>We should move the Firefox repository to GitHub</li>
<li>I should be allowed to commit to GitHub</li>
<li>I want the canonical repository to be hosted by Bitbucket</li>
</ul>
<p>When Firefox development is concerned, Release Engineerings puts down
their foot and insists the canonical repository be hosted by Mozilla,
under a Mozilla hostname. When that's not possible, they set up a mirror
on Mozilla infrastructure.</p>
<p>I think a
<a href="https://groups.google.com/d/topic/jenkinsci-dev/-myjRIPcVwU/discussion">recent issue with the Jenkins project</a>
demonstrates why hosting your own version control server is important.
The gist is someone force pushed to a bunch of repos hosted on GitHub.
They needed to involve GitHub support to recover from the issue. While
it appears they largely recovered (and GitHub support deserves kudos - I
don't want to take away from their excellence), this problem would have
been avoided or the response time significantly decreased if the Jenkins
people had direct control over the Git server: they either could have
installed a custom hook that would have prevented the pushes or had
access to the reflog so they could have easily seen the last pushed
revision and easily forced pushed back to it. GitHub doesn't have a
mechanism for defining pre-* hooks, doesn't allow defining custom
hooks (a security and performance issue for them), and doesn't
expose the reflog data.</p>
<p>Until repository hosting services expose full repository data (such as
reflogs) and allow you to define custom hooks, accidents like these will
happen and the recovery time will be longer than if you hosted the repo
yourself.</p>
<p>It's possible repository hosting services like GitHub and Bitbucket will
expose these features or provide a means to quickly recover. If so,
kudos to them. But larger, more advanced projects will likely employ
custom hooks and considering custom hooks are a massive security and
performance issue for any hosted service provider, I'm not going to
hold my breath this particular feature is rolled out any time soon.
This is unfortunate, as it makes projects seemingly choose between
low risk/low convenience and GitHub's vibrant developer community.</p>]]></content:encoded>
    </item>
    <item>
      <title>Mercurial 2.8 released</title>
      <link>http://gregoryszorc.com/blog/2013/11/08/mercurial-2.8-released</link>
      <pubDate>Fri, 08 Nov 2013 14:30:00 PST</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2013/11/08/mercurial-2.8-released</guid>
      <description>Mercurial 2.8 released</description>
      <content:encoded><![CDATA[<p><a href="http://mercurial.selenic.com/">Mercurial</a> 2.8 has been released.</p>
<p>The <a href="http://mercurial.selenic.com/wiki/WhatsNew#Mercurial_2.8_.282013-11-1.29">changes</a>
aren't as sexy as previous releases. But there are a handful of bug
fixes that seem useful to pull in. People may also find the new <em>shelve</em>
extension useful.</p>
<p>I encourage Mozillians to keep their Mercurial up to date. I once went
around the San Francisco office and stood behind people as they
upgraded to a modern Mercurial. For the next few weeks I was hearing a
lot of "OMG Mercurial is so much better now." Don't handicap yourself by
running an older, buggy Mercurial.</p>
<p>If you don't yet feel comfortable running 2.8, 2.7 should be safe.</p>]]></content:encoded>
    </item>
    <item>
      <title>Using Mercurial to query Mozilla metadata</title>
      <link>http://gregoryszorc.com/blog/2013/11/08/using-mercurial-to-query-mozilla-metadata</link>
      <pubDate>Fri, 08 Nov 2013 09:42:00 PST</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2013/11/08/using-mercurial-to-query-mozilla-metadata</guid>
      <description>Using Mercurial to query Mozilla metadata</description>
      <content:encoded><![CDATA[<p>I have updated my
<a href="https://hg.mozilla.org/users/gszorc_mozilla.com/hgext-gecko-dev">Mercurial extension tailored for Gecko/Firefox development</a>
with features that support rich querying of Mozilla/Gecko-development
specific metadata!</p>
<p>The extension now comes with a bug full of
<a href="http://www.selenic.com/hg/help/revsets">revision set</a> selectors and
<a href="http://www.selenic.com/hg/help/templates">template keywords</a>. You can
use them to query and format Mozilla-central metadata from the
repository.</p>
<h2>Revision set selectors</h2>
<p>You can now select changesets referencing a specific bug number:</p>
<pre><code>hg log -r 'bug(931383)'
</code></pre>
<p>Or that were reviewed by a specific person:</p>
<pre><code>hg log -r 'reviewer(gps)'
</code></pre>
<p>Or were reviewed or not reviewed:</p>
<pre><code>hg log -r 'reviewed()'
hg log -r 'not reviewed()'
</code></pre>
<p>You can now select changesets that are present in a specific tree:</p>
<pre><code>hg log -r 'tree(central)'
</code></pre>
<p>I've also introduced support to query changesets <em>you</em> influenced:</p>
<pre><code>hg log -r 'me()'
</code></pre>
<p>(This finds changesets you authored or reviewed.)</p>
<p>You can select changesets that initially landed on a specific tree:</p>
<pre><code>hg log -r 'firstpushtree(central)'
</code></pre>
<p>You can select changesets marked as <em>DONTBUILD</em>:</p>
<pre><code>hg log -r 'dontbuild()'
</code></pre>
<p>You can select changesets that don't reference a bug:</p>
<pre><code>hg log -r 'nobug()'
</code></pre>
<p>You can select changesets that were <em>push heads</em> for a tree:</p>
<pre><code>hg log -r 'pushhead(central)'
</code></pre>
<p>(This would form the basis of a push-aware bisection tool - an excellent
idea for a future feature in this extension.)</p>
<p>You can combine these revset selector functions with other revset
selectors to do some pretty powerful things.</p>
<p>To select all changesets on inbound but not central:</p>
<pre><code>hg log -r 'tree(inbound) - tree(central)'
</code></pre>
<p>To find all your contributions on beta but not release:</p>
<pre><code>hg log -r 'me() &amp; (tree(beta) - tree(release))'
</code></pre>
<p>To find all changesets referencing a specific bug that have landed in
Aurora:</p>
<pre><code>hg log -r 'bug(931383) and tree(aurora)'
</code></pre>
<p>To find all changesets marked <em>DONTBUILD</em> that landed directly on central:</p>
<pre><code>hg log -r 'dontbuild() and firstpushtree(central)'
</code></pre>
<p>To find all non-merge changesets that don't reference a bug:</p>
<pre><code>hg log -r 'not merge() and nobug()'
</code></pre>
<p>Neato!</p>
<h2>Template keywords</h2>
<p>You can also now print some Mozilla information when using templates.</p>
<p>To print the main bug of a changeset, use:</p>
<pre><code>{bug}
</code></pre>
<p>To retrieve all referenced bugs:</p>
<pre><code>{bugs} {join(bugs, ', ')}
</code></pre>
<p>To print the reviewers:</p>
<pre><code>{reviewer} {join(reviewers, ', ')}
</code></pre>
<p>To print the first version a changeset appeared in a specific channel:</p>
<pre><code>{firstrelease} {firstbeta} {firstaurora} {firstnightly}
</code></pre>
<p>To print the <strong>estimated</strong> first Aurora and Nightly date for a
changeset, use:</p>
<pre><code>{auroradate} {nightlydate}
</code></pre>
<p>(Getting the exact first Aurora and Nightly dates requires consulting
3rd party services, which we don't currently do. I'd like to
eventually integrate these into the extension. For now, it just
estimates dates from the pushlog data.)</p>
<p>You can also print who and where pushed a changeset:</p>
<pre><code>{firstpushuser} {firstpushtree}
</code></pre>
<p>You can also print the TBPL URL with the results of the first push:</p>
<pre><code>{firstpushtbpl}
</code></pre>
<p>Here is an example that prints channel versions and dates for each
changesets:</p>
<pre><code>hg log --template '{rev} Nightly: {firstnightly} {nightlydate}; Aurora {firstaurora} {auroradate}; Beta: {firstbeta}; Release: {firstrelease}\n'
</code></pre>
<h2>Putting it all together</h2>
<p>Of course, you can combine selectors and templates to create some
mighty powerful queries.</p>
<p>To look at your impact on Mozilla, do something like:</p>
<pre><code>hg log --template '{rev} Bug {bug}; Release {firstrelease}\n' -r 'me()'
</code></pre>
<p>You can easily forumate a status report for your activity in the past
week:</p>
<pre><code>hg log --template '{firstline(desc)}\n' -r 'firstpushdate(-7) and me()'
</code></pre>
<p>You can also query Mercurial to see where changesets have been landing
in the past 30 days:</p>
<pre><code>hg log --template '{firstpushtree}\n' -r 'firstpushdate(-30)' | sort | uniq -c
</code></pre>
<p>You can see who has been reviewing lots of patches lately:</p>
<pre><code>hg log --template '{join(reviewers, "\n")}\n' -r 'firstpushdate(-30)' | sort | uniq -c | sort -n
</code></pre>
<p>(smaug currently has the top score, edging out my 116 reviews with 137.)</p>
<p>If you want to reuse templates (instead of having to type them on the
command line), you can save them as <em>style files</em>. Search
<a href="https://www.google.com/search?q=mercurial+style+files">the Internets</a>
to learn how to use them. You can even change your default style so
the default output from <em>hg log</em> contains everything you'd ever want to
know about a changeset!</p>
<h2>Keeping it running</h2>
<p>Many of the queries rely on data derived from multiple repositories and
pushlog data that is external to the repository.</p>
<p>To get best results, you'll need to be running a monolithic/unified
Mercurial repository. You can either assemble one locally with this
extension by periodically pulling from the separate repos:</p>
<pre><code>hg pull releases
hg pull integration
</code></pre>
<p>Or, you can pull from
<a href="http://hg.gregoryszorc.com/gecko">my personal unified repo</a>.</p>
<p>You will also need to ensure the pushlog data is current. If you pull
directly from the official repos, this will happen automatically. To be
sure, run:</p>
<pre><code>hg pushlogsync
</code></pre>
<p>Finally, you can force a repopulation of cached bug data by running:</p>
<pre><code>hg buginfo --reset
</code></pre>
<p>Over time, I want all this to automagically work. Stay tuned.</p>
<h2>Comments and future improvements</h2>
<p>I implemented this feature to save myself from having to go troving
through Bugzilla and repository history to answer questions and to
obtain metrics. I can now answer many questions via simple Mercurial
one-liners.</p>
<p>Custom revision set selectors and template keywords are a pretty nifty
feature of Mercurial. They demonstrate how you can extend Mercurial to
be aware of more than just tracking commits and files. As I've
<a href="/blog/2013/05/12/thoughts-on-mercurial-%28and-git%29/">said before</a>
and will continue to say, the extensibility of Mercurial is
really its killer feature, especially for organizations with
well-defined processes (like Mozilla). The kind of extensibility I
achieved with this extension with custom queries and formatting
functions is just not possible with Git (at least not with the reference
C implementation that the overwhelming majority of Git users use).</p>
<p>There are numerous improvements that can be made to the extension.
Obviously more revision set selectors and template keywords can be
added. The parsing routine to extract bugs and reviewers isn't the most
robust in the world. I copied some existing Mozilla code. It does well
at detecting string patters but doesn't cope well with extracting lists.</p>
<p>I'd also love to better integrate Mercurial with automation
results so you can do things like expose a <em>greenpush()</em> selector and do
things like <em>hg up -r 'last(tree(inbound)) and greenpush()'</em> (which
of course could be exposed as <em>lastgreen(inbound)</em>. Wouldn't
that be cool! (This would be possible if we had better APIs for querying
individual push results.) It would also be possible to have the
Mercurial server expose this data as repository data so clients pull it
automatically. That would prevent clients from all needing to query the
same 3rd party services. Just a crazy thought.</p>
<p>Speed can be an issue. Calculating the release information
(<em>{firstnightly}</em> etc) is currently slower than I'd like. This is mostly
due to me using inefficient algorithms and not caching things where I
should. Speed issues should be fixed in due time.</p>
<p>Please let me know if you run into any problems or have suggestions for
improvements. If you want to implement your own revision set selectors
or template keywords, it's <a href="https://hg.mozilla.org/users/gszorc_mozilla.com/hgext-gecko-dev/file/35bb3c96d786/__init__.py#l705">easier</a>
than you think! I will happily accept patches. Keep in mind that
Mercurial can integrate with 3rd party services. So if you want to
supplement repository data with data from a HTTP+JSON web service,
that's very doable. The sky is the limit.</p>]]></content:encoded>
    </item>
    <item>
      <title>MacBook Pro Firefox Build Times Comparison</title>
      <link>http://gregoryszorc.com/blog/2013/11/05/macbook-pro-firefox-build-times-comparison</link>
      <pubDate>Tue, 05 Nov 2013 10:00:00 PST</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <category><![CDATA[build system]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2013/11/05/macbook-pro-firefox-build-times-comparison</guid>
      <description>MacBook Pro Firefox Build Times Comparison</description>
      <content:encoded><![CDATA[<p>Many developers use MacBook Pros for day-to-day Firefox development.
So, I thought it would be worthwhile to perform a comparison of
Firefox build times for various models of MacBook Pros.</p>
<h2>Test setup</h2>
<p>The numbers in this post are obtained from 3 generations of MacBook
Pros:</p>
<ol>
<li>
<p>A 2011 Sandy Bridge 4 core x 2.3 GHz with 8 GB RAM and an aftermarket
   SSD.</p>
</li>
<li>
<p>A 2012 Ivy Bridge retina with 4 core x 2.6 GHz, 16 GB RAM, and a
   factory SSD (or possibly flash storage).</p>
</li>
<li>
<p>A 2013 Haswell retina with 4 core x 2.6 GHz, 16 GB RAM, and flash
   storage.</p>
</li>
</ol>
<p>All machines were running OS X 10.9 Mavericks and were using the
Xcode 5.0.1 toolchain (<em>Xcode 5 clang: Apple LLVM version 5.0
(clang-500.2.79) (based on LLVM 3.3svn)</em>) to build.</p>
<p>The power settings prevented machine sleep and machines were plugged
into A/C power during measuring. I did not use the machines while
obtaining measurements.</p>
<p>The 2012 and 2013 machines were very vanilla OS installs. However,
the 2011 machine was my primary work computer and may have had a
few background services running and may have been slower due to
normal wear and tear. The 2012 machine was a loaner machine from
IT and has an unknown history.</p>
<p>All data was obtained from mozilla-central revision d4a27d8eda28.</p>
<p>The mozconfig used contained:</p>
<p>export MOZ_PSEUDO_DERECURSE=1
  mk_add_options MOZ_OBJDIR=@TOPSRCDIR@/obj-firefox.noindex</p>
<p>Please note that the objdir name ends with <em>.noindex</em> to prevent Finder
from indexing build files.</p>
<p>I performed all tests multiple times and used the fastest time. I used
<em>time</em> command for obtaining measurements of wall, user, and system
time.</p>
<h2>Results</h2>
<h3>Configure Times</h3>
<p>The result of <em>mach configure</em> is as follows:</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>29.748</td>
    <td>17.921</td>
    <td>11.644</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>26.765</td>
    <td>15.942</td>
    <td>10.501</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>21.581</td>
    <td>12.597</td>
    <td>8.595</td>
  </tr>
</table>

<h3>Clobber build no ccache</h3>
<p><em>mach build</em> was performed <em>after</em> running <em>mach configure</em>. ccache was
not enabled.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
    <th>Total CPU time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>22:29 (1349)</td>
    <td>145:35 (8735)</td>
    <td>12:03 (723)</td>
    <td>157:38 (9458)</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>15:00 (900)</td>
    <td>94:18 (5658)</td>
    <td>8:14 (494)</td>
    <td>102:32 (6152)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>11:13 (673)</td>
    <td>69:55 (4195)</td>
    <td>6:04 (364)</td>
    <td>75:59 (4559)</td>
  </tr>
</table>

<h3>Clobber build with empty ccache</h3>
<p><em>mach build</em> was performed <em>after</em> running <em>mach configure</em>. ccache was
enabled. The ccache ccache was cleared before running <em>mach configure</em>.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
    <th>Total CPU time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>25:57 (1557)</td>
    <td>161:30 (9690)</td>
    <td>18:21 (1101)</td>
    <td>179:51 (10791)</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>16:58 (1018)</td>
    <td>104:50 (6290)</td>
    <td>12:32 (752)</td>
    <td>117:22 (7042)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>12:59 (779)</td>
    <td>79:51 (4791)</td>
    <td>9:24 (564)</td>
    <td>89:15 (5355)</td>
  </tr>
</table>

<h3>Clobber build with populated ccache</h3>
<p><em>mach build</em> was performed after running <em>mach configure</em>. ccache was
enabled and the ccache was populated with the results of a prior build.
In theory, all compiler invocations should be serviced by ccache
entries.</p>
<p>This measure is a very crude way to measure how fast clobber builds
would be if compiler invocations were nearly instantaneous.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>3:59 (239)</td>
    <td>8:04 (484)</td>
    <td>3:21 (201)(</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>3:11 (191)</td>
    <td>6:45 (405)</td>
    <td>2:53 (173)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>2:31 (151)</td>
    <td>5:22 (322)</td>
    <td>2:12 (132)</td>
  </tr>
</table>

<h3>No-op builds</h3>
<p><em>mach build</em> was performed on a tree that was already built.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>1:58 (118)</td>
    <td>2:25 (145)</td>
    <td>0:41 (41)</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>1:42 (102)</td>
    <td>2:02 (122)</td>
    <td>0:37 (37)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>1:20 (80)</td>
    <td>1:39 (99)</td>
    <td>0:28 (28)</td>
  </tr>
</table>

<h3>binaries no-op</h3>
<p><em>mach build binaries</em> was performed on a fully built tree. This results
in nothing being executed. It's a way to test the overhead of the
<em>binaries</em> make target.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>4.21</td>
    <td>4.38</td>
    <td>0.92</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>3.17</td>
    <td>3.37</td>
    <td>0.71</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>2.67</td>
    <td>2.75</td>
    <td>0.56</td>
  </tr>
</table>

<h3>binaries touch single .cpp</h3>
<p><em>mach build binaries</em> was performed on a fully built tree after touching
the file <em>netwerk/dns/nsHostResolver.cpp</em>. ccache was enabled but
cleared before running this test. This test simulates common C++
developer workflow of changing C++ and recompiling.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>12.89</td>
    <td>13.88</td>
    <td>1.96</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>10.82</td>
    <td>11.63</td>
    <td>1.78</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>8.57</td>
    <td>9.29</td>
    <td>1.23</td>
  </tr>
</table>

<h3>Tier times</h3>
<p>The times of each build system <em>tier</em> were measured on the 2013 Haswell
MacBook Pro. These timings were obtained out of curiosity to help
isolate the impact of different parts of the build. ccache was not
enabled for these tests.</p>
<table border="1">
  <tr>
    <th>Action</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
    <th>Total CPU time</th>
  </tr>
  <tr>
    <td>export clobber</td>
    <td>15.75</td>
    <td>66.11</td>
    <td>11.33</td>
    <td>77.44</td>
  </tr>
  <tr>
    <td>compile clobber</td>
    <td>9:01 (541)</td>
    <td>64:58 (3898)</td>
    <td>5:08 (308)</td>
    <td>70:06 (4206)</td>
  </tr>
  <tr>
    <td>libs clobber</td>
    <td>1:34 (94)</td>
    <td>2:15 (135)</td>
    <td>0:39 (39)</td>
    <td>2:54 (174)</td>
  </tr>
  <tr>
    <td>tools clobber</td>
    <td>9.33</td>
    <td>13.41</td>
    <td>2.48</td>
    <td>15.89</td>
  </tr>
  <tr>
    <td>export no-op</td>
    <td>3.01</td>
    <td>9.72</td>
    <td>3.47</td>
    <td>13.19</td>
  </tr>
  <tr>
    <td>compile no-op</td>
    <td>3.18</td>
    <td>18.02</td>
    <td>2.64</td>
    <td>20.66</td>
  </tr>
  <tr>
    <td>libs no-op</td>
    <td>58.2</td>
    <td>46.9</td>
    <td>13.4</td>
    <td>60.3</td>
  </tr>
  <tr>
    <td>tools no-op</td>
    <td>8.82</td>
    <td>12.68</td>
    <td>1.72</td>
    <td>14.40</td>
  </tr>
</table>

<h2>Observations and conclusions</h2>
<p>The data speaks for itself: <strong>the 2013 Haswell MacBook Pro is
significantly faster than its predecessors.</strong> It clocks in at 2x faster
than the benchmarked 2011 Sandy Bridge model (keep in mind the 300 MHz
base clock difference) and is ~34% faster than the 2012 Ivy Bridge (at
similar clock speed). Personally, I was surprised by this. I was
expecting speed improvements over Ivy Bridge, but not 34%.</p>
<p>It should go without saying: <strong>if you have the opportunity to upgrade
to a new, Haswell-based machine: do it.</strong> If possible, purchase
the upgrade to a 2.6 GHz CPU, as it contains ~13% more MHz than the
base 2.3 GHz model: this will make a measurable difference in build
times.</p>
<p>It's worth noting the increased efficiency of Haswell over its
predecessors. The total CPU time required to build decreased from ~158
minutes to ~103 minutes to 76 minutes! That 76 minute number is worth
highlighting because it means if we get 100% CPU saturation during
builds, we'll be able to build the tree in under 10 wall time minutes!</p>
<p>I hadn't performed crude benchmarks of high-level build system actions
since the <em>MOZ_PSEUDO_DERECURSE</em> work landed and I wanted to use the
opportunity of this hardware comparison to grab some numbers.</p>
<p>The overhead of ccache continues to surprise me. On the 2013
machine, enabling ccache increased the wall time of a clobber build by
1:46 and added 13:16 of CPU time. This is an increase of 16% and 17%,
respectively.</p>
<p>It's worth highlighting just how much time is spent compiling C/C++. In
our artificial tier measuring results, our clobber build time was ~660
wall time seconds (11 minutes) and used ~4473s CPU time (74:33). Of
this, 9:01 wall time and 70:06 CPU time was spent compiling C/C++. This
represents ~82% wall time and ~94% CPU time! Please note this does not
include linking. <strong>Anything we can do to decrease the CPU time used by
the compiler will make the build faster.</strong></p>
<p>I also found it interesting to note variances in obtained times. Even on
my brand new 2013 Haswell MacBook Pro where I know there aren't many
background processes running, wall times could vary significantly. I
<em>think</em> I isolated it to CPU bursting and heat issues. If I wait a few
minutes between CPU intensive tests, results are pretty consistent. But
if I perform CPU intensive tests back-to-back, the run times often vary.
The only other thing coming into play could be page caching or
filesystem indexing. I accounted for the latter by disabling Finder
on the object directory. And, I'd like to think that flash storage is
fast enough to remove I/O latency from the equation. Who knows. At the
end of the day, laptops aren't servers and OS X is a consumer OS, so I
don't expect ultra consistency.</p>
<p>Finally, I want to restate just how fast Haswell is. If you have the
opportunity to upgrade, do it.</p>]]></content:encoded>
    </item>
    <item>
      <title>Distributed Compiling and Firefox</title>
      <link>http://gregoryszorc.com/blog/2013/10/31/distributed-compiling-and-firefox</link>
      <pubDate>Thu, 31 Oct 2013 11:35:00 PDT</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <category><![CDATA[build system]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2013/10/31/distributed-compiling-and-firefox</guid>
      <description>Distributed Compiling and Firefox</description>
      <content:encoded><![CDATA[<p>If you had infinite CPU cores available and the Firefox build system
could distribute them all for concurrent compilation, Firefox
clobber build times would likely be 3-5 minutes instead of ~15
minutes on modern machines. This is a massive win. It therefore
should come as no surprise that distributed compiling is very
interesting to us.</p>
<p>Up until recently, the benefits of distributed compiling in the Firefox
build system couldn't be fully realized. This was because the build
system was performing recursive make traversal and make only <em>knew</em>
about a tiny subset of the tree's total C++ files at one time. For
example, when visiting <em>/layout/base</em> it only knew about 35 of the
close to 6000 files that get compiled as part of building Firefox. This
meant there was a hard ceiling to the max concurrency the build system
could achieve. This ceiling was often higher than the number of cores in
an individual machine, so it wasn't a huge issue for single machine
builds. But it did significantly limit the benefits of distributed
compiling. This all changed recently.</p>
<p><strong>As of a few weeks ago, the build system no longer encounters a low
ceiling preventing distributed compilation from reaping massive
benefits.</strong> If you have build with <em>make -j128</em>, make will spawn
128 compiler processes when processing the <em>compile</em> tier (which
is where most compilation occurs). If your compiler is set to a
distributed compiler, you will win.</p>
<p>So, what should you do about it?</p>
<p>I encourage people to set up distributed compilation <em>networks</em>
to reap the benefits of distributed compilation. Here are some tools you
should know about and some things to keep in mind.</p>
<p><a href="https://code.google.com/p/distcc/">distcc</a> is the tried and proven tool
for performing distributed compilation. It's heavily used and gets the
job done. It even works on Windows and can perform remote processing,
which is a huge win for our tree, where preprocessing can be
computationally expensive because of excessive includes. But, it has
a few significant drawbacks. Read the next paragraph.</p>
<p>I'm personally more excited about
<a href="https://github.com/icecc/icecream">icecream</a>. It has some very
compelling advantages to distcc. It has a scheduler that can
intelligently distribute load between machines. It uses network
broadcast to discover the scheduler. So, you just start the client
daemon and if there is a scheduler on the local network, it's all
set up. Icecream transfers the compiler toolchain between nodes
so you are guaranteed to have consistent output. (With distcc,
output may not be idempotent if the nodes aren't homogenous since distcc
relies on the system-local toolchain. If different versions are
installed on different nodes, you are out of luck). Icecream also
supports cross-compiling. In theory, you can have Linux machines
building for OS X, 32-bit machines building for 64-bit, etc. This
is all very difficult (if not impossible) to do with distcc.
Unfortunately, icecream doesn't work on Windows and doesn't appear
to support server-side preprocessing. Although, I imagine
both could be made to work if someone put in the effort.</p>
<p>Distributed compilation is very network intensive. I haven't measured,
but I suspect Wi-Fi bandwidth and latency constraints might make it
prohibitive there. It certainly won't be good for Wi-Fi saturation!
<strong>If you are in a Mozilla office, please do not attempt to perform
distributed compilation over Wi-Fi!</strong> For the same reasons, distributed
compilation will likely not benefit you if you are attempting to compile
on network-distant nodes.</p>
<p>I have set up an icecream server in the Mozilla San Francisco office. If
you install the icecream client daemon (iceccd) on your machine, it
should just work. I'm not sure what broadcast nets are configured as,
but I've successfully had machines on the 7th floor discover it
automatically. I guarantee no SLA for this server. Ping me privately
if you have difficulty connecting.</p>
<p>I've started very preliminary talks with Mozilla IT about setting up
dedicated <em>compiler farms</em> in Mozilla offices. I'm not saying this is
coming any time soon. I feel this will have a major impact on developer
productivity and I wanted to get the ball rolling months in advance
so nobody can claim this is a fire drill.</p>
<p>For distributed compilation to work well, the build system really needs
to be aware of distributed compilation. For example, to yield the
benefits of distributed compilation with make, you need to pass -j64 or
some other large value for concurrency. However, this value would be
universal for <em>every</em> task in the build. There are still thousands of
processes that must run locally. Using -j64 on these local tasks could
cause memory exhaustion, I/O saturation, excessive context switching,
etc. But if you decrease the concurrency ceiling, you lose the benefits
of distributed compilation! The build system thus needs to be taught
when distributed compilation is available and what tasks can be made
concurrent so it can intelligently adjust the -j concurrency limit at
run-time. This is why we have a higher-level build wrapper tool: <em>mach
build</em>. (This is another reason why people should be building through
mach instead of invoking make directly.)</p>
<p>No matter what technical solution we employ, I would like the build
system to automatically discover and use distributed compilation if
it is available. If we need to hardcode Mozilla IP addresses or
hostnames into the build system, I'm fine with that. I just don't want
developers not achieving much-faster build times because they are
ignorant. If you are in a physical location with distributed compilation
support, you should get that automatically: fast builds should not be
hard.</p>
<p>We can and should investigate distributed compilation as part of release
automation. Icecream should mitigate the concerns about build
reproducibility since the toolchain is transferred at build time.</p>
<p>I have had success getting Icecream to work with Linux builds. However,
OS X is problematic. Specifically, Icecream is unable to create the
build environment for distribution (likely modern OS X/Xcode
compatibility issue). Details are in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=927952">bug 927952</a>.</p>
<p>Build peers have a lot on our plate this quarter and making distributed
compilation work well is not in our official goals. <strong>I would love, love,
love if someone could step up and be a hero to make distributed
compilation work better with the build system.</strong> If you are interested,
pop into #build on irc.mozilla.org.</p>
<p>In summary, there are massive developer productivity wins waiting to be
realized through distributed compiling. There is nobody tasked to work
on this officially. Although, I'd love it if there were. If you find
yourself setting up ad-hoc networks in offices, I'd <em>really</em> like to see
some kind of discovery in <em>mach</em>. If not, there will be people left
behind and that really stinks for those individuals. If you do any
work around distributed compiling, please have it tracked under
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=485559">bug 485559</a>.</p>]]></content:encoded>
    </item>
    <item>
      <title>OS X Mavericks and the Firefox Build System</title>
      <link>http://gregoryszorc.com/blog/2013/10/22/os-x-mavericks-and-the-firefox-build-system</link>
      <pubDate>Tue, 22 Oct 2013 13:30:00 PDT</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2013/10/22/os-x-mavericks-and-the-firefox-build-system</guid>
      <description>OS X Mavericks and the Firefox Build System</description>
      <content:encoded><![CDATA[<p>OS X Mavericks is available today as a free upgrade. People at Mozilla
are probably asking if it is safe to upgrade: will it affect my ability
to build Firefox.</p>
<p>A few people (myself included) have been running OS X Mavericks
developer previews for a few months. I believe all the Firefox build
system issues have been worked out for at least a few weeks now. So,
upgrading to OS X Mavericks should not impact your ability to build a
stock Firefox configuration from mozilla-central.</p>
<p>There might still be some non-default features and code paths that need
fixed to work with Mavericks. Support for the OS X 10.9 SDK might also
be problematic. In addition, if you build older trees such as Aurora
and Beta, you may run into issues building on Mavericks because those
trees may not have all required fixes uplifted.</p>
<p>While I won't encourage you to upgrade, I will say that Mavericks should
build Firefox without any issue. And since the number of Mavericks users
will only increase in the days ahead, it should be safe to assume that
regressions will be promptly fixed.</p>
<p>If you run into any issues with Firefox and Mavericks,
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=883824">bug 883824</a> is the
master tracking bug.
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=894090">Bug 894090</a> tracks
build system issues.</p>]]></content:encoded>
    </item>
  </channel>
</rss>

<?xml version="1.0" encoding="UTF-8"?>
<feed
  xmlns="http://www.w3.org/2005/Atom"
  xmlns:thr="http://purl.org/syndication/thread/1.0"
  xml:lang="en"
   >
  <title type="text">Gregory Szorc's Digital Home</title>
  <subtitle type="text">Rambling on</subtitle>

  <updated>2014-01-23T22:04:47Z</updated>
  <generator uri="http://blogofile.com/">Blogofile</generator>

  <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog" />
  <id>http://gregoryszorc.com/blog/feed/atom/</id>
  <link rel="self" type="application/atom+xml" href="http://gregoryszorc.com/blog/feed/atom/" />
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Aggregating Version Control Info at Mozilla]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2014/01/21/aggregating-version-control-info-at-mozilla" />
    <id>http://gregoryszorc.com/blog/2014/01/21/aggregating-version-control-info-at-mozilla</id>
    <updated>2014-01-21T10:50:00Z</updated>
    <published>2014-01-21T10:50:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Git" />
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <category scheme="http://gregoryszorc.com/blog" term="Python" />
    <summary type="html"><![CDATA[Aggregating Version Control Info at Mozilla]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2014/01/21/aggregating-version-control-info-at-mozilla"><![CDATA[<p>Over the winter break, I set out on an ambitious project to create
a service to help developers and others manage the flury
of patches going into Firefox. While the project is far from complete,
I'm ready to unleash the first part of the project upon the world.</p>
<p>If you point your browsers to
<a href="http://moztree.gregoryszorc.com/">moztree.gregoryszorc.com</a>, you'll
hopefully see some documentation about what I've built.
<a href="https://bitbucket.org/indygreg/moz-tree-utopia">Source code</a> is
available and free, of course. Patches very welcome.</p>
<p>Essentially, I built a centralized indexing service for version
control repositories with Mozilla's extra metadata thrown in.
I tell it what repositories to mirror, and it clones everything,
fetches data such as the pushlog and Git SHA-1 mappings, and
stores everything in a central database. It then exposes this
aggregated data through world-readable web services.</p>
<p>Currently, I have the service indexing the popular project branches
for Firefox (central, aurora, beta, release, esr, b2g, inbound, fx-team,
try, etc). You can view the
<a href="http://moztree.gregoryszorc.com/api/repos">full list</a> via the web
service. As a bonus, I'm also serving these repositories via
<a href="http://hg.gregoryszorc.com/">hg.gregoryszorc.com</a>. My server appears
to be significantly faster than
<a href="https://hg.mozilla.org">hg.mozilla.org</a>. If you want to use it for
your daily needs, go for it. I make no SLA guarantees, however.</p>
<p>I'm also using this service as an opportunity to experiment with
alternate forms of Mercurial hosting. I have mirrors of mozilla-central
and the try repository with generaldelta and lz4 compression enabled.
I may blog about what those are eventually. The teaser is that they can
make Mercurial perform a lot faster under some conditions. I'm also
using ZFS under the hood to manage repositories. Each repository is a
ZFS filesystem. This means I can create repository copies on the server
(user repositories anyone?) at a nearly free cost. Contrast this to the
traditional method of full clones, which take lots of time, memory, CPU,
and storage.</p>
<p>Anyway, some things you can do with the existing web service:</p>
<ul>
<li>Obtain metadata about Mercurial changesets.
  <a href="http://moztree.gregoryszorc.com/api/changeset/940b2974f35b">Example</a>.</li>
<li>Look up metadata about Git commits.
  <a href="http://moztree.gregoryszorc.com/api/git-sha1/40438af67c321">Example</a>.</li>
<li>Obtain a <a href="http://moztree.gregoryszorc.com/api/spore">SPORE descriptor</a>
  describing the web service endpoints. This allows you to auto-generate
  clients from descriptors. Yay!</li>
</ul>
<p>Obviously, that's not a lot. But adding new endpoints is relatively
straightforward. See the <a href="https://bitbucket.org/indygreg/moz-tree-utopia/src/tip/repodata/web/app.py">source</a>.
It's literally as easy as defining a URL mapping and writing a
database query.</p>
<p>The performance is also not the best. I just haven't put in the effort
to tune things yet. All of the querying hits the database, not
Mercurial. So, making things faster should merely be a matter of
database and hosting optimization. Patches welcome!</p>
<p>Some ideas that I haven't had time to implement yet:</p>
<ul>
<li>Return changests in a specific repository</li>
<li>Return recently pushed changesets</li>
<li>Return pushes for a given user</li>
<li>Return commits for a given author</li>
<li>Return commits referencing a given bug</li>
<li>Obtain TBPL URLs for pushes with changeset</li>
<li>Integrate bugzilla metadata</li>
</ul>
<p>Once those are in place, I foresee this service powering a number of
dashboards. Patches welcome.</p>
<p>Again, this service is only the tip of what's possible. There's a lot
that could be built on this service. I have ideas. Others have ideas.</p>
<p>The project includes a Vagrant file and Puppet
manifests for provisioning the server. It's a one-liner to get a
development environment up and running. It should be really easy to
contribute to this project. Patches welcome.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Things Mozilla Could Do with Mercurial]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2014/01/17/things-mozilla-could-do-with-mercurial" />
    <id>http://gregoryszorc.com/blog/2014/01/17/things-mozilla-could-do-with-mercurial</id>
    <updated>2014-01-17T15:00:00Z</updated>
    <published>2014-01-17T15:00:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Things Mozilla Could Do with Mercurial]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2014/01/17/things-mozilla-could-do-with-mercurial"><![CDATA[<p>As I've <a href="/blog/category/mercurial/">written before</a>, Mercurial is a
highly extensible version control system. You can do things with
Mercurial you can't do in other version control systems.</p>
<p>In this post, I'll outline some of the cool things Mozilla could do with
Mercurial. But first, I want to outline some features of Mercurial that
many don't know exist.</p>
<h2>pushkey and listkeys command</h2>
<p>The Mercurial wire protocol (how two Mercurial peer repositories
talk to each other over a network) contains two very useful commands:
<em>pushkey</em> and <em>listkeys</em>. These commands allow the storage and listing
of arbitrary key-value pair metadata in the repository.</p>
<p>This generic storage mechanism is how Mercurial stores and synchronizes
bookmarks and phases information, for example.</p>
<p>By implementing a Mercurial extension, you can have Mercurial store
key-value data for any arbitrary data namespace. You can then write
a simple extension that synchronizes this data as part of the push
and pull operations.</p>
<h2>Extending the wire protocol</h2>
<p>For cases where you want to transmit arbitrary data to/from Mercurial
servers and where the <em>pushkey</em> framework isn't robust enough, it's
possible to implement custom commands in the Mercurial wire protocol.</p>
<p>A server installs an extension making the commands available. A client
installs an extension knowing how to use the commands. Arbitrary data
is transferred or custom actions are performed.</p>
<p>When it comes to custom commands, the sky is really the limit. You
could do pretty much anything from transfer extra data types (this
is how the <a href="http://mercurial.selenic.com/wiki/LargefilesExtension">largefiles extension</a>
works) to writing commands that interact with remote agents.</p>
<h2>Custom revision set queries and templating</h2>
<p>Mercurial offers a rich framework for querying repository data and
for formatting data. The querying is called <em>revision sets</em> and the
later <em>templates</em>. If you are unfamiliar with the feature, I
encourage you to run <em>hg help revset</em> and <em>hg help templates</em> right
now to discover the awesomeness.</p>
<p>As I've <a href="/blog/2013/11/08/using-mercurial-to-query-mozilla-metadata/">demonstrated</a>,
you can do some very nifty things with custom revision sets and
templating!</p>
<h2>The possibilities</h2>
<p>Now that you know some ways Mercurial can be extended, let's talk about
some cool use cases at Mozilla. I want to be clear that I'm not
advocating we do these things, just that they are possible and maybe
they are a little cool.</p>
<h3>Storing pushlog data</h3>
<p>Mozilla records information about who pushed what changesets where and
when in what's called the <em>pushlog</em>. The pushlog data is currently
stored in a SQLite database inside the repository on the server. The
data is made available via a HTTP+JSON API.</p>
<p>We could go a step further and make the pushlog data available via
<em>listkeys</em> so Mercurial clients could download pushlog data with the
same channel used to pull core repository data. (Currently, we have
to open a new TCP connection and talk to the HTTP+JSON API.) This
would make fetching of pushlog data faster, especially for clients
on slow connections.</p>
<p>I concede this is an iterative improvement and adds little value beyond
what we currently have. But if I were designing pushlog storage from
scratch, this is how I'd do it.</p>
<h3>Storing a changeset's automation results</h3>
<p>The <em>pushkey</em> framework could be used to mark specific changesets
as passing automation. When release automation or a sheriff determines
that a changeset/push is green, they could issue an authenticated
<em>pushkey</em> command to the Mercurial server stating such. Clients
could then easily obtain a list of all changesets that are green.</p>
<p>Why stop there? We could also record automation failures in Mercurial as
well. Depending on how complex this gets, we may outgrow <em>pushkey</em>
and require a separate command. But that's all doable.</p>
<p>Anyway, clients could download automation results for a specific
changeset as part of the repository data. The same extension that
pulls down that data could also monkeypatch the bisection algorithm used
by <em>hg bisect</em> to automatically skip over changesets that didn't pass
automation. You'll never bisect a backed out changeset again!</p>
<p>If this automation data were stored on the Try repository, the autoland
tool would just need to query the Mercurial repo to see which changesets
are candidates for merging into mainline - there would be no need for
a separate database and web service!</p>
<h3>Marking a changeset as reviewed</h3>
<p>Currently, Mozilla's review procedure is very patch and Bugzilla
centric. But it doesn't have to be that way. (I argue it shouldn't be
that way.)</p>
<p>Imagine a world where code review is initiated by pushing changesets
to a special server, kind of like how Try magically turns pushes into
automation jobs.</p>
<p>In this world, reviews could be initiated by issuing a <em>pushkey</em>
or custom command to the server. This could even initiate
server-side static analysis that would hold off publishing the review
unless static analysis checks passed!</p>
<p>Granted review could be recorded by having someone issue a
<em>pushkey</em> command to mark a changeset as reviewed. The channel to the
Mercurial server is authenticated via SSH, so the user behind the
current SSH key is the reviewer. The Mercurial server could store this
username as part of the repository data. The autoland tool could then
pull down the reviewer data and only consider changesets that have an
appropriate reviewer.</p>
<p>It <em>might</em> also be possible to integrate crypto magic into this
workflow so reviewers could digitally sign a changeset as reviewed.
This could help with the verification of the Firefox source code
that Brendan Eich <a href="https://brendaneich.com/2014/01/trust-but-verify/">recently outlined</a>.</p>
<p>Like the automation data above, no separate
database would be required: all data would be part of the repository.
All you need to build is a Mercurial extension.</p>
<h3>Encouraging best practices</h3>
<p>Mozillians have written a handful of useful Mercurial extensions to
help people become more productive. We have also noticed that many
developers are still (unknowingly?) running old, slow, and buggy
Mercurial releases. We want people to have the best experience possible.
How do we do that?</p>
<p>One idea is to install an extension on the server that strongly
recommands or even requires users follow best practices (minimal HG
version, installed extensions, etc).</p>
<p>I have developed a <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=941856">proof-of-concept</a>
that does just this.</p>
<h3>Rich querying of metadata</h3>
<p>When you start putting more metadata into Mercurial (or at least write
Mercurial extensions to aggregate this metadata), all kinds of
interesting query opportunities open up. Using revsets and templates,
you can do an awful lot to use Mercurial as a database of sorts
to extract useful reports.</p>
<p>I dare say reports like
<a href="http://oduinn.com/blog/2013/12/03/infrastructure-load-for-november-2013/">John O'duinn's Monthly Infrastructure Load</a>
posts could be completely derived from Mercurial. I've
<a href="/blog/2013/11/08/using-mercurial-to-query-mozilla-metadata/">demonstrated</a>
this ability previously. That's only the tip of the iceburg.</p>
<h2>Summary</h2>
<p>We could enable a lot of new and useful scenarios by extending
Mercurial. We could accomplish this without introducing new
services and tools into our already complicated infrastructure
and workflows.</p>
<p>The possibilities I've suggested are by no means exhaustive. I encourage
others to dream up new and interesting ideas. Who knows, maybe some of
them may actually happen.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[mach now lives in mozilla-central]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2014/01/09/mach-now-lives-in-mozilla-central" />
    <id>http://gregoryszorc.com/blog/2014/01/09/mach-now-lives-in-mozilla-central</id>
    <updated>2014-01-09T10:55:00Z</updated>
    <published>2014-01-09T10:55:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <category scheme="http://gregoryszorc.com/blog" term="mach" />
    <summary type="html"><![CDATA[mach now lives in mozilla-central]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2014/01/09/mach-now-lives-in-mozilla-central"><![CDATA[<p><a href="https://pypi.python.org/pypi/mach/">mach</a> -- the generic command
line interface framework that is behind the <em>mach</em> tool used to
build Firefox -- now has its canonical home in
<a href="https://hg.mozilla.org/mozilla-central/file/default/python/mach/">mozilla-central</a>,
the canonical repository for Firefox. The
<a href="https://github.com/indygreg/mach">previous home</a> has been updated to
reflect the change.</p>
<p>mach will continue to be released on
<a href="https://pypi.python.org/pypi/mach/">PyPI</a> and installable via <strong>pip
install mach</strong>.</p>
<p>I made the change because keeping multiple repositories in sync
wasn't something I wanted to spend time doing. Furthermore,
Mozillians have been contributing a steady stream of improvements to
the mach core recently and it makes sense to leverage Mozilla's
familiar infrastructure for patch contribution.</p>
<p>This decision may be revisited in the future. Time will tell.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Why do Projects Support old Python Releases]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2014/01/08/why-do-projects-support-old-python-releases" />
    <id>http://gregoryszorc.com/blog/2014/01/08/why-do-projects-support-old-python-releases</id>
    <updated>2014-01-09T16:05:00Z</updated>
    <published>2014-01-08T17:00:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Python" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Why do Projects Support old Python Releases]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2014/01/08/why-do-projects-support-old-python-releases"><![CDATA[<p>I see a number of open source projects supporting old versions
of Python. Mercurial supports 2.4, for example. I have to ask: why do
projects continue to support old Python releases?</p>
<p>Consider:</p>
<ul>
<li><a href="http://python.org/download/releases/2.4.6/">Python 2.4</a> was last
  released on December 19, 2008 and <strong>there will be no more releases of
  Python 2.4</strong>.</li>
<li><a href="http://python.org/download/releases/2.5.6/">Python 2.5</a> was last
  released on May 26, 2011 and <strong>there will be no more releases of
  Python 2.5</strong>.</li>
<li><a href="http://python.org/download/releases/2.6.9/">Python 2.6</a> was last
  released on October 29, 2013 and <strong>there will be no more releases of
  Python 2.6</strong>.</li>
<li><strong>Everything before Python 2.7 is end-of-lifed</strong></li>
<li>Python 2.7 continues to see periodic releases, but mostly for bug fixes.</li>
<li>Practically all of the work on CPython is happening in the 3.3 and 3.4
  branches. Other implementations continue to support 2.7.</li>
<li>Python 2.7 has been available since July 2010</li>
<li>Python 2.7 provides some very compelling language features over
  earlier releases that developers want to use</li>
<li>It's much easier to write dual compatible 2/3 Python when 2.7 is the
  only 2.x release considered.</li>
<li>Python 2.7 can be installed in userland relatively easily (see
  projects like <a href="https://github.com/yyuu/pyenv">pyenv</a>).</li>
</ul>
<p>Given these facts, I'm not sure why projects insist on supporting old
and end-of-lifed Python releases.</p>
<p><strong>I think maintainers of Python projects should seriously consider
dropping support for Python 2.6 and below.</strong> Are there really that many
people on systems that don't have Python 2.7 easily available? Why are
we Python developers inflicting so much pain on ourselves to support
antiquated Python releases?</p>
<p>As a data point, I successfully transitioned Firefox's build system
from requiring Python 2.5+ to 2.7.3+ and it was relatively
<a href="https://groups.google.com/d/msg/mozilla.dev.platform/djN02O03APc/OS8A9LuHX0sJ">pain</a>
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=870420">free</a>.
Sure, a few people complained. But as far as I know, not very many new
developers are coming in and complaining about the requirement.
If we can do it with a few thousand developers, I'm guessing your
project can as well.</p>
<p><strong>Update 2014-01-09 16:05:00 PST</strong>: This post is being discussed on
<a href="http://developers.slashdot.org/story/14/01/09/1940232/why-do-projects-continue-to-support-old-python-releases">Slashdot</a>. A lot of the comments
talk about Python 3. Python 3 is its own set of
considerations. The intended focus of this post is strictly about
dropping support for Python 2.6 and below. Python 3 is related
in that porting Python 2.x to Python 3 is much easier the higher
the Python 2.x version. This especially holds true when you want
to write Python that works simultaneously in both 2.x and 3.x.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[On Multiple Patches in Bugs]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2014/01/07/on-multiple-patches-in-bugs" />
    <id>http://gregoryszorc.com/blog/2014/01/07/on-multiple-patches-in-bugs</id>
    <updated>2014-01-07T16:40:00Z</updated>
    <published>2014-01-07T16:40:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[On Multiple Patches in Bugs]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2014/01/07/on-multiple-patches-in-bugs"><![CDATA[<p>There is a common practice at Mozilla for developing patches with
multiple parts. Nothing wrong with that. In fact, I think it's a best
practice:</p>
<ul>
<li>Smaller, self-contained patches are much easier to grok and
  review than larger patches.</li>
<li>Smaller patches can land as soon as they are reviewed. Larger patches
  tend to linger and get bit rotted.</li>
<li>Smaller patches contribute to a culture of being fast and nimble, not
  slow and lethargic. This helps with developer confidence, community
  contributions, etc.</li>
</ul>
<p>There are some downsides to multiple, smaller patches:</p>
<ul>
<li>The bigger picture is harder to understand until all parts of a
  logical patch series are shared. (This can be alleviated through
  commit messages or reviewer notes documenting future intentions.
  And of course reviewers can delay review until they are comfortable.)</li>
<li>There is more overhead to maintain the patches (rebasing, etc).
  IMO the solutions provided by Mercurial and Git are sufficient.</li>
<li>The process overhead for dealing with multiple patches and/or bugs
  can be non-trivial. (I would like to think good tooling coupled with
  continuous revisiting of policy decisions is sufficient to counteract
  this.)</li>
</ul>
<p>Anyway, the prevailing practice at Mozilla seems to be that multiple
patches related to the same logical change are attached to the same
bug. I would like to challenge the effectiveness of this practice.</p>
<p>Given:</p>
<ul>
<li>An individual commit to Firefox should be standalone and should not
  rely on future commits to unbust it (i.e. bisects to any commit should
  be safe).</li>
<li>Bugzilla has no good mechanism to isolate review comments from
  multiple attachments on the same bug, making deciphering simultaneous
  reviews on multiple attachments difficult and frustrating. This leads
  to review comments inevitably falling through the cracks and the
  quality of code suffering.</li>
<li>Reiterating the last point because it's important.</li>
</ul>
<p>I therefore argue that attaching multiple reviews to a single Bugzilla
bug is not a best practice and it should be avoided if possible. If that
means filing separate bugs for each patch, so be it. That process can
be automated. Tools like
<a href="https://hg.mozilla.org/users/tmielczarek_mozilla.com/bzexport">bzexport</a>
already do it. Alternatively (and even better IMO), we ditch
Bugzilla's code review interface (Splinter) and integrate something like
<a href="https://reviewboard.allizom.org/">ReviewBoard</a> instead. We limit
Bugzilla to tracking, high-level discussion, and metadata aggregation.
Code review happens elsewhere, without all the clutter and chaos that
Bugzilla brings to the table.</p>
<p>Thoughts?</p>]]></content>
  </entry>
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Python Package Providing Clients for Mozilla Services]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2014/01/06/python-package-providing-clients-for-mozilla-services" />
    <id>http://gregoryszorc.com/blog/2014/01/06/python-package-providing-clients-for-mozilla-services</id>
    <updated>2014-01-06T10:45:00Z</updated>
    <published>2014-01-06T10:45:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Python" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Python Package Providing Clients for Mozilla Services]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2014/01/06/python-package-providing-clients-for-mozilla-services"><![CDATA[<p>I have a number of Python projects and tools that interact with
various Mozilla services. I had authored clients for all these services
as standalone Python modules so they could be reused across projects.</p>
<p>I have consolidated all these Python modules into a unified source
control
<a href="https://bitbucket.org/indygreg/python-mozautomation">repository</a>
and have made the project available on
<a href="https://pypi.python.org/pypi/mozautomation">PyPI</a>. You can install it
by running:</p>
<p>$ pip install mozautomation</p>
<p>Currently included in the Python package are:</p>
<ul>
<li>A client for <a href="https://treestatus.mozilla.org/">treestatus.mozilla.org</a></li>
<li>Module for extracting cookies from Firefox profiles (useful for
  programmatically getting Bugzilla auth credentials).</li>
<li>A client for reading and interpretting the
  <a href="http://builddata.pub.build.mozilla.org/buildjson/">JSON dumps of automation jobs</a></li>
<li>An interface to a SQLite database to manage associations between
  Mercurial changesets, bugs, and pushes.</li>
<li>Rudimentary parsing of commit messages to extract bugs and reviewers.</li>
<li>A client to obtain information about Firefox releases via the
  <a href="http://releases-api.mozilla.org/">releases API</a></li>
<li>A module defining common Firefox source repositories, aliases, logical
  groups (e.g. twigs and integration trees), and APIs for fetching
  pushlog data.</li>
<li>A client for the <a href="https://secure.pub.build.mozilla.org/buildapi/self-serve/">self serve API</a></li>
</ul>
<p>Documentation and testing is currently sparse. Things aren't up to my
regular high quality standard. But something is better than nothing.</p>
<p>If you are interested in contributing, drop me a line or send pull
requests my way!</p>]]></content>
  </entry>
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Importance of Hosting Your Version Control Server]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2013/11/13/importance-of-hosting-your-version-control-server" />
    <id>http://gregoryszorc.com/blog/2013/11/13/importance-of-hosting-your-version-control-server</id>
    <updated>2013-11-13T09:25:00Z</updated>
    <published>2013-11-13T09:25:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Git" />
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Importance of Hosting Your Version Control Server]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2013/11/13/importance-of-hosting-your-version-control-server"><![CDATA[<p>The subject of where to host version control repositories comes up a lot
at Mozilla. It takes many forms:</p>
<ul>
<li>We should move the Firefox repository to GitHub</li>
<li>I should be allowed to commit to GitHub</li>
<li>I want the canonical repository to be hosted by Bitbucket</li>
</ul>
<p>When Firefox development is concerned, Release Engineerings puts down
their foot and insists the canonical repository be hosted by Mozilla,
under a Mozilla hostname. When that's not possible, they set up a mirror
on Mozilla infrastructure.</p>
<p>I think a
<a href="https://groups.google.com/d/topic/jenkinsci-dev/-myjRIPcVwU/discussion">recent issue with the Jenkins project</a>
demonstrates why hosting your own version control server is important.
The gist is someone force pushed to a bunch of repos hosted on GitHub.
They needed to involve GitHub support to recover from the issue. While
it appears they largely recovered (and GitHub support deserves kudos - I
don't want to take away from their excellence), this problem would have
been avoided or the response time significantly decreased if the Jenkins
people had direct control over the Git server: they either could have
installed a custom hook that would have prevented the pushes or had
access to the reflog so they could have easily seen the last pushed
revision and easily forced pushed back to it. GitHub doesn't have a
mechanism for defining pre-* hooks, doesn't allow defining custom
hooks (a security and performance issue for them), and doesn't
expose the reflog data.</p>
<p>Until repository hosting services expose full repository data (such as
reflogs) and allow you to define custom hooks, accidents like these will
happen and the recovery time will be longer than if you hosted the repo
yourself.</p>
<p>It's possible repository hosting services like GitHub and Bitbucket will
expose these features or provide a means to quickly recover. If so,
kudos to them. But larger, more advanced projects will likely employ
custom hooks and considering custom hooks are a massive security and
performance issue for any hosted service provider, I'm not going to
hold my breath this particular feature is rolled out any time soon.
This is unfortunate, as it makes projects seemingly choose between
low risk/low convenience and GitHub's vibrant developer community.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Mercurial 2.8 released]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2013/11/08/mercurial-2.8-released" />
    <id>http://gregoryszorc.com/blog/2013/11/08/mercurial-2.8-released</id>
    <updated>2013-11-08T14:30:00Z</updated>
    <published>2013-11-08T14:30:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Mercurial 2.8 released]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2013/11/08/mercurial-2.8-released"><![CDATA[<p><a href="http://mercurial.selenic.com/">Mercurial</a> 2.8 has been released.</p>
<p>The <a href="http://mercurial.selenic.com/wiki/WhatsNew#Mercurial_2.8_.282013-11-1.29">changes</a>
aren't as sexy as previous releases. But there are a handful of bug
fixes that seem useful to pull in. People may also find the new <em>shelve</em>
extension useful.</p>
<p>I encourage Mozillians to keep their Mercurial up to date. I once went
around the San Francisco office and stood behind people as they
upgraded to a modern Mercurial. For the next few weeks I was hearing a
lot of "OMG Mercurial is so much better now." Don't handicap yourself by
running an older, buggy Mercurial.</p>
<p>If you don't yet feel comfortable running 2.8, 2.7 should be safe.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Using Mercurial to query Mozilla metadata]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2013/11/08/using-mercurial-to-query-mozilla-metadata" />
    <id>http://gregoryszorc.com/blog/2013/11/08/using-mercurial-to-query-mozilla-metadata</id>
    <updated>2013-11-08T09:42:00Z</updated>
    <published>2013-11-08T09:42:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Using Mercurial to query Mozilla metadata]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2013/11/08/using-mercurial-to-query-mozilla-metadata"><![CDATA[<p>I have updated my
<a href="https://hg.mozilla.org/users/gszorc_mozilla.com/hgext-gecko-dev">Mercurial extension tailored for Gecko/Firefox development</a>
with features that support rich querying of Mozilla/Gecko-development
specific metadata!</p>
<p>The extension now comes with a bug full of
<a href="http://www.selenic.com/hg/help/revsets">revision set</a> selectors and
<a href="http://www.selenic.com/hg/help/templates">template keywords</a>. You can
use them to query and format Mozilla-central metadata from the
repository.</p>
<h2>Revision set selectors</h2>
<p>You can now select changesets referencing a specific bug number:</p>
<pre><code>hg log -r 'bug(931383)'
</code></pre>
<p>Or that were reviewed by a specific person:</p>
<pre><code>hg log -r 'reviewer(gps)'
</code></pre>
<p>Or were reviewed or not reviewed:</p>
<pre><code>hg log -r 'reviewed()'
hg log -r 'not reviewed()'
</code></pre>
<p>You can now select changesets that are present in a specific tree:</p>
<pre><code>hg log -r 'tree(central)'
</code></pre>
<p>I've also introduced support to query changesets <em>you</em> influenced:</p>
<pre><code>hg log -r 'me()'
</code></pre>
<p>(This finds changesets you authored or reviewed.)</p>
<p>You can select changesets that initially landed on a specific tree:</p>
<pre><code>hg log -r 'firstpushtree(central)'
</code></pre>
<p>You can select changesets marked as <em>DONTBUILD</em>:</p>
<pre><code>hg log -r 'dontbuild()'
</code></pre>
<p>You can select changesets that don't reference a bug:</p>
<pre><code>hg log -r 'nobug()'
</code></pre>
<p>You can select changesets that were <em>push heads</em> for a tree:</p>
<pre><code>hg log -r 'pushhead(central)'
</code></pre>
<p>(This would form the basis of a push-aware bisection tool - an excellent
idea for a future feature in this extension.)</p>
<p>You can combine these revset selector functions with other revset
selectors to do some pretty powerful things.</p>
<p>To select all changesets on inbound but not central:</p>
<pre><code>hg log -r 'tree(inbound) - tree(central)'
</code></pre>
<p>To find all your contributions on beta but not release:</p>
<pre><code>hg log -r 'me() &amp; (tree(beta) - tree(release))'
</code></pre>
<p>To find all changesets referencing a specific bug that have landed in
Aurora:</p>
<pre><code>hg log -r 'bug(931383) and tree(aurora)'
</code></pre>
<p>To find all changesets marked <em>DONTBUILD</em> that landed directly on central:</p>
<pre><code>hg log -r 'dontbuild() and firstpushtree(central)'
</code></pre>
<p>To find all non-merge changesets that don't reference a bug:</p>
<pre><code>hg log -r 'not merge() and nobug()'
</code></pre>
<p>Neato!</p>
<h2>Template keywords</h2>
<p>You can also now print some Mozilla information when using templates.</p>
<p>To print the main bug of a changeset, use:</p>
<pre><code>{bug}
</code></pre>
<p>To retrieve all referenced bugs:</p>
<pre><code>{bugs} {join(bugs, ', ')}
</code></pre>
<p>To print the reviewers:</p>
<pre><code>{reviewer} {join(reviewers, ', ')}
</code></pre>
<p>To print the first version a changeset appeared in a specific channel:</p>
<pre><code>{firstrelease} {firstbeta} {firstaurora} {firstnightly}
</code></pre>
<p>To print the <strong>estimated</strong> first Aurora and Nightly date for a
changeset, use:</p>
<pre><code>{auroradate} {nightlydate}
</code></pre>
<p>(Getting the exact first Aurora and Nightly dates requires consulting
3rd party services, which we don't currently do. I'd like to
eventually integrate these into the extension. For now, it just
estimates dates from the pushlog data.)</p>
<p>You can also print who and where pushed a changeset:</p>
<pre><code>{firstpushuser} {firstpushtree}
</code></pre>
<p>You can also print the TBPL URL with the results of the first push:</p>
<pre><code>{firstpushtbpl}
</code></pre>
<p>Here is an example that prints channel versions and dates for each
changesets:</p>
<pre><code>hg log --template '{rev} Nightly: {firstnightly} {nightlydate}; Aurora {firstaurora} {auroradate}; Beta: {firstbeta}; Release: {firstrelease}\n'
</code></pre>
<h2>Putting it all together</h2>
<p>Of course, you can combine selectors and templates to create some
mighty powerful queries.</p>
<p>To look at your impact on Mozilla, do something like:</p>
<pre><code>hg log --template '{rev} Bug {bug}; Release {firstrelease}\n' -r 'me()'
</code></pre>
<p>You can easily forumate a status report for your activity in the past
week:</p>
<pre><code>hg log --template '{firstline(desc)}\n' -r 'firstpushdate(-7) and me()'
</code></pre>
<p>You can also query Mercurial to see where changesets have been landing
in the past 30 days:</p>
<pre><code>hg log --template '{firstpushtree}\n' -r 'firstpushdate(-30)' | sort | uniq -c
</code></pre>
<p>You can see who has been reviewing lots of patches lately:</p>
<pre><code>hg log --template '{join(reviewers, "\n")}\n' -r 'firstpushdate(-30)' | sort | uniq -c | sort -n
</code></pre>
<p>(smaug currently has the top score, edging out my 116 reviews with 137.)</p>
<p>If you want to reuse templates (instead of having to type them on the
command line), you can save them as <em>style files</em>. Search
<a href="https://www.google.com/search?q=mercurial+style+files">the Internets</a>
to learn how to use them. You can even change your default style so
the default output from <em>hg log</em> contains everything you'd ever want to
know about a changeset!</p>
<h2>Keeping it running</h2>
<p>Many of the queries rely on data derived from multiple repositories and
pushlog data that is external to the repository.</p>
<p>To get best results, you'll need to be running a monolithic/unified
Mercurial repository. You can either assemble one locally with this
extension by periodically pulling from the separate repos:</p>
<pre><code>hg pull releases
hg pull integration
</code></pre>
<p>Or, you can pull from
<a href="http://hg.gregoryszorc.com/gecko">my personal unified repo</a>.</p>
<p>You will also need to ensure the pushlog data is current. If you pull
directly from the official repos, this will happen automatically. To be
sure, run:</p>
<pre><code>hg pushlogsync
</code></pre>
<p>Finally, you can force a repopulation of cached bug data by running:</p>
<pre><code>hg buginfo --reset
</code></pre>
<p>Over time, I want all this to automagically work. Stay tuned.</p>
<h2>Comments and future improvements</h2>
<p>I implemented this feature to save myself from having to go troving
through Bugzilla and repository history to answer questions and to
obtain metrics. I can now answer many questions via simple Mercurial
one-liners.</p>
<p>Custom revision set selectors and template keywords are a pretty nifty
feature of Mercurial. They demonstrate how you can extend Mercurial to
be aware of more than just tracking commits and files. As I've
<a href="/blog/2013/05/12/thoughts-on-mercurial-%28and-git%29/">said before</a>
and will continue to say, the extensibility of Mercurial is
really its killer feature, especially for organizations with
well-defined processes (like Mozilla). The kind of extensibility I
achieved with this extension with custom queries and formatting
functions is just not possible with Git (at least not with the reference
C implementation that the overwhelming majority of Git users use).</p>
<p>There are numerous improvements that can be made to the extension.
Obviously more revision set selectors and template keywords can be
added. The parsing routine to extract bugs and reviewers isn't the most
robust in the world. I copied some existing Mozilla code. It does well
at detecting string patters but doesn't cope well with extracting lists.</p>
<p>I'd also love to better integrate Mercurial with automation
results so you can do things like expose a <em>greenpush()</em> selector and do
things like <em>hg up -r 'last(tree(inbound)) and greenpush()'</em> (which
of course could be exposed as <em>lastgreen(inbound)</em>. Wouldn't
that be cool! (This would be possible if we had better APIs for querying
individual push results.) It would also be possible to have the
Mercurial server expose this data as repository data so clients pull it
automatically. That would prevent clients from all needing to query the
same 3rd party services. Just a crazy thought.</p>
<p>Speed can be an issue. Calculating the release information
(<em>{firstnightly}</em> etc) is currently slower than I'd like. This is mostly
due to me using inefficient algorithms and not caching things where I
should. Speed issues should be fixed in due time.</p>
<p>Please let me know if you run into any problems or have suggestions for
improvements. If you want to implement your own revision set selectors
or template keywords, it's <a href="https://hg.mozilla.org/users/gszorc_mozilla.com/hgext-gecko-dev/file/35bb3c96d786/__init__.py#l705">easier</a>
than you think! I will happily accept patches. Keep in mind that
Mercurial can integrate with 3rd party services. So if you want to
supplement repository data with data from a HTTP+JSON web service,
that's very doable. The sky is the limit.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[MacBook Pro Firefox Build Times Comparison]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2013/11/05/macbook-pro-firefox-build-times-comparison" />
    <id>http://gregoryszorc.com/blog/2013/11/05/macbook-pro-firefox-build-times-comparison</id>
    <updated>2013-11-05T10:00:00Z</updated>
    <published>2013-11-05T10:00:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <category scheme="http://gregoryszorc.com/blog" term="build system" />
    <summary type="html"><![CDATA[MacBook Pro Firefox Build Times Comparison]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2013/11/05/macbook-pro-firefox-build-times-comparison"><![CDATA[<p>Many developers use MacBook Pros for day-to-day Firefox development.
So, I thought it would be worthwhile to perform a comparison of
Firefox build times for various models of MacBook Pros.</p>
<h2>Test setup</h2>
<p>The numbers in this post are obtained from 3 generations of MacBook
Pros:</p>
<ol>
<li>
<p>A 2011 Sandy Bridge 4 core x 2.3 GHz with 8 GB RAM and an aftermarket
   SSD.</p>
</li>
<li>
<p>A 2012 Ivy Bridge retina with 4 core x 2.6 GHz, 16 GB RAM, and a
   factory SSD (or possibly flash storage).</p>
</li>
<li>
<p>A 2013 Haswell retina with 4 core x 2.6 GHz, 16 GB RAM, and flash
   storage.</p>
</li>
</ol>
<p>All machines were running OS X 10.9 Mavericks and were using the
Xcode 5.0.1 toolchain (<em>Xcode 5 clang: Apple LLVM version 5.0
(clang-500.2.79) (based on LLVM 3.3svn)</em>) to build.</p>
<p>The power settings prevented machine sleep and machines were plugged
into A/C power during measuring. I did not use the machines while
obtaining measurements.</p>
<p>The 2012 and 2013 machines were very vanilla OS installs. However,
the 2011 machine was my primary work computer and may have had a
few background services running and may have been slower due to
normal wear and tear. The 2012 machine was a loaner machine from
IT and has an unknown history.</p>
<p>All data was obtained from mozilla-central revision d4a27d8eda28.</p>
<p>The mozconfig used contained:</p>
<p>export MOZ_PSEUDO_DERECURSE=1
  mk_add_options MOZ_OBJDIR=@TOPSRCDIR@/obj-firefox.noindex</p>
<p>Please note that the objdir name ends with <em>.noindex</em> to prevent Finder
from indexing build files.</p>
<p>I performed all tests multiple times and used the fastest time. I used
<em>time</em> command for obtaining measurements of wall, user, and system
time.</p>
<h2>Results</h2>
<h3>Configure Times</h3>
<p>The result of <em>mach configure</em> is as follows:</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>29.748</td>
    <td>17.921</td>
    <td>11.644</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>26.765</td>
    <td>15.942</td>
    <td>10.501</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>21.581</td>
    <td>12.597</td>
    <td>8.595</td>
  </tr>
</table>

<h3>Clobber build no ccache</h3>
<p><em>mach build</em> was performed <em>after</em> running <em>mach configure</em>. ccache was
not enabled.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
    <th>Total CPU time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>22:29 (1349)</td>
    <td>145:35 (8735)</td>
    <td>12:03 (723)</td>
    <td>157:38 (9458)</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>15:00 (900)</td>
    <td>94:18 (5658)</td>
    <td>8:14 (494)</td>
    <td>102:32 (6152)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>11:13 (673)</td>
    <td>69:55 (4195)</td>
    <td>6:04 (364)</td>
    <td>75:59 (4559)</td>
  </tr>
</table>

<h3>Clobber build with empty ccache</h3>
<p><em>mach build</em> was performed <em>after</em> running <em>mach configure</em>. ccache was
enabled. The ccache ccache was cleared before running <em>mach configure</em>.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
    <th>Total CPU time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>25:57 (1557)</td>
    <td>161:30 (9690)</td>
    <td>18:21 (1101)</td>
    <td>179:51 (10791)</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>16:58 (1018)</td>
    <td>104:50 (6290)</td>
    <td>12:32 (752)</td>
    <td>117:22 (7042)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>12:59 (779)</td>
    <td>79:51 (4791)</td>
    <td>9:24 (564)</td>
    <td>89:15 (5355)</td>
  </tr>
</table>

<h3>Clobber build with populated ccache</h3>
<p><em>mach build</em> was performed after running <em>mach configure</em>. ccache was
enabled and the ccache was populated with the results of a prior build.
In theory, all compiler invocations should be serviced by ccache
entries.</p>
<p>This measure is a very crude way to measure how fast clobber builds
would be if compiler invocations were nearly instantaneous.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>3:59 (239)</td>
    <td>8:04 (484)</td>
    <td>3:21 (201)(</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>3:11 (191)</td>
    <td>6:45 (405)</td>
    <td>2:53 (173)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>2:31 (151)</td>
    <td>5:22 (322)</td>
    <td>2:12 (132)</td>
  </tr>
</table>

<h3>No-op builds</h3>
<p><em>mach build</em> was performed on a tree that was already built.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>1:58 (118)</td>
    <td>2:25 (145)</td>
    <td>0:41 (41)</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>1:42 (102)</td>
    <td>2:02 (122)</td>
    <td>0:37 (37)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>1:20 (80)</td>
    <td>1:39 (99)</td>
    <td>0:28 (28)</td>
  </tr>
</table>

<h3>binaries no-op</h3>
<p><em>mach build binaries</em> was performed on a fully built tree. This results
in nothing being executed. It's a way to test the overhead of the
<em>binaries</em> make target.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>4.21</td>
    <td>4.38</td>
    <td>0.92</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>3.17</td>
    <td>3.37</td>
    <td>0.71</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>2.67</td>
    <td>2.75</td>
    <td>0.56</td>
  </tr>
</table>

<h3>binaries touch single .cpp</h3>
<p><em>mach build binaries</em> was performed on a fully built tree after touching
the file <em>netwerk/dns/nsHostResolver.cpp</em>. ccache was enabled but
cleared before running this test. This test simulates common C++
developer workflow of changing C++ and recompiling.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>12.89</td>
    <td>13.88</td>
    <td>1.96</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>10.82</td>
    <td>11.63</td>
    <td>1.78</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>8.57</td>
    <td>9.29</td>
    <td>1.23</td>
  </tr>
</table>

<h3>Tier times</h3>
<p>The times of each build system <em>tier</em> were measured on the 2013 Haswell
MacBook Pro. These timings were obtained out of curiosity to help
isolate the impact of different parts of the build. ccache was not
enabled for these tests.</p>
<table border="1">
  <tr>
    <th>Action</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
    <th>Total CPU time</th>
  </tr>
  <tr>
    <td>export clobber</td>
    <td>15.75</td>
    <td>66.11</td>
    <td>11.33</td>
    <td>77.44</td>
  </tr>
  <tr>
    <td>compile clobber</td>
    <td>9:01 (541)</td>
    <td>64:58 (3898)</td>
    <td>5:08 (308)</td>
    <td>70:06 (4206)</td>
  </tr>
  <tr>
    <td>libs clobber</td>
    <td>1:34 (94)</td>
    <td>2:15 (135)</td>
    <td>0:39 (39)</td>
    <td>2:54 (174)</td>
  </tr>
  <tr>
    <td>tools clobber</td>
    <td>9.33</td>
    <td>13.41</td>
    <td>2.48</td>
    <td>15.89</td>
  </tr>
  <tr>
    <td>export no-op</td>
    <td>3.01</td>
    <td>9.72</td>
    <td>3.47</td>
    <td>13.19</td>
  </tr>
  <tr>
    <td>compile no-op</td>
    <td>3.18</td>
    <td>18.02</td>
    <td>2.64</td>
    <td>20.66</td>
  </tr>
  <tr>
    <td>libs no-op</td>
    <td>58.2</td>
    <td>46.9</td>
    <td>13.4</td>
    <td>60.3</td>
  </tr>
  <tr>
    <td>tools no-op</td>
    <td>8.82</td>
    <td>12.68</td>
    <td>1.72</td>
    <td>14.40</td>
  </tr>
</table>

<h2>Observations and conclusions</h2>
<p>The data speaks for itself: <strong>the 2013 Haswell MacBook Pro is
significantly faster than its predecessors.</strong> It clocks in at 2x faster
than the benchmarked 2011 Sandy Bridge model (keep in mind the 300 MHz
base clock difference) and is ~34% faster than the 2012 Ivy Bridge (at
similar clock speed). Personally, I was surprised by this. I was
expecting speed improvements over Ivy Bridge, but not 34%.</p>
<p>It should go without saying: <strong>if you have the opportunity to upgrade
to a new, Haswell-based machine: do it.</strong> If possible, purchase
the upgrade to a 2.6 GHz CPU, as it contains ~13% more MHz than the
base 2.3 GHz model: this will make a measurable difference in build
times.</p>
<p>It's worth noting the increased efficiency of Haswell over its
predecessors. The total CPU time required to build decreased from ~158
minutes to ~103 minutes to 76 minutes! That 76 minute number is worth
highlighting because it means if we get 100% CPU saturation during
builds, we'll be able to build the tree in under 10 wall time minutes!</p>
<p>I hadn't performed crude benchmarks of high-level build system actions
since the <em>MOZ_PSEUDO_DERECURSE</em> work landed and I wanted to use the
opportunity of this hardware comparison to grab some numbers.</p>
<p>The overhead of ccache continues to surprise me. On the 2013
machine, enabling ccache increased the wall time of a clobber build by
1:46 and added 13:16 of CPU time. This is an increase of 16% and 17%,
respectively.</p>
<p>It's worth highlighting just how much time is spent compiling C/C++. In
our artificial tier measuring results, our clobber build time was ~660
wall time seconds (11 minutes) and used ~4473s CPU time (74:33). Of
this, 9:01 wall time and 70:06 CPU time was spent compiling C/C++. This
represents ~82% wall time and ~94% CPU time! Please note this does not
include linking. <strong>Anything we can do to decrease the CPU time used by
the compiler will make the build faster.</strong></p>
<p>I also found it interesting to note variances in obtained times. Even on
my brand new 2013 Haswell MacBook Pro where I know there aren't many
background processes running, wall times could vary significantly. I
<em>think</em> I isolated it to CPU bursting and heat issues. If I wait a few
minutes between CPU intensive tests, results are pretty consistent. But
if I perform CPU intensive tests back-to-back, the run times often vary.
The only other thing coming into play could be page caching or
filesystem indexing. I accounted for the latter by disabling Finder
on the object directory. And, I'd like to think that flash storage is
fast enough to remove I/O latency from the equation. Who knows. At the
end of the day, laptops aren't servers and OS X is a consumer OS, so I
don't expect ultra consistency.</p>
<p>Finally, I want to restate just how fast Haswell is. If you have the
opportunity to upgrade, do it.</p>]]></content>
  </entry>
</feed>
